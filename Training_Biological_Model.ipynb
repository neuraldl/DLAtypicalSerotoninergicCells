{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neuraldl/DLAtypicalSerotoninergicCells/blob/main/Training_Biological_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7XZW4FROPLB"
      },
      "source": [
        "# Serotonergic Cell Recognition - DNN - Conv Model\n",
        "Training & Analyzing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Up Loading"
      ],
      "metadata": {
        "id": "ZOfP1mpfnmr9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKGIBZllfgCx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8da9c1fe-f0bd-482e-92f3-306b9189d6cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from numpy import array\n",
        "from numpy import hstack\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from datetime import datetime, timedelta\n",
        "import os\n",
        "import IPython\n",
        "import IPython.display\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "# @title\n",
        "from keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Modelling\n"
      ],
      "metadata": {
        "id": "5CfSCZzngAa6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Biological Data\n",
        "\n",
        "SER Cellulars\n",
        "\n",
        "https://drive.google.com/drive/folders/1OH8HZlfHk17qekf3vjGcXjaARikYGg2E?usp=sharing\n",
        "\n",
        "NSER Cellulars\n",
        "\n",
        "https://drive.google.com/drive/folders/1SzHVo5lmmJy1U2PvwYhHpvdnFpe9lCyP?usp=sharing"
      ],
      "metadata": {
        "id": "6iNrPdQhb0jv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDkI7tKHCCB2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d112bb7-371d-4ebe-9eb6-e20f4ec9e68b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A131024#089\n",
            "172\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A131024#092\n",
            "380\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A131024#095\n",
            "101\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A131024#098\n",
            "288\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A131024#101\n",
            "374\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A131024#104\n",
            "185\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A131024#107\n",
            "240\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A131024#110\n",
            "252\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A131024#113\n",
            "319\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A131024#116\n",
            "131\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A131024#119\n",
            "149\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A131024#125\n",
            "214\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A131024#170\n",
            "601\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A131024#173\n",
            "477\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A131024#176\n",
            "494\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A131024#182\n",
            "317\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A131024#194\n",
            "434\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A131024#199\n",
            "131\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A131024#202\n",
            "189\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A131024#205\n",
            "242\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A131024#215\n",
            "170\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A131024#227\n",
            "162\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A131024#233\n",
            "270\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A131024#239\n",
            "194\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A131031#016\n",
            "188\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A131031#025\n",
            "417\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A131031#028\n",
            "306\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A131031#037\n",
            "165\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A131031#043\n",
            "271\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A131031#049\n",
            "357\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A131031#094\n",
            "299\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A131031#103\n",
            "312\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A131031#118\n",
            "462\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A131031#147\n",
            "511\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A131031#159\n",
            "446\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A131031#162\n",
            "393\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A131031#165\n",
            "342\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A131031#173\n",
            "190\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A131031#179\n",
            "157\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A131031#182\n",
            "183\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A131031#188\n",
            "223\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A131031#191\n",
            "141\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A131031#194\n",
            "239\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A140121#004\n",
            "166\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A140121#017\n",
            "35\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A140121#057\n",
            "255\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A140122#075\n",
            "348\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A140122#080\n",
            "700\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A140122#096\n",
            "217\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A140122#104\n",
            "89\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A140122#115\n",
            "319\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A140122#117\n",
            "311\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A140122#119\n",
            "321\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A140212#027\n",
            "136\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A140212#034\n",
            "250\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A140212#036\n",
            "111\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A140313#008\n",
            "224\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A140313#010\n",
            "120\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A140313#012\n",
            "150\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A140313#022\n",
            "242\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A140313#028\n",
            "206\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A140313#032\n",
            "205\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A140313#034\n",
            "190\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A140313#036\n",
            "187\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A140313#038\n",
            "222\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A140313#040\n",
            "180\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A140313#044\n",
            "205\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A140313#046\n",
            "150\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A140313#048\n",
            "208\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A140313#050\n",
            "201\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A140313#052\n",
            "352\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A140313#054\n",
            "189\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A140313#068\n",
            "298\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A140313#070\n",
            "296\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A140313#073\n",
            "208\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A140313#074\n",
            "261\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A140313#075\n",
            "226\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A140724#043\n",
            "95\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A140725#003\n",
            "125\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A140725#006\n",
            "486\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A140725#009\n",
            "293\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A140725#029\n",
            "300\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A140725#030\n",
            "179\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A140910#006\n",
            "217\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A140910#008\n",
            "219\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A150515#001\n",
            "262\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A150515#003\n",
            "481\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A150515#007\n",
            "366\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A150515#012\n",
            "453\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A150515#018\n",
            "682\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A150618#001\n",
            "511\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A150618#004\n",
            "312\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A150618#007\n",
            "411\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A150619#004\n",
            "296\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A150629#019\n",
            "391\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A150629#029\n",
            "416\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A150630#013\n",
            "482\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A150630#028\n",
            "356\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A150630#034\n",
            "400\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A150701#005\n",
            "259\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A150701#009\n",
            "159\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A150701#018\n",
            "125\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A150701#024\n",
            "177\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A150701#032\n",
            "305\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A150701#034\n",
            "187\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A150701#058\n",
            "584\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A150701#066\n",
            "153\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/SER/A151015#010\n",
            "225\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/NSER/A131024#140\n",
            "700\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/NSER/A131024#143\n",
            "700\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/NSER/A131024#146\n",
            "226\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/NSER/A131031#046\n",
            "132\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/NSER/A131031#085\n",
            "138\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/NSER/A131031#138\n",
            "700\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/NSER/A131031#170\n",
            "418\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/NSER/A131031#176\n",
            "120\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/NSER/A131031#185\n",
            "173\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/NSER/A140121#044\n",
            "432\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/NSER/A140212#002\n",
            "56\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/NSER/A140212#006\n",
            "124\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/NSER/A140313#042\n",
            "610\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/NSER/A140313#062\n",
            "700\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/NSER/A140725#057\n",
            "250\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/NSER/A160118#020\n",
            "628\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/NSER/A160118#023\n",
            "31\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/NSER/A160125#037\n",
            "637\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/NSER/A160125#059\n",
            "15\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/NSER/A160125#063\n",
            "292\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/NSER/A160125#071\n",
            "15\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/NSER/A160125#089\n",
            "27\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/NSER/A160125#095\n",
            "311\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/NSER/A160127#015\n",
            "183\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/NSER/A160127#019\n",
            "688\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/NSER/A160127#021\n",
            "341\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/NSER/A160127#023\n",
            "494\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/NSER/A160127#025\n",
            "127\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/NSER/A160127#027\n",
            "340\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/NSER/A160127#029\n",
            "426\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/NSER/A160127#037\n",
            "16\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/NSER/A160322#007\n",
            "38\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/NSER/A160322#010\n",
            "168\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/NSER/A160322#013\n",
            "201\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/NSER/A160322#016\n",
            "321\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/NSER/A160420#007\n",
            "60\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/NSER/A160420#013\n",
            "101\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/NSER/A160420#023\n",
            "20\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/NSER/A160420#033\n",
            "496\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/NSER/A160420#043\n",
            "30\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/NSER/F160324#015\n",
            "376\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/NSER/F160411#014\n",
            "700\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/NSER/F160411#016\n",
            "46\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/NSER/F160411#021\n",
            "437\n",
            "/content/drive/MyDrive/NEURONDL/NEW-RAW-20231205 /3rd-RUN-Single-Spikes/NSER/F160411#051\n",
            "510\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Paths to the data directories\n",
        "directories = {\n",
        "    \"SERTIP\": \"../SER\",\n",
        "    \"NSERTIP\": \"../NSER\"\n",
        "}\n",
        "\n",
        "# Class labels\n",
        "labels = {\"SERTIP\": 0, \"NSERTIP\": 1}\n",
        "# Load the data (just for the first time, then jump at 2 cells below)\n",
        "obs = []\n",
        "lbs = []\n",
        "cls = []\n",
        "i = 0\n",
        "for label, path in directories.items():\n",
        "  folders = os.listdir(path)\n",
        "  folders = sorted(folders)\n",
        "  for folder in folders:\n",
        "    if 'IMAGES' not in folder:\n",
        "      path_folder = os.path.join(path,folder)\n",
        "      print(path_folder)\n",
        "      files = os.listdir(path_folder)\n",
        "      print(len(files))\n",
        "      i=0\n",
        "      for file_name in files:\n",
        "        file_path = os.path.join(path_folder, file_name)\n",
        "        record = pd.read_csv(file_path,header=0)\n",
        "        if len(record)==160:\n",
        "          #print('OK')\n",
        "          recordT = record.to_numpy().reshape(len(record),2,1)\n",
        "          if len(obs)==0:\n",
        "            obs = [recordT]\n",
        "          else:\n",
        "            obs = np.append(obs,[recordT], axis=0)\n",
        "          cls = np.append(cls,[file_name])\n",
        "          lbs = np.append(lbs,[labels[label]], axis=0)\n",
        "          i+=1\n",
        "lbs = lbs.reshape(len(lbs),1)\n",
        "cls = cls.reshape(len(cls),1)\n",
        "dimN = len(record)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nywLUc-KW7Uq",
        "outputId": "1b083122-7ec6-4436-9431-25028b5a7559"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(43327, 43327, 43327)"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ],
      "source": [
        "len(obs),len(lbs),len(cls)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSwYVFqCK5ub"
      },
      "source": [
        "###Split the data using Scikit-learn:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-mfXNi8K5Cs"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Features and labels\n",
        "X = obs\n",
        "y = lbs\n",
        "\n",
        "# Splitting the data into training, validation, and test sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-xkuYyQr31I",
        "outputId": "52ed6f48-90a1-47f7-be8a-1e6866b38ef4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (30328, 160, 2, 1)\n",
            "30328 train samples\n",
            "6500 test samples\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Features and labels\n",
        "X = obs\n",
        "y = lbs\n",
        "# Splitting the data into training, validation, and test sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "# Model / data parameters\n",
        "num_classes = 2\n",
        "print(\"x_train shape:\", X_train.shape)\n",
        "print(X_train.shape[0], \"train samples\")\n",
        "print(X_test.shape[0], \"test samples\")\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "y_val = keras.utils.to_categorical(y_val, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4r1SeVmE2F3v",
        "outputId": "1422560e-0fd5-4d70-c245-031861450abf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((30328, 2), (6499, 2), (6500, 2), (6499, 160, 2, 1), (6499, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "y_train.shape, y_val.shape, y_test.shape, X_val.shape, y_val.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Compiling & Training"
      ],
      "metadata": {
        "id": "I_ZZ0j2Mhg4D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DNN Keras Models and Results\n",
        "\n",
        "ModelsDNN Folder\n",
        "\n",
        "https://drive.google.com/drive/folders/1zjwc-_P6zjsmc77BdwgBhxrEhBGw8Igz?usp=sharing"
      ],
      "metadata": {
        "id": "QdtB5A7RbYgA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MjD5siuDRte",
        "outputId": "815f4f2d-1984-4729-f000-9ab78b1b33e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 160, 2, 32)        64        \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 80, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 80, 2, 64)         2112      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 40, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2560)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2560)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 5122      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7618 (29.76 KB)\n",
            "Trainable params: 7618 (29.76 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "474/474 [==============================] - 18s 8ms/step - loss: 0.3534 - accuracy: 0.8289 - precision: 0.8283 - recall: 0.8288 - binary_accuracy: 0.8285 - false_positives: 5209.0000 - false_negatives: 5192.0000 - sensitivity_at_specificity: 0.9853 - val_loss: 0.3043 - val_accuracy: 0.8594 - val_precision: 0.8598 - val_recall: 0.8597 - val_binary_accuracy: 0.8597 - val_false_positives: 911.0000 - val_false_negatives: 912.0000 - val_sensitivity_at_specificity: 0.9951\n",
            "Epoch 2/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.3077 - accuracy: 0.8559 - precision: 0.8558 - recall: 0.8559 - binary_accuracy: 0.8558 - false_positives: 4375.0000 - false_negatives: 4371.0000 - sensitivity_at_specificity: 0.9924 - val_loss: 0.2900 - val_accuracy: 0.8669 - val_precision: 0.8677 - val_recall: 0.8647 - val_binary_accuracy: 0.8664 - val_false_positives: 857.0000 - val_false_negatives: 879.0000 - val_sensitivity_at_specificity: 0.9938\n",
            "Epoch 3/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.2995 - accuracy: 0.8633 - precision: 0.8627 - recall: 0.8622 - binary_accuracy: 0.8625 - false_positives: 4163.0000 - false_negatives: 4178.0000 - sensitivity_at_specificity: 0.9930 - val_loss: 0.2827 - val_accuracy: 0.8707 - val_precision: 0.8706 - val_recall: 0.8704 - val_binary_accuracy: 0.8705 - val_false_positives: 841.0000 - val_false_negatives: 842.0000 - val_sensitivity_at_specificity: 0.9943\n",
            "Epoch 4/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.2913 - accuracy: 0.8667 - precision: 0.8663 - recall: 0.8673 - binary_accuracy: 0.8667 - false_positives: 4060.0000 - false_negatives: 4025.0000 - sensitivity_at_specificity: 0.9927 - val_loss: 0.2760 - val_accuracy: 0.8711 - val_precision: 0.8711 - val_recall: 0.8703 - val_binary_accuracy: 0.8707 - val_false_positives: 837.0000 - val_false_negatives: 843.0000 - val_sensitivity_at_specificity: 0.9960\n",
            "Epoch 5/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.2862 - accuracy: 0.8704 - precision: 0.8706 - recall: 0.8703 - binary_accuracy: 0.8705 - false_positives: 3923.0000 - false_negatives: 3933.0000 - sensitivity_at_specificity: 0.9937 - val_loss: 0.2785 - val_accuracy: 0.8727 - val_precision: 0.8734 - val_recall: 0.8723 - val_binary_accuracy: 0.8729 - val_false_positives: 822.0000 - val_false_negatives: 830.0000 - val_sensitivity_at_specificity: 0.9937\n",
            "Epoch 6/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.2828 - accuracy: 0.8721 - precision: 0.8718 - recall: 0.8723 - binary_accuracy: 0.8720 - false_positives: 3889.0000 - false_negatives: 3872.0000 - sensitivity_at_specificity: 0.9943 - val_loss: 0.2701 - val_accuracy: 0.8789 - val_precision: 0.8786 - val_recall: 0.8784 - val_binary_accuracy: 0.8785 - val_false_positives: 789.0000 - val_false_negatives: 790.0000 - val_sensitivity_at_specificity: 0.9952\n",
            "Epoch 7/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.2801 - accuracy: 0.8739 - precision: 0.8735 - recall: 0.8743 - binary_accuracy: 0.8738 - false_positives: 3839.0000 - false_negatives: 3813.0000 - sensitivity_at_specificity: 0.9940 - val_loss: 0.2638 - val_accuracy: 0.8761 - val_precision: 0.8766 - val_recall: 0.8764 - val_binary_accuracy: 0.8765 - val_false_positives: 802.0000 - val_false_negatives: 803.0000 - val_sensitivity_at_specificity: 0.9966\n",
            "Epoch 8/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.2754 - accuracy: 0.8792 - precision: 0.8791 - recall: 0.8790 - binary_accuracy: 0.8791 - false_positives: 3667.0000 - false_negatives: 3669.0000 - sensitivity_at_specificity: 0.9943 - val_loss: 0.2600 - val_accuracy: 0.8811 - val_precision: 0.8810 - val_recall: 0.8815 - val_binary_accuracy: 0.8812 - val_false_positives: 774.0000 - val_false_negatives: 770.0000 - val_sensitivity_at_specificity: 0.9962\n",
            "Epoch 9/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.2736 - accuracy: 0.8786 - precision: 0.8788 - recall: 0.8784 - binary_accuracy: 0.8786 - false_positives: 3673.0000 - false_negatives: 3689.0000 - sensitivity_at_specificity: 0.9945 - val_loss: 0.2577 - val_accuracy: 0.8874 - val_precision: 0.8875 - val_recall: 0.8869 - val_binary_accuracy: 0.8872 - val_false_positives: 731.0000 - val_false_negatives: 735.0000 - val_sensitivity_at_specificity: 0.9969\n",
            "Epoch 10/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.2691 - accuracy: 0.8808 - precision: 0.8805 - recall: 0.8808 - binary_accuracy: 0.8806 - false_positives: 3625.0000 - false_negatives: 3615.0000 - sensitivity_at_specificity: 0.9952 - val_loss: 0.2714 - val_accuracy: 0.8766 - val_precision: 0.8766 - val_recall: 0.8764 - val_binary_accuracy: 0.8765 - val_false_positives: 802.0000 - val_false_negatives: 803.0000 - val_sensitivity_at_specificity: 0.9960\n",
            "Epoch 11/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.2674 - accuracy: 0.8816 - precision: 0.8814 - recall: 0.8817 - binary_accuracy: 0.8816 - false_positives: 3597.0000 - false_negatives: 3587.0000 - sensitivity_at_specificity: 0.9949 - val_loss: 0.2568 - val_accuracy: 0.8815 - val_precision: 0.8814 - val_recall: 0.8818 - val_binary_accuracy: 0.8816 - val_false_positives: 771.0000 - val_false_negatives: 768.0000 - val_sensitivity_at_specificity: 0.9968\n",
            "Epoch 12/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.2647 - accuracy: 0.8839 - precision: 0.8840 - recall: 0.8840 - binary_accuracy: 0.8840 - false_positives: 3519.0000 - false_negatives: 3518.0000 - sensitivity_at_specificity: 0.9946 - val_loss: 0.2469 - val_accuracy: 0.8914 - val_precision: 0.8914 - val_recall: 0.8912 - val_binary_accuracy: 0.8913 - val_false_positives: 706.0000 - val_false_negatives: 707.0000 - val_sensitivity_at_specificity: 0.9969\n",
            "Epoch 13/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.2605 - accuracy: 0.8856 - precision: 0.8856 - recall: 0.8856 - binary_accuracy: 0.8856 - false_positives: 3471.0000 - false_negatives: 3471.0000 - sensitivity_at_specificity: 0.9957 - val_loss: 0.2453 - val_accuracy: 0.8906 - val_precision: 0.8908 - val_recall: 0.8908 - val_binary_accuracy: 0.8908 - val_false_positives: 710.0000 - val_false_negatives: 710.0000 - val_sensitivity_at_specificity: 0.9969\n",
            "Epoch 14/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.2583 - accuracy: 0.8875 - precision: 0.8873 - recall: 0.8877 - binary_accuracy: 0.8875 - false_positives: 3420.0000 - false_negatives: 3406.0000 - sensitivity_at_specificity: 0.9954 - val_loss: 0.2438 - val_accuracy: 0.8960 - val_precision: 0.8958 - val_recall: 0.8958 - val_binary_accuracy: 0.8958 - val_false_positives: 677.0000 - val_false_negatives: 677.0000 - val_sensitivity_at_specificity: 0.9960\n",
            "Epoch 15/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.2552 - accuracy: 0.8891 - precision: 0.8891 - recall: 0.8889 - binary_accuracy: 0.8890 - false_positives: 3363.0000 - false_negatives: 3369.0000 - sensitivity_at_specificity: 0.9954 - val_loss: 0.2387 - val_accuracy: 0.8988 - val_precision: 0.8988 - val_recall: 0.8983 - val_binary_accuracy: 0.8986 - val_false_positives: 657.0000 - val_false_negatives: 661.0000 - val_sensitivity_at_specificity: 0.9962\n",
            "Epoch 16/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.2517 - accuracy: 0.8916 - precision: 0.8914 - recall: 0.8914 - binary_accuracy: 0.8914 - false_positives: 3292.0000 - false_negatives: 3293.0000 - sensitivity_at_specificity: 0.9962 - val_loss: 0.2351 - val_accuracy: 0.8994 - val_precision: 0.8998 - val_recall: 0.8992 - val_binary_accuracy: 0.8995 - val_false_positives: 651.0000 - val_false_negatives: 655.0000 - val_sensitivity_at_specificity: 0.9974\n",
            "Epoch 17/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.2472 - accuracy: 0.8912 - precision: 0.8909 - recall: 0.8913 - binary_accuracy: 0.8911 - false_positives: 3309.0000 - false_negatives: 3298.0000 - sensitivity_at_specificity: 0.9960 - val_loss: 0.2346 - val_accuracy: 0.9000 - val_precision: 0.9003 - val_recall: 0.9001 - val_binary_accuracy: 0.9002 - val_false_positives: 648.0000 - val_false_negatives: 649.0000 - val_sensitivity_at_specificity: 0.9974\n",
            "Epoch 18/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.2460 - accuracy: 0.8949 - precision: 0.8947 - recall: 0.8948 - binary_accuracy: 0.8948 - false_positives: 3194.0000 - false_negatives: 3190.0000 - sensitivity_at_specificity: 0.9963 - val_loss: 0.2302 - val_accuracy: 0.8998 - val_precision: 0.9000 - val_recall: 0.8997 - val_binary_accuracy: 0.8998 - val_false_positives: 650.0000 - val_false_negatives: 652.0000 - val_sensitivity_at_specificity: 0.9971\n",
            "Epoch 19/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.2417 - accuracy: 0.8961 - precision: 0.8961 - recall: 0.8964 - binary_accuracy: 0.8962 - false_positives: 3151.0000 - false_negatives: 3143.0000 - sensitivity_at_specificity: 0.9966 - val_loss: 0.2270 - val_accuracy: 0.9037 - val_precision: 0.9037 - val_recall: 0.9037 - val_binary_accuracy: 0.9037 - val_false_positives: 626.0000 - val_false_negatives: 626.0000 - val_sensitivity_at_specificity: 0.9974\n",
            "Epoch 20/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.2394 - accuracy: 0.8985 - precision: 0.8983 - recall: 0.8983 - binary_accuracy: 0.8983 - false_positives: 3084.0000 - false_negatives: 3083.0000 - sensitivity_at_specificity: 0.9963 - val_loss: 0.2291 - val_accuracy: 0.9044 - val_precision: 0.9045 - val_recall: 0.9048 - val_binary_accuracy: 0.9046 - val_false_positives: 621.0000 - val_false_negatives: 619.0000 - val_sensitivity_at_specificity: 0.9957\n",
            "Epoch 21/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.2393 - accuracy: 0.8972 - precision: 0.8970 - recall: 0.8974 - binary_accuracy: 0.8972 - false_positives: 3126.0000 - false_negatives: 3112.0000 - sensitivity_at_specificity: 0.9964 - val_loss: 0.2247 - val_accuracy: 0.9041 - val_precision: 0.9044 - val_recall: 0.9040 - val_binary_accuracy: 0.9042 - val_false_positives: 621.0000 - val_false_negatives: 624.0000 - val_sensitivity_at_specificity: 0.9978\n",
            "Epoch 22/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.2340 - accuracy: 0.8999 - precision: 0.8997 - recall: 0.8998 - binary_accuracy: 0.8997 - false_positives: 3043.0000 - false_negatives: 3040.0000 - sensitivity_at_specificity: 0.9968 - val_loss: 0.2235 - val_accuracy: 0.9071 - val_precision: 0.9069 - val_recall: 0.9069 - val_binary_accuracy: 0.9069 - val_false_positives: 605.0000 - val_false_negatives: 605.0000 - val_sensitivity_at_specificity: 0.9968\n",
            "Epoch 23/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.2343 - accuracy: 0.9006 - precision: 0.9006 - recall: 0.9007 - binary_accuracy: 0.9006 - false_positives: 3014.0000 - false_negatives: 3013.0000 - sensitivity_at_specificity: 0.9966 - val_loss: 0.2219 - val_accuracy: 0.9054 - val_precision: 0.9051 - val_recall: 0.9055 - val_binary_accuracy: 0.9053 - val_false_positives: 617.0000 - val_false_negatives: 614.0000 - val_sensitivity_at_specificity: 0.9972\n",
            "Epoch 24/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.2302 - accuracy: 0.9018 - precision: 0.9016 - recall: 0.9019 - binary_accuracy: 0.9018 - false_positives: 2985.0000 - false_negatives: 2974.0000 - sensitivity_at_specificity: 0.9967 - val_loss: 0.2222 - val_accuracy: 0.9097 - val_precision: 0.9095 - val_recall: 0.9095 - val_binary_accuracy: 0.9095 - val_false_positives: 588.0000 - val_false_negatives: 588.0000 - val_sensitivity_at_specificity: 0.9972\n",
            "Epoch 25/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.2280 - accuracy: 0.9022 - precision: 0.9020 - recall: 0.9023 - binary_accuracy: 0.9022 - false_positives: 2973.0000 - false_negatives: 2962.0000 - sensitivity_at_specificity: 0.9967 - val_loss: 0.2173 - val_accuracy: 0.9108 - val_precision: 0.9110 - val_recall: 0.9106 - val_binary_accuracy: 0.9108 - val_false_positives: 578.0000 - val_false_negatives: 581.0000 - val_sensitivity_at_specificity: 0.9977\n",
            "Test loss: 0.22217142581939697\n",
            "Test accuracy: 0.9064615368843079\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 159, 2, 32)        96        \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 79, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 78, 2, 64)         4160      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 39, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2496)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2496)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 4994      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9570 (37.38 KB)\n",
            "Trainable params: 9570 (37.38 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "474/474 [==============================] - 6s 8ms/step - loss: 0.3370 - accuracy: 0.8387 - precision: 0.8381 - recall: 0.8375 - binary_accuracy: 0.8379 - false_positives: 4906.0000 - false_negatives: 4929.0000 - sensitivity_at_specificity: 0.9878 - val_loss: 0.2817 - val_accuracy: 0.8701 - val_precision: 0.8702 - val_recall: 0.8687 - val_binary_accuracy: 0.8696 - val_false_positives: 842.0000 - val_false_negatives: 853.0000 - val_sensitivity_at_specificity: 0.9971\n",
            "Epoch 2/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.2802 - accuracy: 0.8728 - precision: 0.8721 - recall: 0.8729 - binary_accuracy: 0.8724 - false_positives: 3883.0000 - false_negatives: 3854.0000 - sensitivity_at_specificity: 0.9946 - val_loss: 0.2571 - val_accuracy: 0.8803 - val_precision: 0.8819 - val_recall: 0.8791 - val_binary_accuracy: 0.8807 - val_false_positives: 765.0000 - val_false_negatives: 786.0000 - val_sensitivity_at_specificity: 0.9977\n",
            "Epoch 3/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.2595 - accuracy: 0.8848 - precision: 0.8850 - recall: 0.8850 - binary_accuracy: 0.8850 - false_positives: 3489.0000 - false_negatives: 3488.0000 - sensitivity_at_specificity: 0.9958 - val_loss: 0.2386 - val_accuracy: 0.8932 - val_precision: 0.8930 - val_recall: 0.8948 - val_binary_accuracy: 0.8938 - val_false_positives: 697.0000 - val_false_negatives: 684.0000 - val_sensitivity_at_specificity: 0.9969\n",
            "Epoch 4/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.2447 - accuracy: 0.8935 - precision: 0.8940 - recall: 0.8933 - binary_accuracy: 0.8937 - false_positives: 3213.0000 - false_negatives: 3236.0000 - sensitivity_at_specificity: 0.9954 - val_loss: 0.2350 - val_accuracy: 0.8983 - val_precision: 0.8978 - val_recall: 0.8988 - val_binary_accuracy: 0.8982 - val_false_positives: 665.0000 - val_false_negatives: 658.0000 - val_sensitivity_at_specificity: 0.9977\n",
            "Epoch 5/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.2365 - accuracy: 0.8999 - precision: 0.9000 - recall: 0.8989 - binary_accuracy: 0.8995 - false_positives: 3029.0000 - false_negatives: 3066.0000 - sensitivity_at_specificity: 0.9963 - val_loss: 0.2200 - val_accuracy: 0.9060 - val_precision: 0.9063 - val_recall: 0.9061 - val_binary_accuracy: 0.9062 - val_false_positives: 609.0000 - val_false_negatives: 610.0000 - val_sensitivity_at_specificity: 0.9972\n",
            "Epoch 6/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.2302 - accuracy: 0.9011 - precision: 0.9015 - recall: 0.9013 - binary_accuracy: 0.9014 - false_positives: 2987.0000 - false_negatives: 2994.0000 - sensitivity_at_specificity: 0.9966 - val_loss: 0.2133 - val_accuracy: 0.9066 - val_precision: 0.9063 - val_recall: 0.9068 - val_binary_accuracy: 0.9065 - val_false_positives: 609.0000 - val_false_negatives: 606.0000 - val_sensitivity_at_specificity: 0.9977\n",
            "Epoch 7/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.2272 - accuracy: 0.9048 - precision: 0.9044 - recall: 0.9044 - binary_accuracy: 0.9044 - false_positives: 2900.0000 - false_negatives: 2900.0000 - sensitivity_at_specificity: 0.9962 - val_loss: 0.2116 - val_accuracy: 0.9069 - val_precision: 0.9061 - val_recall: 0.9071 - val_binary_accuracy: 0.9065 - val_false_positives: 611.0000 - val_false_negatives: 604.0000 - val_sensitivity_at_specificity: 0.9980\n",
            "Epoch 8/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.2197 - accuracy: 0.9073 - precision: 0.9072 - recall: 0.9070 - binary_accuracy: 0.9071 - false_positives: 2814.0000 - false_negatives: 2821.0000 - sensitivity_at_specificity: 0.9964 - val_loss: 0.2036 - val_accuracy: 0.9164 - val_precision: 0.9169 - val_recall: 0.9164 - val_binary_accuracy: 0.9167 - val_false_positives: 540.0000 - val_false_negatives: 543.0000 - val_sensitivity_at_specificity: 0.9977\n",
            "Epoch 9/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.2184 - accuracy: 0.9090 - precision: 0.9093 - recall: 0.9089 - binary_accuracy: 0.9091 - false_positives: 2750.0000 - false_negatives: 2762.0000 - sensitivity_at_specificity: 0.9962 - val_loss: 0.2026 - val_accuracy: 0.9109 - val_precision: 0.9110 - val_recall: 0.9106 - val_binary_accuracy: 0.9108 - val_false_positives: 578.0000 - val_false_negatives: 581.0000 - val_sensitivity_at_specificity: 0.9983\n",
            "Epoch 10/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.2114 - accuracy: 0.9127 - precision: 0.9128 - recall: 0.9127 - binary_accuracy: 0.9127 - false_positives: 2645.0000 - false_negatives: 2649.0000 - sensitivity_at_specificity: 0.9969 - val_loss: 0.1951 - val_accuracy: 0.9181 - val_precision: 0.9179 - val_recall: 0.9181 - val_binary_accuracy: 0.9180 - val_false_positives: 534.0000 - val_false_negatives: 532.0000 - val_sensitivity_at_specificity: 0.9980\n",
            "Epoch 11/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.2104 - accuracy: 0.9144 - precision: 0.9142 - recall: 0.9146 - binary_accuracy: 0.9144 - false_positives: 2603.0000 - false_negatives: 2590.0000 - sensitivity_at_specificity: 0.9969 - val_loss: 0.2019 - val_accuracy: 0.9129 - val_precision: 0.9133 - val_recall: 0.9123 - val_binary_accuracy: 0.9128 - val_false_positives: 563.0000 - val_false_negatives: 570.0000 - val_sensitivity_at_specificity: 0.9978\n",
            "Epoch 12/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.2062 - accuracy: 0.9145 - precision: 0.9147 - recall: 0.9143 - binary_accuracy: 0.9145 - false_positives: 2585.0000 - false_negatives: 2599.0000 - sensitivity_at_specificity: 0.9972 - val_loss: 0.1913 - val_accuracy: 0.9191 - val_precision: 0.9188 - val_recall: 0.9191 - val_binary_accuracy: 0.9189 - val_false_positives: 528.0000 - val_false_negatives: 526.0000 - val_sensitivity_at_specificity: 0.9982\n",
            "Epoch 13/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.2018 - accuracy: 0.9179 - precision: 0.9178 - recall: 0.9181 - binary_accuracy: 0.9179 - false_positives: 2494.0000 - false_negatives: 2484.0000 - sensitivity_at_specificity: 0.9971 - val_loss: 0.1862 - val_accuracy: 0.9254 - val_precision: 0.9258 - val_recall: 0.9248 - val_binary_accuracy: 0.9253 - val_false_positives: 482.0000 - val_false_negatives: 489.0000 - val_sensitivity_at_specificity: 0.9977\n",
            "Epoch 14/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1970 - accuracy: 0.9191 - precision: 0.9190 - recall: 0.9190 - binary_accuracy: 0.9190 - false_positives: 2456.0000 - false_negatives: 2457.0000 - sensitivity_at_specificity: 0.9974 - val_loss: 0.1811 - val_accuracy: 0.9244 - val_precision: 0.9243 - val_recall: 0.9246 - val_binary_accuracy: 0.9244 - val_false_positives: 492.0000 - val_false_negatives: 490.0000 - val_sensitivity_at_specificity: 0.9983\n",
            "Epoch 15/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1919 - accuracy: 0.9213 - precision: 0.9212 - recall: 0.9210 - binary_accuracy: 0.9211 - false_positives: 2390.0000 - false_negatives: 2396.0000 - sensitivity_at_specificity: 0.9978 - val_loss: 0.1782 - val_accuracy: 0.9294 - val_precision: 0.9294 - val_recall: 0.9292 - val_binary_accuracy: 0.9293 - val_false_positives: 459.0000 - val_false_negatives: 460.0000 - val_sensitivity_at_specificity: 0.9985\n",
            "Epoch 16/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1894 - accuracy: 0.9231 - precision: 0.9234 - recall: 0.9230 - binary_accuracy: 0.9232 - false_positives: 2322.0000 - false_negatives: 2334.0000 - sensitivity_at_specificity: 0.9980 - val_loss: 0.1725 - val_accuracy: 0.9321 - val_precision: 0.9317 - val_recall: 0.9321 - val_binary_accuracy: 0.9319 - val_false_positives: 444.0000 - val_false_negatives: 441.0000 - val_sensitivity_at_specificity: 0.9988\n",
            "Epoch 17/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1884 - accuracy: 0.9243 - precision: 0.9245 - recall: 0.9242 - binary_accuracy: 0.9244 - false_positives: 2288.0000 - false_negatives: 2299.0000 - sensitivity_at_specificity: 0.9982 - val_loss: 0.1703 - val_accuracy: 0.9300 - val_precision: 0.9300 - val_recall: 0.9297 - val_binary_accuracy: 0.9298 - val_false_positives: 455.0000 - val_false_negatives: 457.0000 - val_sensitivity_at_specificity: 0.9986\n",
            "Epoch 18/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.1821 - accuracy: 0.9253 - precision: 0.9254 - recall: 0.9254 - binary_accuracy: 0.9254 - false_positives: 2261.0000 - false_negatives: 2263.0000 - sensitivity_at_specificity: 0.9983 - val_loss: 0.1773 - val_accuracy: 0.9292 - val_precision: 0.9294 - val_recall: 0.9291 - val_binary_accuracy: 0.9292 - val_false_positives: 459.0000 - val_false_negatives: 461.0000 - val_sensitivity_at_specificity: 0.9988\n",
            "Epoch 19/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.1792 - accuracy: 0.9258 - precision: 0.9257 - recall: 0.9261 - binary_accuracy: 0.9259 - false_positives: 2254.0000 - false_negatives: 2242.0000 - sensitivity_at_specificity: 0.9983 - val_loss: 0.1672 - val_accuracy: 0.9305 - val_precision: 0.9303 - val_recall: 0.9309 - val_binary_accuracy: 0.9306 - val_false_positives: 453.0000 - val_false_negatives: 449.0000 - val_sensitivity_at_specificity: 0.9986\n",
            "Epoch 20/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.1775 - accuracy: 0.9279 - precision: 0.9278 - recall: 0.9280 - binary_accuracy: 0.9279 - false_positives: 2191.0000 - false_negatives: 2183.0000 - sensitivity_at_specificity: 0.9982 - val_loss: 0.1663 - val_accuracy: 0.9294 - val_precision: 0.9293 - val_recall: 0.9298 - val_binary_accuracy: 0.9295 - val_false_positives: 460.0000 - val_false_negatives: 456.0000 - val_sensitivity_at_specificity: 0.9989\n",
            "Epoch 21/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.1727 - accuracy: 0.9286 - precision: 0.9288 - recall: 0.9286 - binary_accuracy: 0.9287 - false_positives: 2159.0000 - false_negatives: 2164.0000 - sensitivity_at_specificity: 0.9985 - val_loss: 0.1660 - val_accuracy: 0.9361 - val_precision: 0.9362 - val_recall: 0.9365 - val_binary_accuracy: 0.9363 - val_false_positives: 415.0000 - val_false_negatives: 413.0000 - val_sensitivity_at_specificity: 0.9989\n",
            "Epoch 22/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1695 - accuracy: 0.9311 - precision: 0.9310 - recall: 0.9312 - binary_accuracy: 0.9311 - false_positives: 2093.0000 - false_negatives: 2087.0000 - sensitivity_at_specificity: 0.9989 - val_loss: 0.1618 - val_accuracy: 0.9345 - val_precision: 0.9343 - val_recall: 0.9343 - val_binary_accuracy: 0.9343 - val_false_positives: 427.0000 - val_false_negatives: 427.0000 - val_sensitivity_at_specificity: 0.9989\n",
            "Epoch 23/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.1658 - accuracy: 0.9343 - precision: 0.9343 - recall: 0.9342 - binary_accuracy: 0.9343 - false_positives: 1992.0000 - false_negatives: 1995.0000 - sensitivity_at_specificity: 0.9989 - val_loss: 0.1552 - val_accuracy: 0.9395 - val_precision: 0.9394 - val_recall: 0.9392 - val_binary_accuracy: 0.9393 - val_false_positives: 394.0000 - val_false_negatives: 395.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 24/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.1657 - accuracy: 0.9319 - precision: 0.9321 - recall: 0.9322 - binary_accuracy: 0.9322 - false_positives: 2058.0000 - false_negatives: 2056.0000 - sensitivity_at_specificity: 0.9989 - val_loss: 0.1594 - val_accuracy: 0.9321 - val_precision: 0.9326 - val_recall: 0.9321 - val_binary_accuracy: 0.9324 - val_false_positives: 438.0000 - val_false_negatives: 441.0000 - val_sensitivity_at_specificity: 0.9989\n",
            "Epoch 25/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.1600 - accuracy: 0.9337 - precision: 0.9336 - recall: 0.9340 - binary_accuracy: 0.9338 - false_positives: 2014.0000 - false_negatives: 2001.0000 - sensitivity_at_specificity: 0.9988 - val_loss: 0.1549 - val_accuracy: 0.9354 - val_precision: 0.9357 - val_recall: 0.9355 - val_binary_accuracy: 0.9356 - val_false_positives: 418.0000 - val_false_negatives: 419.0000 - val_sensitivity_at_specificity: 0.9988\n",
            "Test loss: 0.15893147885799408\n",
            "Test accuracy: 0.9361538290977478\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 158, 2, 32)        128       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 79, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 77, 2, 64)         6208      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 38, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2432)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2432)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 4866      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11522 (45.01 KB)\n",
            "Trainable params: 11522 (45.01 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "474/474 [==============================] - 6s 8ms/step - loss: 0.3342 - accuracy: 0.8417 - precision: 0.8410 - recall: 0.8401 - binary_accuracy: 0.8406 - false_positives: 4818.0000 - false_negatives: 4850.0000 - sensitivity_at_specificity: 0.9869 - val_loss: 0.2715 - val_accuracy: 0.8777 - val_precision: 0.8759 - val_recall: 0.8800 - val_binary_accuracy: 0.8777 - val_false_positives: 810.0000 - val_false_negatives: 780.0000 - val_sensitivity_at_specificity: 0.9978\n",
            "Epoch 2/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.2599 - accuracy: 0.8838 - precision: 0.8835 - recall: 0.8828 - binary_accuracy: 0.8832 - false_positives: 3531.0000 - false_negatives: 3554.0000 - sensitivity_at_specificity: 0.9965 - val_loss: 0.2269 - val_accuracy: 0.9004 - val_precision: 0.9027 - val_recall: 0.8983 - val_binary_accuracy: 0.9008 - val_false_positives: 629.0000 - val_false_negatives: 661.0000 - val_sensitivity_at_specificity: 0.9974\n",
            "Epoch 3/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.2316 - accuracy: 0.8996 - precision: 0.8992 - recall: 0.8989 - binary_accuracy: 0.8991 - false_positives: 3056.0000 - false_negatives: 3066.0000 - sensitivity_at_specificity: 0.9970 - val_loss: 0.2067 - val_accuracy: 0.9097 - val_precision: 0.9103 - val_recall: 0.9092 - val_binary_accuracy: 0.9098 - val_false_positives: 582.0000 - val_false_negatives: 590.0000 - val_sensitivity_at_specificity: 0.9983\n",
            "Epoch 4/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.2177 - accuracy: 0.9062 - precision: 0.9068 - recall: 0.9062 - binary_accuracy: 0.9065 - false_positives: 2825.0000 - false_negatives: 2846.0000 - sensitivity_at_specificity: 0.9972 - val_loss: 0.1982 - val_accuracy: 0.9129 - val_precision: 0.9122 - val_recall: 0.9134 - val_binary_accuracy: 0.9128 - val_false_positives: 571.0000 - val_false_negatives: 563.0000 - val_sensitivity_at_specificity: 0.9982\n",
            "Epoch 5/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.2062 - accuracy: 0.9131 - precision: 0.9131 - recall: 0.9131 - binary_accuracy: 0.9131 - false_positives: 2637.0000 - false_negatives: 2637.0000 - sensitivity_at_specificity: 0.9974 - val_loss: 0.1826 - val_accuracy: 0.9274 - val_precision: 0.9266 - val_recall: 0.9280 - val_binary_accuracy: 0.9272 - val_false_positives: 478.0000 - val_false_negatives: 468.0000 - val_sensitivity_at_specificity: 0.9989\n",
            "Epoch 6/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1963 - accuracy: 0.9185 - precision: 0.9186 - recall: 0.9185 - binary_accuracy: 0.9186 - false_positives: 2468.0000 - false_negatives: 2472.0000 - sensitivity_at_specificity: 0.9980 - val_loss: 0.1777 - val_accuracy: 0.9221 - val_precision: 0.9222 - val_recall: 0.9223 - val_binary_accuracy: 0.9222 - val_false_positives: 506.0000 - val_false_negatives: 505.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 7/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1880 - accuracy: 0.9216 - precision: 0.9215 - recall: 0.9219 - binary_accuracy: 0.9217 - false_positives: 2382.0000 - false_negatives: 2368.0000 - sensitivity_at_specificity: 0.9984 - val_loss: 0.1674 - val_accuracy: 0.9331 - val_precision: 0.9330 - val_recall: 0.9325 - val_binary_accuracy: 0.9328 - val_false_positives: 435.0000 - val_false_negatives: 439.0000 - val_sensitivity_at_specificity: 0.9986\n",
            "Epoch 8/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1834 - accuracy: 0.9254 - precision: 0.9250 - recall: 0.9253 - binary_accuracy: 0.9251 - false_positives: 2276.0000 - false_negatives: 2266.0000 - sensitivity_at_specificity: 0.9983 - val_loss: 0.1645 - val_accuracy: 0.9311 - val_precision: 0.9311 - val_recall: 0.9311 - val_binary_accuracy: 0.9311 - val_false_positives: 448.0000 - val_false_negatives: 448.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 9/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1745 - accuracy: 0.9300 - precision: 0.9298 - recall: 0.9300 - binary_accuracy: 0.9299 - false_positives: 2128.0000 - false_negatives: 2122.0000 - sensitivity_at_specificity: 0.9983 - val_loss: 0.1586 - val_accuracy: 0.9354 - val_precision: 0.9358 - val_recall: 0.9355 - val_binary_accuracy: 0.9357 - val_false_positives: 417.0000 - val_false_negatives: 419.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 10/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1693 - accuracy: 0.9324 - precision: 0.9326 - recall: 0.9320 - binary_accuracy: 0.9323 - false_positives: 2043.0000 - false_negatives: 2062.0000 - sensitivity_at_specificity: 0.9989 - val_loss: 0.1593 - val_accuracy: 0.9337 - val_precision: 0.9334 - val_recall: 0.9335 - val_binary_accuracy: 0.9335 - val_false_positives: 433.0000 - val_false_negatives: 432.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 11/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.1657 - accuracy: 0.9341 - precision: 0.9341 - recall: 0.9341 - binary_accuracy: 0.9341 - false_positives: 2000.0000 - false_negatives: 1998.0000 - sensitivity_at_specificity: 0.9986 - val_loss: 0.1496 - val_accuracy: 0.9398 - val_precision: 0.9397 - val_recall: 0.9400 - val_binary_accuracy: 0.9398 - val_false_positives: 392.0000 - val_false_negatives: 390.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 12/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.1609 - accuracy: 0.9368 - precision: 0.9370 - recall: 0.9369 - binary_accuracy: 0.9369 - false_positives: 1911.0000 - false_negatives: 1915.0000 - sensitivity_at_specificity: 0.9991 - val_loss: 0.1470 - val_accuracy: 0.9395 - val_precision: 0.9397 - val_recall: 0.9394 - val_binary_accuracy: 0.9395 - val_false_positives: 392.0000 - val_false_negatives: 394.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 13/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1581 - accuracy: 0.9357 - precision: 0.9354 - recall: 0.9358 - binary_accuracy: 0.9356 - false_positives: 1959.0000 - false_negatives: 1947.0000 - sensitivity_at_specificity: 0.9989 - val_loss: 0.1488 - val_accuracy: 0.9369 - val_precision: 0.9366 - val_recall: 0.9372 - val_binary_accuracy: 0.9369 - val_false_positives: 412.0000 - val_false_negatives: 408.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 14/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1537 - accuracy: 0.9384 - precision: 0.9381 - recall: 0.9381 - binary_accuracy: 0.9381 - false_positives: 1878.0000 - false_negatives: 1876.0000 - sensitivity_at_specificity: 0.9988 - val_loss: 0.1399 - val_accuracy: 0.9428 - val_precision: 0.9420 - val_recall: 0.9426 - val_binary_accuracy: 0.9423 - val_false_positives: 377.0000 - val_false_negatives: 373.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 15/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1503 - accuracy: 0.9396 - precision: 0.9398 - recall: 0.9397 - binary_accuracy: 0.9397 - false_positives: 1827.0000 - false_negatives: 1830.0000 - sensitivity_at_specificity: 0.9992 - val_loss: 0.1372 - val_accuracy: 0.9445 - val_precision: 0.9443 - val_recall: 0.9448 - val_binary_accuracy: 0.9445 - val_false_positives: 362.0000 - val_false_negatives: 359.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 16/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.1451 - accuracy: 0.9414 - precision: 0.9414 - recall: 0.9414 - binary_accuracy: 0.9414 - false_positives: 1778.0000 - false_negatives: 1778.0000 - sensitivity_at_specificity: 0.9993 - val_loss: 0.1327 - val_accuracy: 0.9472 - val_precision: 0.9469 - val_recall: 0.9475 - val_binary_accuracy: 0.9472 - val_false_positives: 345.0000 - val_false_negatives: 341.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 17/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1444 - accuracy: 0.9420 - precision: 0.9418 - recall: 0.9421 - binary_accuracy: 0.9420 - false_positives: 1766.0000 - false_negatives: 1755.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.1343 - val_accuracy: 0.9457 - val_precision: 0.9458 - val_recall: 0.9454 - val_binary_accuracy: 0.9456 - val_false_positives: 352.0000 - val_false_negatives: 355.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 18/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1392 - accuracy: 0.9438 - precision: 0.9439 - recall: 0.9439 - binary_accuracy: 0.9439 - false_positives: 1702.0000 - false_negatives: 1700.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.1279 - val_accuracy: 0.9512 - val_precision: 0.9515 - val_recall: 0.9515 - val_binary_accuracy: 0.9515 - val_false_positives: 315.0000 - val_false_negatives: 315.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 19/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1350 - accuracy: 0.9444 - precision: 0.9443 - recall: 0.9441 - binary_accuracy: 0.9442 - false_positives: 1689.0000 - false_negatives: 1695.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.1317 - val_accuracy: 0.9437 - val_precision: 0.9438 - val_recall: 0.9440 - val_binary_accuracy: 0.9439 - val_false_positives: 365.0000 - val_false_negatives: 364.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 20/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1357 - accuracy: 0.9463 - precision: 0.9462 - recall: 0.9463 - binary_accuracy: 0.9462 - false_positives: 1632.0000 - false_negatives: 1630.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.1313 - val_accuracy: 0.9451 - val_precision: 0.9449 - val_recall: 0.9454 - val_binary_accuracy: 0.9451 - val_false_positives: 358.0000 - val_false_negatives: 355.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 21/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.1330 - accuracy: 0.9461 - precision: 0.9461 - recall: 0.9464 - binary_accuracy: 0.9462 - false_positives: 1635.0000 - false_negatives: 1627.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.1246 - val_accuracy: 0.9495 - val_precision: 0.9497 - val_recall: 0.9497 - val_binary_accuracy: 0.9497 - val_false_positives: 327.0000 - val_false_negatives: 327.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 22/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1302 - accuracy: 0.9480 - precision: 0.9478 - recall: 0.9478 - binary_accuracy: 0.9478 - false_positives: 1583.0000 - false_negatives: 1583.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.1220 - val_accuracy: 0.9511 - val_precision: 0.9512 - val_recall: 0.9511 - val_binary_accuracy: 0.9511 - val_false_positives: 317.0000 - val_false_negatives: 318.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 23/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1281 - accuracy: 0.9486 - precision: 0.9488 - recall: 0.9486 - binary_accuracy: 0.9487 - false_positives: 1552.0000 - false_negatives: 1558.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.1245 - val_accuracy: 0.9486 - val_precision: 0.9485 - val_recall: 0.9491 - val_binary_accuracy: 0.9488 - val_false_positives: 335.0000 - val_false_negatives: 331.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 24/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.1274 - accuracy: 0.9503 - precision: 0.9505 - recall: 0.9503 - binary_accuracy: 0.9504 - false_positives: 1501.0000 - false_negatives: 1507.0000 - sensitivity_at_specificity: 0.9993 - val_loss: 0.1171 - val_accuracy: 0.9528 - val_precision: 0.9528 - val_recall: 0.9528 - val_binary_accuracy: 0.9528 - val_false_positives: 307.0000 - val_false_negatives: 307.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 25/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.1256 - accuracy: 0.9497 - precision: 0.9496 - recall: 0.9498 - binary_accuracy: 0.9497 - false_positives: 1530.0000 - false_negatives: 1523.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.1170 - val_accuracy: 0.9548 - val_precision: 0.9548 - val_recall: 0.9549 - val_binary_accuracy: 0.9548 - val_false_positives: 294.0000 - val_false_negatives: 293.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Test loss: 0.11355171352624893\n",
            "Test accuracy: 0.9559999704360962\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 157, 2, 32)        160       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 78, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 75, 2, 64)         8256      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 37, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2368)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2368)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 4738      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13474 (52.63 KB)\n",
            "Trainable params: 13474 (52.63 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "474/474 [==============================] - 6s 8ms/step - loss: 0.3190 - accuracy: 0.8514 - precision: 0.8499 - recall: 0.8507 - binary_accuracy: 0.8503 - false_positives: 4555.0000 - false_negatives: 4527.0000 - sensitivity_at_specificity: 0.9899 - val_loss: 0.2488 - val_accuracy: 0.8909 - val_precision: 0.8907 - val_recall: 0.8892 - val_binary_accuracy: 0.8901 - val_false_positives: 709.0000 - val_false_negatives: 720.0000 - val_sensitivity_at_specificity: 0.9971\n",
            "Epoch 2/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.2406 - accuracy: 0.8940 - precision: 0.8935 - recall: 0.8941 - binary_accuracy: 0.8938 - false_positives: 3233.0000 - false_negatives: 3211.0000 - sensitivity_at_specificity: 0.9966 - val_loss: 0.2049 - val_accuracy: 0.9103 - val_precision: 0.9109 - val_recall: 0.9104 - val_binary_accuracy: 0.9107 - val_false_positives: 579.0000 - val_false_negatives: 582.0000 - val_sensitivity_at_specificity: 0.9986\n",
            "Epoch 3/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.2122 - accuracy: 0.9086 - precision: 0.9085 - recall: 0.9091 - binary_accuracy: 0.9088 - false_positives: 2777.0000 - false_negatives: 2756.0000 - sensitivity_at_specificity: 0.9976 - val_loss: 0.1975 - val_accuracy: 0.9123 - val_precision: 0.9121 - val_recall: 0.9120 - val_binary_accuracy: 0.9121 - val_false_positives: 571.0000 - val_false_negatives: 572.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 4/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.1975 - accuracy: 0.9155 - precision: 0.9152 - recall: 0.9152 - binary_accuracy: 0.9152 - false_positives: 2571.0000 - false_negatives: 2572.0000 - sensitivity_at_specificity: 0.9984 - val_loss: 0.1753 - val_accuracy: 0.9244 - val_precision: 0.9234 - val_recall: 0.9252 - val_binary_accuracy: 0.9242 - val_false_positives: 499.0000 - val_false_negatives: 486.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 5/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1841 - accuracy: 0.9245 - precision: 0.9244 - recall: 0.9243 - binary_accuracy: 0.9243 - false_positives: 2293.0000 - false_negatives: 2297.0000 - sensitivity_at_specificity: 0.9982 - val_loss: 0.1623 - val_accuracy: 0.9355 - val_precision: 0.9359 - val_recall: 0.9348 - val_binary_accuracy: 0.9354 - val_false_positives: 416.0000 - val_false_negatives: 424.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 6/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1706 - accuracy: 0.9311 - precision: 0.9304 - recall: 0.9314 - binary_accuracy: 0.9309 - false_positives: 2112.0000 - false_negatives: 2081.0000 - sensitivity_at_specificity: 0.9985 - val_loss: 0.1504 - val_accuracy: 0.9386 - val_precision: 0.9386 - val_recall: 0.9381 - val_binary_accuracy: 0.9384 - val_false_positives: 399.0000 - val_false_negatives: 402.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 7/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.1621 - accuracy: 0.9350 - precision: 0.9349 - recall: 0.9349 - binary_accuracy: 0.9349 - false_positives: 1976.0000 - false_negatives: 1973.0000 - sensitivity_at_specificity: 0.9991 - val_loss: 0.1459 - val_accuracy: 0.9383 - val_precision: 0.9381 - val_recall: 0.9378 - val_binary_accuracy: 0.9380 - val_false_positives: 402.0000 - val_false_negatives: 404.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 8/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.1512 - accuracy: 0.9390 - precision: 0.9389 - recall: 0.9389 - binary_accuracy: 0.9389 - false_positives: 1854.0000 - false_negatives: 1854.0000 - sensitivity_at_specificity: 0.9991 - val_loss: 0.1431 - val_accuracy: 0.9408 - val_precision: 0.9400 - val_recall: 0.9406 - val_binary_accuracy: 0.9403 - val_false_positives: 390.0000 - val_false_negatives: 386.0000 - val_sensitivity_at_specificity: 1.0000\n",
            "Epoch 9/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.1475 - accuracy: 0.9418 - precision: 0.9418 - recall: 0.9419 - binary_accuracy: 0.9419 - false_positives: 1765.0000 - false_negatives: 1761.0000 - sensitivity_at_specificity: 0.9992 - val_loss: 0.1300 - val_accuracy: 0.9465 - val_precision: 0.9467 - val_recall: 0.9463 - val_binary_accuracy: 0.9465 - val_false_positives: 346.0000 - val_false_negatives: 349.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 10/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1380 - accuracy: 0.9459 - precision: 0.9462 - recall: 0.9459 - binary_accuracy: 0.9460 - false_positives: 1632.0000 - false_negatives: 1642.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.1286 - val_accuracy: 0.9491 - val_precision: 0.9489 - val_recall: 0.9494 - val_binary_accuracy: 0.9491 - val_false_positives: 332.0000 - val_false_negatives: 329.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 11/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1351 - accuracy: 0.9473 - precision: 0.9473 - recall: 0.9471 - binary_accuracy: 0.9472 - false_positives: 1598.0000 - false_negatives: 1603.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.1204 - val_accuracy: 0.9525 - val_precision: 0.9526 - val_recall: 0.9523 - val_binary_accuracy: 0.9525 - val_false_positives: 308.0000 - val_false_negatives: 310.0000 - val_sensitivity_at_specificity: 1.0000\n",
            "Epoch 12/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.1298 - accuracy: 0.9483 - precision: 0.9484 - recall: 0.9486 - binary_accuracy: 0.9485 - false_positives: 1566.0000 - false_negatives: 1558.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.1181 - val_accuracy: 0.9512 - val_precision: 0.9512 - val_recall: 0.9511 - val_binary_accuracy: 0.9511 - val_false_positives: 317.0000 - val_false_negatives: 318.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 13/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.1262 - accuracy: 0.9495 - precision: 0.9495 - recall: 0.9497 - binary_accuracy: 0.9496 - false_positives: 1532.0000 - false_negatives: 1526.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.1131 - val_accuracy: 0.9566 - val_precision: 0.9565 - val_recall: 0.9568 - val_binary_accuracy: 0.9566 - val_false_positives: 283.0000 - val_false_negatives: 281.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 14/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1241 - accuracy: 0.9509 - precision: 0.9512 - recall: 0.9509 - binary_accuracy: 0.9511 - false_positives: 1479.0000 - false_negatives: 1490.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.1117 - val_accuracy: 0.9566 - val_precision: 0.9557 - val_recall: 0.9568 - val_binary_accuracy: 0.9562 - val_false_positives: 288.0000 - val_false_negatives: 281.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 15/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1173 - accuracy: 0.9543 - precision: 0.9542 - recall: 0.9544 - binary_accuracy: 0.9543 - false_positives: 1389.0000 - false_negatives: 1383.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.1083 - val_accuracy: 0.9575 - val_precision: 0.9575 - val_recall: 0.9571 - val_binary_accuracy: 0.9573 - val_false_positives: 276.0000 - val_false_negatives: 279.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 16/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.1164 - accuracy: 0.9542 - precision: 0.9541 - recall: 0.9540 - binary_accuracy: 0.9541 - false_positives: 1393.0000 - false_negatives: 1394.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.1102 - val_accuracy: 0.9535 - val_precision: 0.9538 - val_recall: 0.9537 - val_binary_accuracy: 0.9538 - val_false_positives: 300.0000 - val_false_negatives: 301.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 17/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.1130 - accuracy: 0.9544 - precision: 0.9541 - recall: 0.9545 - binary_accuracy: 0.9543 - false_positives: 1393.0000 - false_negatives: 1381.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.1055 - val_accuracy: 0.9594 - val_precision: 0.9592 - val_recall: 0.9591 - val_binary_accuracy: 0.9591 - val_false_positives: 265.0000 - val_false_negatives: 266.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 18/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.1098 - accuracy: 0.9562 - precision: 0.9562 - recall: 0.9561 - binary_accuracy: 0.9562 - false_positives: 1329.0000 - false_negatives: 1330.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.1070 - val_accuracy: 0.9551 - val_precision: 0.9551 - val_recall: 0.9552 - val_binary_accuracy: 0.9551 - val_false_positives: 292.0000 - val_false_negatives: 291.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 19/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1119 - accuracy: 0.9557 - precision: 0.9556 - recall: 0.9558 - binary_accuracy: 0.9557 - false_positives: 1347.0000 - false_negatives: 1342.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.1004 - val_accuracy: 0.9597 - val_precision: 0.9596 - val_recall: 0.9600 - val_binary_accuracy: 0.9598 - val_false_positives: 263.0000 - val_false_negatives: 260.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 20/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1080 - accuracy: 0.9578 - precision: 0.9577 - recall: 0.9578 - binary_accuracy: 0.9578 - false_positives: 1282.0000 - false_negatives: 1280.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.1016 - val_accuracy: 0.9601 - val_precision: 0.9600 - val_recall: 0.9598 - val_binary_accuracy: 0.9599 - val_false_positives: 260.0000 - val_false_negatives: 261.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 21/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.1056 - accuracy: 0.9597 - precision: 0.9595 - recall: 0.9597 - binary_accuracy: 0.9596 - false_positives: 1227.0000 - false_negatives: 1223.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.1023 - val_accuracy: 0.9603 - val_precision: 0.9606 - val_recall: 0.9603 - val_binary_accuracy: 0.9605 - val_false_positives: 256.0000 - val_false_negatives: 258.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 22/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.1020 - accuracy: 0.9598 - precision: 0.9600 - recall: 0.9599 - binary_accuracy: 0.9599 - false_positives: 1213.0000 - false_negatives: 1217.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0972 - val_accuracy: 0.9640 - val_precision: 0.9640 - val_recall: 0.9640 - val_binary_accuracy: 0.9640 - val_false_positives: 234.0000 - val_false_negatives: 234.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 23/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.0994 - accuracy: 0.9603 - precision: 0.9604 - recall: 0.9603 - binary_accuracy: 0.9603 - false_positives: 1202.0000 - false_negatives: 1205.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0965 - val_accuracy: 0.9626 - val_precision: 0.9628 - val_recall: 0.9626 - val_binary_accuracy: 0.9627 - val_false_positives: 242.0000 - val_false_negatives: 243.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 24/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1002 - accuracy: 0.9608 - precision: 0.9608 - recall: 0.9608 - binary_accuracy: 0.9608 - false_positives: 1189.0000 - false_negatives: 1190.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0977 - val_accuracy: 0.9614 - val_precision: 0.9611 - val_recall: 0.9612 - val_binary_accuracy: 0.9611 - val_false_positives: 253.0000 - val_false_negatives: 252.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 25/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.0960 - accuracy: 0.9636 - precision: 0.9635 - recall: 0.9635 - binary_accuracy: 0.9635 - false_positives: 1107.0000 - false_negatives: 1108.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0948 - val_accuracy: 0.9631 - val_precision: 0.9631 - val_recall: 0.9631 - val_binary_accuracy: 0.9631 - val_false_positives: 240.0000 - val_false_negatives: 240.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Test loss: 0.0896405577659607\n",
            "Test accuracy: 0.9658461809158325\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 156, 2, 32)        192       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 78, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 74, 2, 64)         10304     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 37, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2368)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2368)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 4738      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15554 (60.76 KB)\n",
            "Trainable params: 15554 (60.76 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "474/474 [==============================] - 6s 8ms/step - loss: 0.3137 - accuracy: 0.8533 - precision: 0.8525 - recall: 0.8515 - binary_accuracy: 0.8521 - false_positives: 4469.0000 - false_negatives: 4505.0000 - sensitivity_at_specificity: 0.9916 - val_loss: 0.2433 - val_accuracy: 0.8920 - val_precision: 0.8955 - val_recall: 0.8871 - val_binary_accuracy: 0.8918 - val_false_positives: 673.0000 - val_false_negatives: 734.0000 - val_sensitivity_at_specificity: 0.9989\n",
            "Epoch 2/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.2304 - accuracy: 0.8968 - precision: 0.8959 - recall: 0.8965 - binary_accuracy: 0.8962 - false_positives: 3158.0000 - false_negatives: 3140.0000 - sensitivity_at_specificity: 0.9981 - val_loss: 0.1980 - val_accuracy: 0.9126 - val_precision: 0.9132 - val_recall: 0.9114 - val_binary_accuracy: 0.9124 - val_false_positives: 563.0000 - val_false_negatives: 576.0000 - val_sensitivity_at_specificity: 1.0000\n",
            "Epoch 3/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1969 - accuracy: 0.9152 - precision: 0.9146 - recall: 0.9158 - binary_accuracy: 0.9151 - false_positives: 2594.0000 - false_negatives: 2553.0000 - sensitivity_at_specificity: 0.9988 - val_loss: 0.1861 - val_accuracy: 0.9175 - val_precision: 0.9176 - val_recall: 0.9169 - val_binary_accuracy: 0.9173 - val_false_positives: 535.0000 - val_false_negatives: 540.0000 - val_sensitivity_at_specificity: 1.0000\n",
            "Epoch 4/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.1763 - accuracy: 0.9265 - precision: 0.9263 - recall: 0.9264 - binary_accuracy: 0.9264 - false_positives: 2234.0000 - false_negatives: 2231.0000 - sensitivity_at_specificity: 0.9989 - val_loss: 0.1546 - val_accuracy: 0.9365 - val_precision: 0.9361 - val_recall: 0.9371 - val_binary_accuracy: 0.9365 - val_false_positives: 416.0000 - val_false_negatives: 409.0000 - val_sensitivity_at_specificity: 1.0000\n",
            "Epoch 5/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1635 - accuracy: 0.9324 - precision: 0.9324 - recall: 0.9319 - binary_accuracy: 0.9322 - false_positives: 2050.0000 - false_negatives: 2064.0000 - sensitivity_at_specificity: 0.9991 - val_loss: 0.1440 - val_accuracy: 0.9431 - val_precision: 0.9433 - val_recall: 0.9429 - val_binary_accuracy: 0.9431 - val_false_positives: 368.0000 - val_false_negatives: 371.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 6/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1529 - accuracy: 0.9381 - precision: 0.9381 - recall: 0.9384 - binary_accuracy: 0.9383 - false_positives: 1878.0000 - false_negatives: 1867.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.1350 - val_accuracy: 0.9468 - val_precision: 0.9469 - val_recall: 0.9460 - val_binary_accuracy: 0.9465 - val_false_positives: 345.0000 - val_false_negatives: 351.0000 - val_sensitivity_at_specificity: 1.0000\n",
            "Epoch 7/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1444 - accuracy: 0.9420 - precision: 0.9419 - recall: 0.9416 - binary_accuracy: 0.9417 - false_positives: 1763.0000 - false_negatives: 1771.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.1308 - val_accuracy: 0.9466 - val_precision: 0.9468 - val_recall: 0.9469 - val_binary_accuracy: 0.9468 - val_false_positives: 346.0000 - val_false_negatives: 345.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 8/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1382 - accuracy: 0.9459 - precision: 0.9458 - recall: 0.9456 - binary_accuracy: 0.9457 - false_positives: 1643.0000 - false_negatives: 1651.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.1254 - val_accuracy: 0.9501 - val_precision: 0.9502 - val_recall: 0.9503 - val_binary_accuracy: 0.9502 - val_false_positives: 324.0000 - val_false_negatives: 323.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 9/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1311 - accuracy: 0.9476 - precision: 0.9479 - recall: 0.9474 - binary_accuracy: 0.9477 - false_positives: 1578.0000 - false_negatives: 1594.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.1289 - val_accuracy: 0.9441 - val_precision: 0.9442 - val_recall: 0.9446 - val_binary_accuracy: 0.9444 - val_false_positives: 363.0000 - val_false_negatives: 360.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 10/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1244 - accuracy: 0.9508 - precision: 0.9510 - recall: 0.9511 - binary_accuracy: 0.9511 - false_positives: 1485.0000 - false_negatives: 1483.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.1259 - val_accuracy: 0.9500 - val_precision: 0.9500 - val_recall: 0.9494 - val_binary_accuracy: 0.9497 - val_false_positives: 325.0000 - val_false_negatives: 329.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 11/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1217 - accuracy: 0.9521 - precision: 0.9519 - recall: 0.9521 - binary_accuracy: 0.9520 - false_positives: 1458.0000 - false_negatives: 1454.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.1133 - val_accuracy: 0.9535 - val_precision: 0.9537 - val_recall: 0.9535 - val_binary_accuracy: 0.9536 - val_false_positives: 301.0000 - val_false_negatives: 302.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 12/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1170 - accuracy: 0.9546 - precision: 0.9544 - recall: 0.9546 - binary_accuracy: 0.9545 - false_positives: 1382.0000 - false_negatives: 1378.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.1073 - val_accuracy: 0.9558 - val_precision: 0.9558 - val_recall: 0.9554 - val_binary_accuracy: 0.9556 - val_false_positives: 287.0000 - val_false_negatives: 290.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 13/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1124 - accuracy: 0.9546 - precision: 0.9548 - recall: 0.9547 - binary_accuracy: 0.9547 - false_positives: 1372.0000 - false_negatives: 1375.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.1062 - val_accuracy: 0.9572 - val_precision: 0.9574 - val_recall: 0.9572 - val_binary_accuracy: 0.9573 - val_false_positives: 277.0000 - val_false_negatives: 278.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 14/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.1092 - accuracy: 0.9563 - precision: 0.9564 - recall: 0.9562 - binary_accuracy: 0.9563 - false_positives: 1322.0000 - false_negatives: 1328.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.1044 - val_accuracy: 0.9580 - val_precision: 0.9577 - val_recall: 0.9580 - val_binary_accuracy: 0.9578 - val_false_positives: 275.0000 - val_false_negatives: 273.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 15/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1082 - accuracy: 0.9565 - precision: 0.9568 - recall: 0.9565 - binary_accuracy: 0.9567 - false_positives: 1311.0000 - false_negatives: 1318.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.1052 - val_accuracy: 0.9580 - val_precision: 0.9579 - val_recall: 0.9581 - val_binary_accuracy: 0.9580 - val_false_positives: 274.0000 - val_false_negatives: 272.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 16/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1057 - accuracy: 0.9579 - precision: 0.9579 - recall: 0.9578 - binary_accuracy: 0.9578 - false_positives: 1278.0000 - false_negatives: 1279.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0977 - val_accuracy: 0.9603 - val_precision: 0.9602 - val_recall: 0.9603 - val_binary_accuracy: 0.9602 - val_false_positives: 259.0000 - val_false_negatives: 258.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 17/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1030 - accuracy: 0.9584 - precision: 0.9582 - recall: 0.9584 - binary_accuracy: 0.9583 - false_positives: 1267.0000 - false_negatives: 1262.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0976 - val_accuracy: 0.9598 - val_precision: 0.9598 - val_recall: 0.9600 - val_binary_accuracy: 0.9599 - val_false_positives: 261.0000 - val_false_negatives: 260.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 18/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0999 - accuracy: 0.9608 - precision: 0.9607 - recall: 0.9611 - binary_accuracy: 0.9609 - false_positives: 1193.0000 - false_negatives: 1180.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0989 - val_accuracy: 0.9609 - val_precision: 0.9609 - val_recall: 0.9609 - val_binary_accuracy: 0.9609 - val_false_positives: 254.0000 - val_false_negatives: 254.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 19/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0995 - accuracy: 0.9613 - precision: 0.9614 - recall: 0.9614 - binary_accuracy: 0.9614 - false_positives: 1172.0000 - false_negatives: 1170.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0961 - val_accuracy: 0.9608 - val_precision: 0.9606 - val_recall: 0.9608 - val_binary_accuracy: 0.9607 - val_false_positives: 256.0000 - val_false_negatives: 255.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 20/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0980 - accuracy: 0.9605 - precision: 0.9606 - recall: 0.9606 - binary_accuracy: 0.9606 - false_positives: 1196.0000 - false_negatives: 1195.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0942 - val_accuracy: 0.9608 - val_precision: 0.9609 - val_recall: 0.9608 - val_binary_accuracy: 0.9608 - val_false_positives: 254.0000 - val_false_negatives: 255.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 21/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0920 - accuracy: 0.9647 - precision: 0.9648 - recall: 0.9645 - binary_accuracy: 0.9647 - false_positives: 1068.0000 - false_negatives: 1076.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0907 - val_accuracy: 0.9646 - val_precision: 0.9646 - val_recall: 0.9646 - val_binary_accuracy: 0.9646 - val_false_positives: 230.0000 - val_false_negatives: 230.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 22/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.0956 - accuracy: 0.9628 - precision: 0.9627 - recall: 0.9627 - binary_accuracy: 0.9627 - false_positives: 1131.0000 - false_negatives: 1132.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.1021 - val_accuracy: 0.9597 - val_precision: 0.9595 - val_recall: 0.9595 - val_binary_accuracy: 0.9595 - val_false_positives: 263.0000 - val_false_negatives: 263.0000 - val_sensitivity_at_specificity: 0.9988\n",
            "Epoch 23/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.0910 - accuracy: 0.9660 - precision: 0.9660 - recall: 0.9660 - binary_accuracy: 0.9660 - false_positives: 1032.0000 - false_negatives: 1032.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0959 - val_accuracy: 0.9606 - val_precision: 0.9604 - val_recall: 0.9603 - val_binary_accuracy: 0.9604 - val_false_positives: 257.0000 - val_false_negatives: 258.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 24/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.0928 - accuracy: 0.9637 - precision: 0.9637 - recall: 0.9636 - binary_accuracy: 0.9636 - false_positives: 1102.0000 - false_negatives: 1103.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0907 - val_accuracy: 0.9621 - val_precision: 0.9622 - val_recall: 0.9623 - val_binary_accuracy: 0.9622 - val_false_positives: 246.0000 - val_false_negatives: 245.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 25/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0902 - accuracy: 0.9645 - precision: 0.9645 - recall: 0.9646 - binary_accuracy: 0.9646 - false_positives: 1076.0000 - false_negatives: 1074.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0958 - val_accuracy: 0.9617 - val_precision: 0.9620 - val_recall: 0.9617 - val_binary_accuracy: 0.9618 - val_false_positives: 247.0000 - val_false_negatives: 249.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Test loss: 0.08441269397735596\n",
            "Test accuracy: 0.9709230661392212\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 155, 2, 32)        224       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 77, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 72, 2, 64)         12352     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 36, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2304)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2304)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 4610      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17506 (68.38 KB)\n",
            "Trainable params: 17506 (68.38 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "474/474 [==============================] - 6s 8ms/step - loss: 0.3147 - accuracy: 0.8515 - precision: 0.8510 - recall: 0.8510 - binary_accuracy: 0.8510 - false_positives: 4520.0000 - false_negatives: 4518.0000 - sensitivity_at_specificity: 0.9906 - val_loss: 0.2529 - val_accuracy: 0.8824 - val_precision: 0.8803 - val_recall: 0.8838 - val_binary_accuracy: 0.8818 - val_false_positives: 781.0000 - val_false_negatives: 755.0000 - val_sensitivity_at_specificity: 0.9978\n",
            "Epoch 2/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.2245 - accuracy: 0.9010 - precision: 0.9005 - recall: 0.9001 - binary_accuracy: 0.9003 - false_positives: 3017.0000 - false_negatives: 3029.0000 - sensitivity_at_specificity: 0.9977 - val_loss: 0.1948 - val_accuracy: 0.9092 - val_precision: 0.9100 - val_recall: 0.9088 - val_binary_accuracy: 0.9094 - val_false_positives: 584.0000 - val_false_negatives: 593.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 3/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1933 - accuracy: 0.9182 - precision: 0.9182 - recall: 0.9180 - binary_accuracy: 0.9181 - false_positives: 2480.0000 - false_negatives: 2487.0000 - sensitivity_at_specificity: 0.9985 - val_loss: 0.1584 - val_accuracy: 0.9301 - val_precision: 0.9306 - val_recall: 0.9301 - val_binary_accuracy: 0.9304 - val_false_positives: 451.0000 - val_false_negatives: 454.0000 - val_sensitivity_at_specificity: 1.0000\n",
            "Epoch 4/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1699 - accuracy: 0.9297 - precision: 0.9295 - recall: 0.9295 - binary_accuracy: 0.9295 - false_positives: 2138.0000 - false_negatives: 2137.0000 - sensitivity_at_specificity: 0.9989 - val_loss: 0.1413 - val_accuracy: 0.9423 - val_precision: 0.9414 - val_recall: 0.9423 - val_binary_accuracy: 0.9418 - val_false_positives: 381.0000 - val_false_negatives: 375.0000 - val_sensitivity_at_specificity: 1.0000\n",
            "Epoch 5/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.1521 - accuracy: 0.9379 - precision: 0.9378 - recall: 0.9378 - binary_accuracy: 0.9378 - false_positives: 1885.0000 - false_negatives: 1885.0000 - sensitivity_at_specificity: 0.9993 - val_loss: 0.1300 - val_accuracy: 0.9488 - val_precision: 0.9488 - val_recall: 0.9489 - val_binary_accuracy: 0.9488 - val_false_positives: 333.0000 - val_false_negatives: 332.0000 - val_sensitivity_at_specificity: 1.0000\n",
            "Epoch 6/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.1393 - accuracy: 0.9436 - precision: 0.9437 - recall: 0.9436 - binary_accuracy: 0.9437 - false_positives: 1708.0000 - false_negatives: 1709.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.1266 - val_accuracy: 0.9465 - val_precision: 0.9455 - val_recall: 0.9472 - val_binary_accuracy: 0.9463 - val_false_positives: 355.0000 - val_false_negatives: 343.0000 - val_sensitivity_at_specificity: 1.0000\n",
            "Epoch 7/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.1287 - accuracy: 0.9493 - precision: 0.9496 - recall: 0.9497 - binary_accuracy: 0.9497 - false_positives: 1529.0000 - false_negatives: 1524.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.1114 - val_accuracy: 0.9538 - val_precision: 0.9534 - val_recall: 0.9541 - val_binary_accuracy: 0.9538 - val_false_positives: 303.0000 - val_false_negatives: 298.0000 - val_sensitivity_at_specificity: 1.0000\n",
            "Epoch 8/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1224 - accuracy: 0.9515 - precision: 0.9517 - recall: 0.9517 - binary_accuracy: 0.9517 - false_positives: 1465.0000 - false_negatives: 1465.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.1024 - val_accuracy: 0.9581 - val_precision: 0.9584 - val_recall: 0.9581 - val_binary_accuracy: 0.9583 - val_false_positives: 270.0000 - val_false_negatives: 272.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 9/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1140 - accuracy: 0.9554 - precision: 0.9553 - recall: 0.9554 - binary_accuracy: 0.9553 - false_positives: 1356.0000 - false_negatives: 1354.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.1044 - val_accuracy: 0.9595 - val_precision: 0.9594 - val_recall: 0.9598 - val_binary_accuracy: 0.9596 - val_false_positives: 264.0000 - val_false_negatives: 261.0000 - val_sensitivity_at_specificity: 1.0000\n",
            "Epoch 10/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1084 - accuracy: 0.9568 - precision: 0.9569 - recall: 0.9570 - binary_accuracy: 0.9569 - false_positives: 1308.0000 - false_negatives: 1304.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0927 - val_accuracy: 0.9655 - val_precision: 0.9654 - val_recall: 0.9654 - val_binary_accuracy: 0.9654 - val_false_positives: 225.0000 - val_false_negatives: 225.0000 - val_sensitivity_at_specificity: 1.0000\n",
            "Epoch 11/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.1061 - accuracy: 0.9585 - precision: 0.9582 - recall: 0.9585 - binary_accuracy: 0.9584 - false_positives: 1267.0000 - false_negatives: 1259.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0932 - val_accuracy: 0.9641 - val_precision: 0.9643 - val_recall: 0.9643 - val_binary_accuracy: 0.9643 - val_false_positives: 232.0000 - val_false_negatives: 232.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 12/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1024 - accuracy: 0.9601 - precision: 0.9599 - recall: 0.9601 - binary_accuracy: 0.9600 - false_positives: 1215.0000 - false_negatives: 1209.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0906 - val_accuracy: 0.9660 - val_precision: 0.9661 - val_recall: 0.9660 - val_binary_accuracy: 0.9661 - val_false_positives: 220.0000 - val_false_negatives: 221.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 13/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0974 - accuracy: 0.9612 - precision: 0.9611 - recall: 0.9610 - binary_accuracy: 0.9610 - false_positives: 1181.0000 - false_negatives: 1182.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0892 - val_accuracy: 0.9652 - val_precision: 0.9649 - val_recall: 0.9652 - val_binary_accuracy: 0.9651 - val_false_positives: 228.0000 - val_false_negatives: 226.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 14/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.0942 - accuracy: 0.9631 - precision: 0.9631 - recall: 0.9631 - binary_accuracy: 0.9631 - false_positives: 1119.0000 - false_negatives: 1119.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0831 - val_accuracy: 0.9678 - val_precision: 0.9678 - val_recall: 0.9677 - val_binary_accuracy: 0.9678 - val_false_positives: 209.0000 - val_false_negatives: 210.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 15/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.0933 - accuracy: 0.9642 - precision: 0.9643 - recall: 0.9644 - binary_accuracy: 0.9643 - false_positives: 1084.0000 - false_negatives: 1080.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.0931 - val_accuracy: 0.9648 - val_precision: 0.9646 - val_recall: 0.9649 - val_binary_accuracy: 0.9648 - val_false_positives: 230.0000 - val_false_negatives: 228.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 16/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.0899 - accuracy: 0.9655 - precision: 0.9655 - recall: 0.9655 - binary_accuracy: 0.9655 - false_positives: 1047.0000 - false_negatives: 1046.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0833 - val_accuracy: 0.9705 - val_precision: 0.9704 - val_recall: 0.9701 - val_binary_accuracy: 0.9703 - val_false_positives: 192.0000 - val_false_negatives: 194.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 17/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0892 - accuracy: 0.9649 - precision: 0.9649 - recall: 0.9648 - binary_accuracy: 0.9649 - false_positives: 1063.0000 - false_negatives: 1067.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0872 - val_accuracy: 0.9655 - val_precision: 0.9652 - val_recall: 0.9655 - val_binary_accuracy: 0.9654 - val_false_positives: 226.0000 - val_false_negatives: 224.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 18/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0859 - accuracy: 0.9677 - precision: 0.9677 - recall: 0.9678 - binary_accuracy: 0.9677 - false_positives: 981.0000 - false_negatives: 978.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0819 - val_accuracy: 0.9692 - val_precision: 0.9692 - val_recall: 0.9694 - val_binary_accuracy: 0.9693 - val_false_positives: 200.0000 - val_false_negatives: 199.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 19/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.0867 - accuracy: 0.9659 - precision: 0.9661 - recall: 0.9660 - binary_accuracy: 0.9661 - false_positives: 1028.0000 - false_negatives: 1031.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0808 - val_accuracy: 0.9694 - val_precision: 0.9697 - val_recall: 0.9694 - val_binary_accuracy: 0.9695 - val_false_positives: 197.0000 - val_false_negatives: 199.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 20/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0830 - accuracy: 0.9685 - precision: 0.9685 - recall: 0.9684 - binary_accuracy: 0.9684 - false_positives: 955.0000 - false_negatives: 959.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0802 - val_accuracy: 0.9703 - val_precision: 0.9703 - val_recall: 0.9708 - val_binary_accuracy: 0.9705 - val_false_positives: 193.0000 - val_false_negatives: 190.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 21/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0819 - accuracy: 0.9678 - precision: 0.9679 - recall: 0.9678 - binary_accuracy: 0.9678 - false_positives: 974.0000 - false_negatives: 978.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0908 - val_accuracy: 0.9620 - val_precision: 0.9618 - val_recall: 0.9615 - val_binary_accuracy: 0.9617 - val_false_positives: 248.0000 - val_false_negatives: 250.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 22/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0809 - accuracy: 0.9690 - precision: 0.9691 - recall: 0.9690 - binary_accuracy: 0.9690 - false_positives: 938.0000 - false_negatives: 941.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0750 - val_accuracy: 0.9734 - val_precision: 0.9734 - val_recall: 0.9734 - val_binary_accuracy: 0.9734 - val_false_positives: 173.0000 - val_false_negatives: 173.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 23/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0778 - accuracy: 0.9699 - precision: 0.9699 - recall: 0.9700 - binary_accuracy: 0.9699 - false_positives: 913.0000 - false_negatives: 911.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0759 - val_accuracy: 0.9718 - val_precision: 0.9720 - val_recall: 0.9718 - val_binary_accuracy: 0.9719 - val_false_positives: 182.0000 - val_false_negatives: 183.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 24/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0799 - accuracy: 0.9696 - precision: 0.9697 - recall: 0.9695 - binary_accuracy: 0.9696 - false_positives: 919.0000 - false_negatives: 924.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0848 - val_accuracy: 0.9681 - val_precision: 0.9682 - val_recall: 0.9683 - val_binary_accuracy: 0.9682 - val_false_positives: 207.0000 - val_false_negatives: 206.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 25/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0762 - accuracy: 0.9695 - precision: 0.9696 - recall: 0.9697 - binary_accuracy: 0.9696 - false_positives: 923.0000 - false_negatives: 919.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0779 - val_accuracy: 0.9685 - val_precision: 0.9683 - val_recall: 0.9685 - val_binary_accuracy: 0.9684 - val_false_positives: 206.0000 - val_false_negatives: 205.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Test loss: 0.07532085478305817\n",
            "Test accuracy: 0.9713846445083618\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 154, 2, 32)        256       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 77, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 71, 2, 64)         14400     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 35, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2240)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2240)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 4482      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 19458 (76.01 KB)\n",
            "Trainable params: 19458 (76.01 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "474/474 [==============================] - 6s 9ms/step - loss: 0.3001 - accuracy: 0.8606 - precision: 0.8584 - recall: 0.8601 - binary_accuracy: 0.8591 - false_positives: 4303.0000 - false_negatives: 4243.0000 - sensitivity_at_specificity: 0.9935 - val_loss: 0.2241 - val_accuracy: 0.8983 - val_precision: 0.8945 - val_recall: 0.9028 - val_binary_accuracy: 0.8981 - val_false_positives: 692.0000 - val_false_negatives: 632.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 2/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.2103 - accuracy: 0.9080 - precision: 0.9073 - recall: 0.9067 - binary_accuracy: 0.9070 - false_positives: 2808.0000 - false_negatives: 2831.0000 - sensitivity_at_specificity: 0.9985 - val_loss: 0.1772 - val_accuracy: 0.9204 - val_precision: 0.9183 - val_recall: 0.9214 - val_binary_accuracy: 0.9197 - val_false_positives: 533.0000 - val_false_negatives: 511.0000 - val_sensitivity_at_specificity: 1.0000\n",
            "Epoch 3/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1726 - accuracy: 0.9269 - precision: 0.9265 - recall: 0.9258 - binary_accuracy: 0.9262 - false_positives: 2226.0000 - false_negatives: 2250.0000 - sensitivity_at_specificity: 0.9990 - val_loss: 0.1502 - val_accuracy: 0.9352 - val_precision: 0.9357 - val_recall: 0.9341 - val_binary_accuracy: 0.9350 - val_false_positives: 417.0000 - val_false_negatives: 428.0000 - val_sensitivity_at_specificity: 1.0000\n",
            "Epoch 4/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1508 - accuracy: 0.9398 - precision: 0.9400 - recall: 0.9397 - binary_accuracy: 0.9399 - false_positives: 1820.0000 - false_negatives: 1828.0000 - sensitivity_at_specificity: 0.9993 - val_loss: 0.1258 - val_accuracy: 0.9512 - val_precision: 0.9508 - val_recall: 0.9511 - val_binary_accuracy: 0.9509 - val_false_positives: 320.0000 - val_false_negatives: 318.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 5/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1393 - accuracy: 0.9449 - precision: 0.9447 - recall: 0.9449 - binary_accuracy: 0.9448 - false_positives: 1677.0000 - false_negatives: 1670.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.1145 - val_accuracy: 0.9558 - val_precision: 0.9562 - val_recall: 0.9548 - val_binary_accuracy: 0.9555 - val_false_positives: 284.0000 - val_false_negatives: 294.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 6/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1231 - accuracy: 0.9522 - precision: 0.9521 - recall: 0.9524 - binary_accuracy: 0.9523 - false_positives: 1453.0000 - false_negatives: 1443.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.1095 - val_accuracy: 0.9588 - val_precision: 0.9592 - val_recall: 0.9586 - val_binary_accuracy: 0.9589 - val_false_positives: 265.0000 - val_false_negatives: 269.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 7/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1169 - accuracy: 0.9544 - precision: 0.9543 - recall: 0.9541 - binary_accuracy: 0.9542 - false_positives: 1385.0000 - false_negatives: 1392.0000 - sensitivity_at_specificity: 0.9993 - val_loss: 0.1004 - val_accuracy: 0.9625 - val_precision: 0.9626 - val_recall: 0.9621 - val_binary_accuracy: 0.9624 - val_false_positives: 243.0000 - val_false_negatives: 246.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 8/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.1109 - accuracy: 0.9569 - precision: 0.9570 - recall: 0.9568 - binary_accuracy: 0.9569 - false_positives: 1303.0000 - false_negatives: 1310.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.0976 - val_accuracy: 0.9657 - val_precision: 0.9655 - val_recall: 0.9657 - val_binary_accuracy: 0.9656 - val_false_positives: 224.0000 - val_false_negatives: 223.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 9/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1048 - accuracy: 0.9587 - precision: 0.9586 - recall: 0.9582 - binary_accuracy: 0.9584 - false_positives: 1254.0000 - false_negatives: 1269.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0900 - val_accuracy: 0.9643 - val_precision: 0.9647 - val_recall: 0.9643 - val_binary_accuracy: 0.9645 - val_false_positives: 229.0000 - val_false_negatives: 232.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 10/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0988 - accuracy: 0.9617 - precision: 0.9618 - recall: 0.9618 - binary_accuracy: 0.9618 - false_positives: 1159.0000 - false_negatives: 1158.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0894 - val_accuracy: 0.9668 - val_precision: 0.9668 - val_recall: 0.9671 - val_binary_accuracy: 0.9669 - val_false_positives: 216.0000 - val_false_negatives: 214.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 11/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.0971 - accuracy: 0.9626 - precision: 0.9625 - recall: 0.9626 - binary_accuracy: 0.9625 - false_positives: 1138.0000 - false_negatives: 1135.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0858 - val_accuracy: 0.9681 - val_precision: 0.9684 - val_recall: 0.9681 - val_binary_accuracy: 0.9683 - val_false_positives: 205.0000 - val_false_negatives: 207.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 12/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.0946 - accuracy: 0.9643 - precision: 0.9642 - recall: 0.9641 - binary_accuracy: 0.9641 - false_positives: 1087.0000 - false_negatives: 1088.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.0863 - val_accuracy: 0.9694 - val_precision: 0.9691 - val_recall: 0.9694 - val_binary_accuracy: 0.9692 - val_false_positives: 201.0000 - val_false_negatives: 199.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 13/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0887 - accuracy: 0.9652 - precision: 0.9653 - recall: 0.9651 - binary_accuracy: 0.9652 - false_positives: 1053.0000 - false_negatives: 1058.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0804 - val_accuracy: 0.9711 - val_precision: 0.9712 - val_recall: 0.9711 - val_binary_accuracy: 0.9711 - val_false_positives: 187.0000 - val_false_negatives: 188.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 14/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0870 - accuracy: 0.9659 - precision: 0.9659 - recall: 0.9660 - binary_accuracy: 0.9659 - false_positives: 1035.0000 - false_negatives: 1032.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0780 - val_accuracy: 0.9729 - val_precision: 0.9732 - val_recall: 0.9731 - val_binary_accuracy: 0.9731 - val_false_positives: 174.0000 - val_false_negatives: 175.0000 - val_sensitivity_at_specificity: 0.9989\n",
            "Epoch 15/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0852 - accuracy: 0.9655 - precision: 0.9653 - recall: 0.9655 - binary_accuracy: 0.9654 - false_positives: 1053.0000 - false_negatives: 1045.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0855 - val_accuracy: 0.9689 - val_precision: 0.9686 - val_recall: 0.9688 - val_binary_accuracy: 0.9687 - val_false_positives: 204.0000 - val_false_negatives: 203.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 16/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0839 - accuracy: 0.9676 - precision: 0.9676 - recall: 0.9674 - binary_accuracy: 0.9675 - false_positives: 984.0000 - false_negatives: 988.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0775 - val_accuracy: 0.9723 - val_precision: 0.9725 - val_recall: 0.9725 - val_binary_accuracy: 0.9725 - val_false_positives: 179.0000 - val_false_negatives: 179.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 17/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0808 - accuracy: 0.9684 - precision: 0.9685 - recall: 0.9682 - binary_accuracy: 0.9684 - false_positives: 954.0000 - false_negatives: 964.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0750 - val_accuracy: 0.9721 - val_precision: 0.9720 - val_recall: 0.9723 - val_binary_accuracy: 0.9721 - val_false_positives: 182.0000 - val_false_negatives: 180.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 18/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0786 - accuracy: 0.9687 - precision: 0.9687 - recall: 0.9686 - binary_accuracy: 0.9687 - false_positives: 948.0000 - false_negatives: 952.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0758 - val_accuracy: 0.9734 - val_precision: 0.9732 - val_recall: 0.9735 - val_binary_accuracy: 0.9734 - val_false_positives: 174.0000 - val_false_negatives: 172.0000 - val_sensitivity_at_specificity: 0.9989\n",
            "Epoch 19/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0757 - accuracy: 0.9712 - precision: 0.9713 - recall: 0.9712 - binary_accuracy: 0.9713 - false_positives: 870.0000 - false_negatives: 872.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0829 - val_accuracy: 0.9701 - val_precision: 0.9697 - val_recall: 0.9700 - val_binary_accuracy: 0.9698 - val_false_positives: 197.0000 - val_false_negatives: 195.0000 - val_sensitivity_at_specificity: 0.9989\n",
            "Epoch 20/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0748 - accuracy: 0.9708 - precision: 0.9708 - recall: 0.9709 - binary_accuracy: 0.9708 - false_positives: 886.0000 - false_negatives: 883.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0707 - val_accuracy: 0.9738 - val_precision: 0.9740 - val_recall: 0.9740 - val_binary_accuracy: 0.9740 - val_false_positives: 169.0000 - val_false_negatives: 169.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 21/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.0735 - accuracy: 0.9724 - precision: 0.9724 - recall: 0.9725 - binary_accuracy: 0.9725 - false_positives: 836.0000 - false_negatives: 835.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0752 - val_accuracy: 0.9735 - val_precision: 0.9735 - val_recall: 0.9735 - val_binary_accuracy: 0.9735 - val_false_positives: 172.0000 - val_false_negatives: 172.0000 - val_sensitivity_at_specificity: 0.9989\n",
            "Epoch 22/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.0709 - accuracy: 0.9732 - precision: 0.9731 - recall: 0.9732 - binary_accuracy: 0.9732 - false_positives: 815.0000 - false_negatives: 813.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0777 - val_accuracy: 0.9728 - val_precision: 0.9728 - val_recall: 0.9723 - val_binary_accuracy: 0.9725 - val_false_positives: 177.0000 - val_false_negatives: 180.0000 - val_sensitivity_at_specificity: 0.9988\n",
            "Epoch 23/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0707 - accuracy: 0.9728 - precision: 0.9728 - recall: 0.9729 - binary_accuracy: 0.9728 - false_positives: 824.0000 - false_negatives: 823.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0707 - val_accuracy: 0.9748 - val_precision: 0.9751 - val_recall: 0.9746 - val_binary_accuracy: 0.9748 - val_false_positives: 162.0000 - val_false_negatives: 165.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 24/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0701 - accuracy: 0.9740 - precision: 0.9739 - recall: 0.9740 - binary_accuracy: 0.9740 - false_positives: 791.0000 - false_negatives: 789.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0724 - val_accuracy: 0.9758 - val_precision: 0.9757 - val_recall: 0.9758 - val_binary_accuracy: 0.9758 - val_false_positives: 158.0000 - val_false_negatives: 157.0000 - val_sensitivity_at_specificity: 0.9985\n",
            "Epoch 25/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0679 - accuracy: 0.9729 - precision: 0.9728 - recall: 0.9729 - binary_accuracy: 0.9729 - false_positives: 825.0000 - false_negatives: 821.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0684 - val_accuracy: 0.9745 - val_precision: 0.9745 - val_recall: 0.9746 - val_binary_accuracy: 0.9745 - val_false_positives: 166.0000 - val_false_negatives: 165.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Test loss: 0.062026094645261765\n",
            "Test accuracy: 0.975538432598114\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 153, 2, 32)        288       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 76, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 69, 2, 64)         16448     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 34, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2176)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2176)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 4354      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21410 (83.63 KB)\n",
            "Trainable params: 21410 (83.63 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "474/474 [==============================] - 6s 8ms/step - loss: 0.2971 - accuracy: 0.8607 - precision: 0.8597 - recall: 0.8595 - binary_accuracy: 0.8596 - false_positives: 4254.0000 - false_negatives: 4262.0000 - sensitivity_at_specificity: 0.9940 - val_loss: 0.2169 - val_accuracy: 0.9046 - val_precision: 0.9046 - val_recall: 0.9028 - val_binary_accuracy: 0.9038 - val_false_positives: 619.0000 - val_false_negatives: 632.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 2/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1991 - accuracy: 0.9120 - precision: 0.9126 - recall: 0.9124 - binary_accuracy: 0.9125 - false_positives: 2651.0000 - false_negatives: 2658.0000 - sensitivity_at_specificity: 0.9986 - val_loss: 0.1627 - val_accuracy: 0.9289 - val_precision: 0.9288 - val_recall: 0.9295 - val_binary_accuracy: 0.9291 - val_false_positives: 463.0000 - val_false_negatives: 458.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 3/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1653 - accuracy: 0.9312 - precision: 0.9311 - recall: 0.9306 - binary_accuracy: 0.9308 - false_positives: 2090.0000 - false_negatives: 2105.0000 - sensitivity_at_specificity: 0.9992 - val_loss: 0.1397 - val_accuracy: 0.9435 - val_precision: 0.9430 - val_recall: 0.9438 - val_binary_accuracy: 0.9434 - val_false_positives: 371.0000 - val_false_negatives: 365.0000 - val_sensitivity_at_specificity: 1.0000\n",
            "Epoch 4/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.1431 - accuracy: 0.9424 - precision: 0.9426 - recall: 0.9421 - binary_accuracy: 0.9424 - false_positives: 1740.0000 - false_negatives: 1756.0000 - sensitivity_at_specificity: 0.9993 - val_loss: 0.1247 - val_accuracy: 0.9512 - val_precision: 0.9505 - val_recall: 0.9518 - val_binary_accuracy: 0.9511 - val_false_positives: 322.0000 - val_false_negatives: 313.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 5/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1268 - accuracy: 0.9503 - precision: 0.9504 - recall: 0.9508 - binary_accuracy: 0.9506 - false_positives: 1504.0000 - false_negatives: 1491.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.1189 - val_accuracy: 0.9540 - val_precision: 0.9540 - val_recall: 0.9538 - val_binary_accuracy: 0.9539 - val_false_positives: 299.0000 - val_false_negatives: 300.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 6/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1154 - accuracy: 0.9548 - precision: 0.9545 - recall: 0.9546 - binary_accuracy: 0.9545 - false_positives: 1380.0000 - false_negatives: 1377.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0986 - val_accuracy: 0.9631 - val_precision: 0.9632 - val_recall: 0.9632 - val_binary_accuracy: 0.9632 - val_false_positives: 239.0000 - val_false_negatives: 239.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 7/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1078 - accuracy: 0.9598 - precision: 0.9597 - recall: 0.9597 - binary_accuracy: 0.9597 - false_positives: 1221.0000 - false_negatives: 1221.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0943 - val_accuracy: 0.9645 - val_precision: 0.9648 - val_recall: 0.9646 - val_binary_accuracy: 0.9647 - val_false_positives: 229.0000 - val_false_negatives: 230.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 8/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1014 - accuracy: 0.9596 - precision: 0.9597 - recall: 0.9599 - binary_accuracy: 0.9598 - false_positives: 1224.0000 - false_negatives: 1215.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0856 - val_accuracy: 0.9671 - val_precision: 0.9674 - val_recall: 0.9672 - val_binary_accuracy: 0.9673 - val_false_positives: 212.0000 - val_false_negatives: 213.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 9/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0935 - accuracy: 0.9644 - precision: 0.9645 - recall: 0.9644 - binary_accuracy: 0.9645 - false_positives: 1075.0000 - false_negatives: 1079.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0864 - val_accuracy: 0.9683 - val_precision: 0.9681 - val_recall: 0.9678 - val_binary_accuracy: 0.9680 - val_false_positives: 207.0000 - val_false_negatives: 209.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 10/25\n",
            "474/474 [==============================] - 4s 9ms/step - loss: 0.0920 - accuracy: 0.9654 - precision: 0.9651 - recall: 0.9649 - binary_accuracy: 0.9650 - false_positives: 1057.0000 - false_negatives: 1063.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0811 - val_accuracy: 0.9695 - val_precision: 0.9691 - val_recall: 0.9697 - val_binary_accuracy: 0.9694 - val_false_positives: 201.0000 - val_false_negatives: 197.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 11/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0860 - accuracy: 0.9677 - precision: 0.9676 - recall: 0.9676 - binary_accuracy: 0.9676 - false_positives: 984.0000 - false_negatives: 984.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0863 - val_accuracy: 0.9668 - val_precision: 0.9669 - val_recall: 0.9666 - val_binary_accuracy: 0.9668 - val_false_positives: 215.0000 - val_false_negatives: 217.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 12/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0866 - accuracy: 0.9672 - precision: 0.9673 - recall: 0.9672 - binary_accuracy: 0.9672 - false_positives: 993.0000 - false_negatives: 996.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0778 - val_accuracy: 0.9712 - val_precision: 0.9718 - val_recall: 0.9709 - val_binary_accuracy: 0.9714 - val_false_positives: 183.0000 - val_false_negatives: 189.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 13/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0807 - accuracy: 0.9695 - precision: 0.9694 - recall: 0.9694 - binary_accuracy: 0.9694 - false_positives: 927.0000 - false_negatives: 929.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0839 - val_accuracy: 0.9680 - val_precision: 0.9680 - val_recall: 0.9680 - val_binary_accuracy: 0.9680 - val_false_positives: 208.0000 - val_false_negatives: 208.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 14/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0800 - accuracy: 0.9695 - precision: 0.9695 - recall: 0.9694 - binary_accuracy: 0.9695 - false_positives: 924.0000 - false_negatives: 927.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0747 - val_accuracy: 0.9712 - val_precision: 0.9712 - val_recall: 0.9712 - val_binary_accuracy: 0.9712 - val_false_positives: 187.0000 - val_false_negatives: 187.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 15/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0751 - accuracy: 0.9710 - precision: 0.9710 - recall: 0.9710 - binary_accuracy: 0.9710 - false_positives: 879.0000 - false_negatives: 878.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0697 - val_accuracy: 0.9769 - val_precision: 0.9766 - val_recall: 0.9769 - val_binary_accuracy: 0.9768 - val_false_positives: 152.0000 - val_false_negatives: 150.0000 - val_sensitivity_at_specificity: 0.9989\n",
            "Epoch 16/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0734 - accuracy: 0.9716 - precision: 0.9716 - recall: 0.9716 - binary_accuracy: 0.9716 - false_positives: 860.0000 - false_negatives: 861.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0737 - val_accuracy: 0.9741 - val_precision: 0.9741 - val_recall: 0.9741 - val_binary_accuracy: 0.9741 - val_false_positives: 168.0000 - val_false_negatives: 168.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 17/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0717 - accuracy: 0.9723 - precision: 0.9723 - recall: 0.9724 - binary_accuracy: 0.9724 - false_positives: 840.0000 - false_negatives: 836.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0766 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714 - val_binary_accuracy: 0.9714 - val_false_positives: 186.0000 - val_false_negatives: 186.0000 - val_sensitivity_at_specificity: 0.9985\n",
            "Epoch 18/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0711 - accuracy: 0.9732 - precision: 0.9732 - recall: 0.9735 - binary_accuracy: 0.9733 - false_positives: 814.0000 - false_negatives: 803.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0754 - val_accuracy: 0.9709 - val_precision: 0.9708 - val_recall: 0.9711 - val_binary_accuracy: 0.9709 - val_false_positives: 190.0000 - val_false_negatives: 188.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 19/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0679 - accuracy: 0.9740 - precision: 0.9741 - recall: 0.9741 - binary_accuracy: 0.9741 - false_positives: 784.0000 - false_negatives: 787.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0705 - val_accuracy: 0.9734 - val_precision: 0.9735 - val_recall: 0.9734 - val_binary_accuracy: 0.9735 - val_false_positives: 172.0000 - val_false_negatives: 173.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 20/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.0688 - accuracy: 0.9739 - precision: 0.9737 - recall: 0.9739 - binary_accuracy: 0.9738 - false_positives: 799.0000 - false_negatives: 791.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0827 - val_accuracy: 0.9703 - val_precision: 0.9700 - val_recall: 0.9703 - val_binary_accuracy: 0.9701 - val_false_positives: 195.0000 - val_false_negatives: 193.0000 - val_sensitivity_at_specificity: 0.9989\n",
            "Epoch 21/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.0656 - accuracy: 0.9755 - precision: 0.9752 - recall: 0.9755 - binary_accuracy: 0.9754 - false_positives: 752.0000 - false_negatives: 743.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0679 - val_accuracy: 0.9746 - val_precision: 0.9746 - val_recall: 0.9746 - val_binary_accuracy: 0.9746 - val_false_positives: 165.0000 - val_false_negatives: 165.0000 - val_sensitivity_at_specificity: 0.9989\n",
            "Epoch 22/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.0634 - accuracy: 0.9765 - precision: 0.9767 - recall: 0.9765 - binary_accuracy: 0.9766 - false_positives: 706.0000 - false_negatives: 714.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0697 - val_accuracy: 0.9760 - val_precision: 0.9761 - val_recall: 0.9760 - val_binary_accuracy: 0.9761 - val_false_positives: 155.0000 - val_false_negatives: 156.0000 - val_sensitivity_at_specificity: 0.9988\n",
            "Epoch 23/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0644 - accuracy: 0.9753 - precision: 0.9752 - recall: 0.9752 - binary_accuracy: 0.9752 - false_positives: 751.0000 - false_negatives: 752.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0691 - val_accuracy: 0.9749 - val_precision: 0.9749 - val_recall: 0.9748 - val_binary_accuracy: 0.9748 - val_false_positives: 163.0000 - val_false_negatives: 164.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 24/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0598 - accuracy: 0.9773 - precision: 0.9774 - recall: 0.9775 - binary_accuracy: 0.9774 - false_positives: 685.0000 - false_negatives: 683.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0687 - val_accuracy: 0.9752 - val_precision: 0.9754 - val_recall: 0.9752 - val_binary_accuracy: 0.9753 - val_false_positives: 160.0000 - val_false_negatives: 161.0000 - val_sensitivity_at_specificity: 0.9989\n",
            "Epoch 25/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0603 - accuracy: 0.9767 - precision: 0.9768 - recall: 0.9767 - binary_accuracy: 0.9767 - false_positives: 704.0000 - false_negatives: 707.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0712 - val_accuracy: 0.9745 - val_precision: 0.9745 - val_recall: 0.9748 - val_binary_accuracy: 0.9746 - val_false_positives: 166.0000 - val_false_negatives: 164.0000 - val_sensitivity_at_specificity: 0.9986\n",
            "Test loss: 0.06220972165465355\n",
            "Test accuracy: 0.9778461456298828\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 152, 2, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 76, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 68, 2, 64)         18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 34, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2176)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2176)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 4354      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23490 (91.76 KB)\n",
            "Trainable params: 23490 (91.76 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "474/474 [==============================] - 6s 9ms/step - loss: 0.2874 - accuracy: 0.8659 - precision: 0.8659 - recall: 0.8658 - binary_accuracy: 0.8658 - false_positives: 4068.0000 - false_negatives: 4071.0000 - sensitivity_at_specificity: 0.9951 - val_loss: 0.2103 - val_accuracy: 0.9071 - val_precision: 0.9068 - val_recall: 0.9075 - val_binary_accuracy: 0.9071 - val_false_positives: 606.0000 - val_false_negatives: 601.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 2/25\n",
            "474/474 [==============================] - 4s 8ms/step - loss: 0.1933 - accuracy: 0.9168 - precision: 0.9171 - recall: 0.9169 - binary_accuracy: 0.9170 - false_positives: 2514.0000 - false_negatives: 2521.0000 - sensitivity_at_specificity: 0.9986 - val_loss: 0.1586 - val_accuracy: 0.9311 - val_precision: 0.9297 - val_recall: 0.9318 - val_binary_accuracy: 0.9307 - val_false_positives: 458.0000 - val_false_negatives: 443.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 3/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1546 - accuracy: 0.9361 - precision: 0.9356 - recall: 0.9358 - binary_accuracy: 0.9357 - false_positives: 1954.0000 - false_negatives: 1948.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.1321 - val_accuracy: 0.9451 - val_precision: 0.9462 - val_recall: 0.9446 - val_binary_accuracy: 0.9455 - val_false_positives: 349.0000 - val_false_negatives: 360.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 4/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1351 - accuracy: 0.9452 - precision: 0.9449 - recall: 0.9449 - binary_accuracy: 0.9449 - false_positives: 1672.0000 - false_negatives: 1671.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.1215 - val_accuracy: 0.9498 - val_precision: 0.9498 - val_recall: 0.9495 - val_binary_accuracy: 0.9497 - val_false_positives: 326.0000 - val_false_negatives: 328.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 5/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1187 - accuracy: 0.9535 - precision: 0.9533 - recall: 0.9527 - binary_accuracy: 0.9530 - false_positives: 1416.0000 - false_negatives: 1433.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.1017 - val_accuracy: 0.9608 - val_precision: 0.9608 - val_recall: 0.9605 - val_binary_accuracy: 0.9606 - val_false_positives: 255.0000 - val_false_negatives: 257.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 6/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1111 - accuracy: 0.9565 - precision: 0.9564 - recall: 0.9564 - binary_accuracy: 0.9564 - false_positives: 1321.0000 - false_negatives: 1321.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0934 - val_accuracy: 0.9645 - val_precision: 0.9646 - val_recall: 0.9641 - val_binary_accuracy: 0.9644 - val_false_positives: 230.0000 - val_false_negatives: 233.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 7/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1030 - accuracy: 0.9601 - precision: 0.9600 - recall: 0.9603 - binary_accuracy: 0.9602 - false_positives: 1213.0000 - false_negatives: 1204.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.0879 - val_accuracy: 0.9683 - val_precision: 0.9689 - val_recall: 0.9685 - val_binary_accuracy: 0.9687 - val_false_positives: 202.0000 - val_false_negatives: 205.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 8/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0946 - accuracy: 0.9634 - precision: 0.9635 - recall: 0.9633 - binary_accuracy: 0.9634 - false_positives: 1108.0000 - false_negatives: 1114.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0826 - val_accuracy: 0.9669 - val_precision: 0.9666 - val_recall: 0.9665 - val_binary_accuracy: 0.9665 - val_false_positives: 217.0000 - val_false_negatives: 218.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 9/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0912 - accuracy: 0.9648 - precision: 0.9650 - recall: 0.9644 - binary_accuracy: 0.9647 - false_positives: 1060.0000 - false_negatives: 1079.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0809 - val_accuracy: 0.9691 - val_precision: 0.9689 - val_recall: 0.9691 - val_binary_accuracy: 0.9690 - val_false_positives: 202.0000 - val_false_negatives: 201.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 10/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0854 - accuracy: 0.9675 - precision: 0.9673 - recall: 0.9678 - binary_accuracy: 0.9675 - false_positives: 991.0000 - false_negatives: 978.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0846 - val_accuracy: 0.9669 - val_precision: 0.9672 - val_recall: 0.9666 - val_binary_accuracy: 0.9669 - val_false_positives: 213.0000 - val_false_negatives: 217.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 11/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0826 - accuracy: 0.9691 - precision: 0.9692 - recall: 0.9690 - binary_accuracy: 0.9691 - false_positives: 935.0000 - false_negatives: 940.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0783 - val_accuracy: 0.9718 - val_precision: 0.9714 - val_recall: 0.9718 - val_binary_accuracy: 0.9716 - val_false_positives: 186.0000 - val_false_negatives: 183.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 12/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0791 - accuracy: 0.9707 - precision: 0.9705 - recall: 0.9706 - binary_accuracy: 0.9705 - false_positives: 895.0000 - false_negatives: 893.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0817 - val_accuracy: 0.9685 - val_precision: 0.9686 - val_recall: 0.9685 - val_binary_accuracy: 0.9685 - val_false_positives: 204.0000 - val_false_negatives: 205.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 13/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0768 - accuracy: 0.9708 - precision: 0.9708 - recall: 0.9707 - binary_accuracy: 0.9707 - false_positives: 886.0000 - false_negatives: 889.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0799 - val_accuracy: 0.9688 - val_precision: 0.9688 - val_recall: 0.9688 - val_binary_accuracy: 0.9688 - val_false_positives: 203.0000 - val_false_negatives: 203.0000 - val_sensitivity_at_specificity: 0.9989\n",
            "Epoch 14/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0756 - accuracy: 0.9710 - precision: 0.9713 - recall: 0.9709 - binary_accuracy: 0.9711 - false_positives: 870.0000 - false_negatives: 882.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0717 - val_accuracy: 0.9726 - val_precision: 0.9717 - val_recall: 0.9726 - val_binary_accuracy: 0.9721 - val_false_positives: 184.0000 - val_false_negatives: 178.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 15/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0711 - accuracy: 0.9731 - precision: 0.9734 - recall: 0.9731 - binary_accuracy: 0.9732 - false_positives: 808.0000 - false_negatives: 816.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0748 - val_accuracy: 0.9709 - val_precision: 0.9705 - val_recall: 0.9711 - val_binary_accuracy: 0.9708 - val_false_positives: 192.0000 - val_false_negatives: 188.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 16/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0661 - accuracy: 0.9744 - precision: 0.9745 - recall: 0.9743 - binary_accuracy: 0.9744 - false_positives: 772.0000 - false_negatives: 779.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0625 - val_accuracy: 0.9762 - val_precision: 0.9760 - val_recall: 0.9763 - val_binary_accuracy: 0.9762 - val_false_positives: 156.0000 - val_false_negatives: 154.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 17/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0668 - accuracy: 0.9746 - precision: 0.9747 - recall: 0.9745 - binary_accuracy: 0.9746 - false_positives: 766.0000 - false_negatives: 773.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0660 - val_accuracy: 0.9752 - val_precision: 0.9752 - val_recall: 0.9754 - val_binary_accuracy: 0.9753 - val_false_positives: 161.0000 - val_false_negatives: 160.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 18/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0656 - accuracy: 0.9749 - precision: 0.9749 - recall: 0.9750 - binary_accuracy: 0.9749 - false_positives: 761.0000 - false_negatives: 759.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0661 - val_accuracy: 0.9737 - val_precision: 0.9735 - val_recall: 0.9735 - val_binary_accuracy: 0.9735 - val_false_positives: 172.0000 - val_false_negatives: 172.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 19/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0648 - accuracy: 0.9752 - precision: 0.9752 - recall: 0.9751 - binary_accuracy: 0.9751 - false_positives: 753.0000 - false_negatives: 755.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0646 - val_accuracy: 0.9749 - val_precision: 0.9749 - val_recall: 0.9749 - val_binary_accuracy: 0.9749 - val_false_positives: 163.0000 - val_false_negatives: 163.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 20/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0601 - accuracy: 0.9770 - precision: 0.9770 - recall: 0.9771 - binary_accuracy: 0.9771 - false_positives: 697.0000 - false_negatives: 695.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0641 - val_accuracy: 0.9748 - val_precision: 0.9749 - val_recall: 0.9748 - val_binary_accuracy: 0.9748 - val_false_positives: 163.0000 - val_false_negatives: 164.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 21/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.0586 - accuracy: 0.9779 - precision: 0.9779 - recall: 0.9779 - binary_accuracy: 0.9779 - false_positives: 670.0000 - false_negatives: 671.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0637 - val_accuracy: 0.9746 - val_precision: 0.9746 - val_recall: 0.9746 - val_binary_accuracy: 0.9746 - val_false_positives: 165.0000 - val_false_negatives: 165.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 22/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.0585 - accuracy: 0.9781 - precision: 0.9781 - recall: 0.9781 - binary_accuracy: 0.9781 - false_positives: 665.0000 - false_negatives: 663.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0604 - val_accuracy: 0.9762 - val_precision: 0.9762 - val_recall: 0.9762 - val_binary_accuracy: 0.9762 - val_false_positives: 155.0000 - val_false_negatives: 155.0000 - val_sensitivity_at_specificity: 0.9988\n",
            "Epoch 23/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0564 - accuracy: 0.9794 - precision: 0.9793 - recall: 0.9795 - binary_accuracy: 0.9794 - false_positives: 629.0000 - false_negatives: 623.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.0610 - val_accuracy: 0.9780 - val_precision: 0.9781 - val_recall: 0.9778 - val_binary_accuracy: 0.9780 - val_false_positives: 142.0000 - val_false_negatives: 144.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 24/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0599 - accuracy: 0.9770 - precision: 0.9770 - recall: 0.9771 - binary_accuracy: 0.9770 - false_positives: 697.0000 - false_negatives: 696.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0639 - val_accuracy: 0.9786 - val_precision: 0.9786 - val_recall: 0.9785 - val_binary_accuracy: 0.9785 - val_false_positives: 139.0000 - val_false_negatives: 140.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 25/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0530 - accuracy: 0.9793 - precision: 0.9793 - recall: 0.9794 - binary_accuracy: 0.9793 - false_positives: 629.0000 - false_negatives: 624.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0604 - val_accuracy: 0.9786 - val_precision: 0.9786 - val_recall: 0.9786 - val_binary_accuracy: 0.9786 - val_false_positives: 139.0000 - val_false_negatives: 139.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Test loss: 0.0526341050863266\n",
            "Test accuracy: 0.9803076982498169\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 151, 2, 32)        352       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 75, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 66, 2, 64)         20544     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 33, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2112)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2112)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 4226      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25442 (99.38 KB)\n",
            "Trainable params: 25442 (99.38 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "474/474 [==============================] - 6s 8ms/step - loss: 0.2910 - accuracy: 0.8640 - precision: 0.8629 - recall: 0.8618 - binary_accuracy: 0.8625 - false_positives: 4153.0000 - false_negatives: 4190.0000 - sensitivity_at_specificity: 0.9939 - val_loss: 0.2061 - val_accuracy: 0.9118 - val_precision: 0.9129 - val_recall: 0.9098 - val_binary_accuracy: 0.9115 - val_false_positives: 564.0000 - val_false_negatives: 586.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 2/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1849 - accuracy: 0.9236 - precision: 0.9230 - recall: 0.9222 - binary_accuracy: 0.9226 - false_positives: 2333.0000 - false_negatives: 2359.0000 - sensitivity_at_specificity: 0.9992 - val_loss: 0.1494 - val_accuracy: 0.9338 - val_precision: 0.9336 - val_recall: 0.9351 - val_binary_accuracy: 0.9343 - val_false_positives: 432.0000 - val_false_negatives: 422.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 3/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1450 - accuracy: 0.9428 - precision: 0.9419 - recall: 0.9421 - binary_accuracy: 0.9420 - false_positives: 1763.0000 - false_negatives: 1755.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.1211 - val_accuracy: 0.9545 - val_precision: 0.9534 - val_recall: 0.9543 - val_binary_accuracy: 0.9538 - val_false_positives: 303.0000 - val_false_negatives: 297.0000 - val_sensitivity_at_specificity: 1.0000\n",
            "Epoch 4/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1240 - accuracy: 0.9511 - precision: 0.9510 - recall: 0.9506 - binary_accuracy: 0.9508 - false_positives: 1486.0000 - false_negatives: 1497.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.1024 - val_accuracy: 0.9628 - val_precision: 0.9629 - val_recall: 0.9625 - val_binary_accuracy: 0.9627 - val_false_positives: 241.0000 - val_false_negatives: 244.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 5/25\n",
            "474/474 [==============================] - 4s 8ms/step - loss: 0.1109 - accuracy: 0.9571 - precision: 0.9570 - recall: 0.9566 - binary_accuracy: 0.9568 - false_positives: 1304.0000 - false_negatives: 1317.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0949 - val_accuracy: 0.9645 - val_precision: 0.9649 - val_recall: 0.9641 - val_binary_accuracy: 0.9645 - val_false_positives: 228.0000 - val_false_negatives: 233.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 6/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1004 - accuracy: 0.9616 - precision: 0.9613 - recall: 0.9615 - binary_accuracy: 0.9614 - false_positives: 1175.0000 - false_negatives: 1167.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0884 - val_accuracy: 0.9666 - val_precision: 0.9669 - val_recall: 0.9666 - val_binary_accuracy: 0.9668 - val_false_positives: 215.0000 - val_false_negatives: 217.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 7/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0939 - accuracy: 0.9640 - precision: 0.9640 - recall: 0.9638 - binary_accuracy: 0.9639 - false_positives: 1093.0000 - false_negatives: 1097.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.0808 - val_accuracy: 0.9703 - val_precision: 0.9703 - val_recall: 0.9700 - val_binary_accuracy: 0.9701 - val_false_positives: 193.0000 - val_false_negatives: 195.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 8/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0915 - accuracy: 0.9649 - precision: 0.9649 - recall: 0.9647 - binary_accuracy: 0.9648 - false_positives: 1065.0000 - false_negatives: 1072.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0755 - val_accuracy: 0.9728 - val_precision: 0.9731 - val_recall: 0.9732 - val_binary_accuracy: 0.9731 - val_false_positives: 175.0000 - val_false_negatives: 174.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 9/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0853 - accuracy: 0.9672 - precision: 0.9671 - recall: 0.9676 - binary_accuracy: 0.9674 - false_positives: 997.0000 - false_negatives: 983.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0783 - val_accuracy: 0.9695 - val_precision: 0.9692 - val_recall: 0.9698 - val_binary_accuracy: 0.9695 - val_false_positives: 200.0000 - val_false_negatives: 196.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 10/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0795 - accuracy: 0.9685 - precision: 0.9687 - recall: 0.9685 - binary_accuracy: 0.9686 - false_positives: 949.0000 - false_negatives: 955.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0797 - val_accuracy: 0.9706 - val_precision: 0.9702 - val_recall: 0.9703 - val_binary_accuracy: 0.9702 - val_false_positives: 194.0000 - val_false_negatives: 193.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 11/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0758 - accuracy: 0.9717 - precision: 0.9715 - recall: 0.9717 - binary_accuracy: 0.9716 - false_positives: 864.0000 - false_negatives: 858.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.0849 - val_accuracy: 0.9669 - val_precision: 0.9672 - val_recall: 0.9669 - val_binary_accuracy: 0.9671 - val_false_positives: 213.0000 - val_false_negatives: 215.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 12/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0746 - accuracy: 0.9714 - precision: 0.9715 - recall: 0.9716 - binary_accuracy: 0.9715 - false_positives: 866.0000 - false_negatives: 861.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0743 - val_accuracy: 0.9717 - val_precision: 0.9718 - val_recall: 0.9715 - val_binary_accuracy: 0.9717 - val_false_positives: 183.0000 - val_false_negatives: 185.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 13/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0714 - accuracy: 0.9728 - precision: 0.9729 - recall: 0.9730 - binary_accuracy: 0.9729 - false_positives: 821.0000 - false_negatives: 820.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0703 - val_accuracy: 0.9731 - val_precision: 0.9732 - val_recall: 0.9729 - val_binary_accuracy: 0.9731 - val_false_positives: 174.0000 - val_false_negatives: 176.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 14/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0695 - accuracy: 0.9736 - precision: 0.9737 - recall: 0.9735 - binary_accuracy: 0.9736 - false_positives: 798.0000 - false_negatives: 804.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0659 - val_accuracy: 0.9774 - val_precision: 0.9777 - val_recall: 0.9782 - val_binary_accuracy: 0.9779 - val_false_positives: 145.0000 - val_false_negatives: 142.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 15/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0653 - accuracy: 0.9771 - precision: 0.9769 - recall: 0.9769 - binary_accuracy: 0.9769 - false_positives: 701.0000 - false_negatives: 701.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.0616 - val_accuracy: 0.9802 - val_precision: 0.9803 - val_recall: 0.9798 - val_binary_accuracy: 0.9801 - val_false_positives: 128.0000 - val_false_negatives: 131.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 16/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0646 - accuracy: 0.9746 - precision: 0.9746 - recall: 0.9747 - binary_accuracy: 0.9747 - false_positives: 770.0000 - false_negatives: 767.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0692 - val_accuracy: 0.9754 - val_precision: 0.9751 - val_recall: 0.9760 - val_binary_accuracy: 0.9755 - val_false_positives: 162.0000 - val_false_negatives: 156.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 17/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0610 - accuracy: 0.9762 - precision: 0.9762 - recall: 0.9762 - binary_accuracy: 0.9762 - false_positives: 723.0000 - false_negatives: 723.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0637 - val_accuracy: 0.9775 - val_precision: 0.9775 - val_recall: 0.9778 - val_binary_accuracy: 0.9777 - val_false_positives: 146.0000 - val_false_negatives: 144.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 18/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0585 - accuracy: 0.9784 - precision: 0.9784 - recall: 0.9784 - binary_accuracy: 0.9784 - false_positives: 655.0000 - false_negatives: 655.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0623 - val_accuracy: 0.9774 - val_precision: 0.9772 - val_recall: 0.9774 - val_binary_accuracy: 0.9773 - val_false_positives: 148.0000 - val_false_negatives: 147.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 19/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0588 - accuracy: 0.9767 - precision: 0.9767 - recall: 0.9766 - binary_accuracy: 0.9767 - false_positives: 707.0000 - false_negatives: 709.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0589 - val_accuracy: 0.9803 - val_precision: 0.9803 - val_recall: 0.9803 - val_binary_accuracy: 0.9803 - val_false_positives: 128.0000 - val_false_negatives: 128.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 20/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0584 - accuracy: 0.9787 - precision: 0.9786 - recall: 0.9788 - binary_accuracy: 0.9787 - false_positives: 649.0000 - false_negatives: 644.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0589 - val_accuracy: 0.9808 - val_precision: 0.9808 - val_recall: 0.9808 - val_binary_accuracy: 0.9808 - val_false_positives: 125.0000 - val_false_negatives: 125.0000 - val_sensitivity_at_specificity: 0.9989\n",
            "Epoch 21/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0560 - accuracy: 0.9791 - precision: 0.9791 - recall: 0.9792 - binary_accuracy: 0.9792 - false_positives: 633.0000 - false_negatives: 630.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0610 - val_accuracy: 0.9777 - val_precision: 0.9777 - val_recall: 0.9775 - val_binary_accuracy: 0.9776 - val_false_positives: 145.0000 - val_false_negatives: 146.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 22/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0547 - accuracy: 0.9782 - precision: 0.9783 - recall: 0.9782 - binary_accuracy: 0.9783 - false_positives: 659.0000 - false_negatives: 660.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0588 - val_accuracy: 0.9788 - val_precision: 0.9788 - val_recall: 0.9785 - val_binary_accuracy: 0.9786 - val_false_positives: 138.0000 - val_false_negatives: 140.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 23/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0533 - accuracy: 0.9797 - precision: 0.9797 - recall: 0.9797 - binary_accuracy: 0.9797 - false_positives: 616.0000 - false_negatives: 617.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0660 - val_accuracy: 0.9743 - val_precision: 0.9746 - val_recall: 0.9745 - val_binary_accuracy: 0.9745 - val_false_positives: 165.0000 - val_false_negatives: 166.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 24/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0528 - accuracy: 0.9799 - precision: 0.9801 - recall: 0.9798 - binary_accuracy: 0.9800 - false_positives: 603.0000 - false_negatives: 612.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0612 - val_accuracy: 0.9775 - val_precision: 0.9772 - val_recall: 0.9777 - val_binary_accuracy: 0.9775 - val_false_positives: 148.0000 - val_false_negatives: 145.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 25/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0520 - accuracy: 0.9799 - precision: 0.9799 - recall: 0.9799 - binary_accuracy: 0.9799 - false_positives: 609.0000 - false_negatives: 611.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0560 - val_accuracy: 0.9808 - val_precision: 0.9806 - val_recall: 0.9809 - val_binary_accuracy: 0.9808 - val_false_positives: 126.0000 - val_false_negatives: 124.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Test loss: 0.04880281910300255\n",
            "Test accuracy: 0.9826154112815857\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 150, 2, 32)        384       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 75, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 65, 2, 64)         22592     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 32, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 4098      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 27394 (107.01 KB)\n",
            "Trainable params: 27394 (107.01 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "474/474 [==============================] - 6s 8ms/step - loss: 0.2781 - accuracy: 0.8697 - precision: 0.8692 - recall: 0.8684 - binary_accuracy: 0.8689 - false_positives: 3965.0000 - false_negatives: 3990.0000 - sensitivity_at_specificity: 0.9948 - val_loss: 0.1887 - val_accuracy: 0.9140 - val_precision: 0.9147 - val_recall: 0.9121 - val_binary_accuracy: 0.9135 - val_false_positives: 553.0000 - val_false_negatives: 571.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 2/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1682 - accuracy: 0.9306 - precision: 0.9297 - recall: 0.9298 - binary_accuracy: 0.9298 - false_positives: 2132.0000 - false_negatives: 2128.0000 - sensitivity_at_specificity: 0.9990 - val_loss: 0.1281 - val_accuracy: 0.9497 - val_precision: 0.9487 - val_recall: 0.9503 - val_binary_accuracy: 0.9495 - val_false_positives: 334.0000 - val_false_negatives: 323.0000 - val_sensitivity_at_specificity: 1.0000\n",
            "Epoch 3/25\n",
            "474/474 [==============================] - 4s 7ms/step - loss: 0.1331 - accuracy: 0.9477 - precision: 0.9473 - recall: 0.9467 - binary_accuracy: 0.9470 - false_positives: 1596.0000 - false_negatives: 1617.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.1085 - val_accuracy: 0.9568 - val_precision: 0.9571 - val_recall: 0.9578 - val_binary_accuracy: 0.9575 - val_false_positives: 279.0000 - val_false_negatives: 274.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 4/25\n",
            "474/474 [==============================] - 4s 8ms/step - loss: 0.1149 - accuracy: 0.9557 - precision: 0.9550 - recall: 0.9557 - binary_accuracy: 0.9553 - false_positives: 1365.0000 - false_negatives: 1344.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0895 - val_accuracy: 0.9672 - val_precision: 0.9672 - val_recall: 0.9675 - val_binary_accuracy: 0.9674 - val_false_positives: 213.0000 - val_false_negatives: 211.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 5/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1016 - accuracy: 0.9617 - precision: 0.9615 - recall: 0.9611 - binary_accuracy: 0.9613 - false_positives: 1168.0000 - false_negatives: 1180.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0847 - val_accuracy: 0.9689 - val_precision: 0.9695 - val_recall: 0.9694 - val_binary_accuracy: 0.9695 - val_false_positives: 198.0000 - val_false_negatives: 199.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 6/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0951 - accuracy: 0.9645 - precision: 0.9642 - recall: 0.9647 - binary_accuracy: 0.9644 - false_positives: 1086.0000 - false_negatives: 1072.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0786 - val_accuracy: 0.9714 - val_precision: 0.9706 - val_recall: 0.9718 - val_binary_accuracy: 0.9712 - val_false_positives: 191.0000 - val_false_negatives: 183.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 7/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0901 - accuracy: 0.9654 - precision: 0.9655 - recall: 0.9654 - binary_accuracy: 0.9654 - false_positives: 1047.0000 - false_negatives: 1050.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.0823 - val_accuracy: 0.9683 - val_precision: 0.9682 - val_recall: 0.9683 - val_binary_accuracy: 0.9682 - val_false_positives: 207.0000 - val_false_negatives: 206.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 8/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0824 - accuracy: 0.9690 - precision: 0.9690 - recall: 0.9689 - binary_accuracy: 0.9690 - false_positives: 939.0000 - false_negatives: 944.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.0686 - val_accuracy: 0.9751 - val_precision: 0.9748 - val_recall: 0.9748 - val_binary_accuracy: 0.9748 - val_false_positives: 164.0000 - val_false_negatives: 164.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 9/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0791 - accuracy: 0.9698 - precision: 0.9697 - recall: 0.9699 - binary_accuracy: 0.9698 - false_positives: 920.0000 - false_negatives: 914.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0697 - val_accuracy: 0.9752 - val_precision: 0.9755 - val_recall: 0.9755 - val_binary_accuracy: 0.9755 - val_false_positives: 159.0000 - val_false_negatives: 159.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 10/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0751 - accuracy: 0.9719 - precision: 0.9723 - recall: 0.9719 - binary_accuracy: 0.9721 - false_positives: 839.0000 - false_negatives: 851.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0694 - val_accuracy: 0.9775 - val_precision: 0.9775 - val_recall: 0.9771 - val_binary_accuracy: 0.9773 - val_false_positives: 146.0000 - val_false_negatives: 149.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 11/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0728 - accuracy: 0.9717 - precision: 0.9721 - recall: 0.9716 - binary_accuracy: 0.9719 - false_positives: 847.0000 - false_negatives: 860.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0676 - val_accuracy: 0.9752 - val_precision: 0.9749 - val_recall: 0.9748 - val_binary_accuracy: 0.9748 - val_false_positives: 163.0000 - val_false_negatives: 164.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 12/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0699 - accuracy: 0.9735 - precision: 0.9736 - recall: 0.9736 - binary_accuracy: 0.9736 - false_positives: 801.0000 - false_negatives: 802.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0717 - val_accuracy: 0.9728 - val_precision: 0.9731 - val_recall: 0.9725 - val_binary_accuracy: 0.9728 - val_false_positives: 175.0000 - val_false_negatives: 179.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 13/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0679 - accuracy: 0.9744 - precision: 0.9742 - recall: 0.9747 - binary_accuracy: 0.9745 - false_positives: 782.0000 - false_negatives: 767.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.0608 - val_accuracy: 0.9777 - val_precision: 0.9772 - val_recall: 0.9778 - val_binary_accuracy: 0.9775 - val_false_positives: 148.0000 - val_false_negatives: 144.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 14/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0631 - accuracy: 0.9757 - precision: 0.9756 - recall: 0.9757 - binary_accuracy: 0.9757 - false_positives: 740.0000 - false_negatives: 736.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0600 - val_accuracy: 0.9814 - val_precision: 0.9812 - val_recall: 0.9812 - val_binary_accuracy: 0.9812 - val_false_positives: 122.0000 - val_false_negatives: 122.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 15/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0597 - accuracy: 0.9780 - precision: 0.9778 - recall: 0.9781 - binary_accuracy: 0.9779 - false_positives: 674.0000 - false_negatives: 664.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0580 - val_accuracy: 0.9791 - val_precision: 0.9797 - val_recall: 0.9791 - val_binary_accuracy: 0.9794 - val_false_positives: 132.0000 - val_false_negatives: 136.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 16/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0562 - accuracy: 0.9795 - precision: 0.9796 - recall: 0.9793 - binary_accuracy: 0.9794 - false_positives: 619.0000 - false_negatives: 629.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0731 - val_accuracy: 0.9706 - val_precision: 0.9708 - val_recall: 0.9705 - val_binary_accuracy: 0.9706 - val_false_positives: 190.0000 - val_false_negatives: 192.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 17/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.0590 - accuracy: 0.9778 - precision: 0.9777 - recall: 0.9777 - binary_accuracy: 0.9777 - false_positives: 676.0000 - false_negatives: 676.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0604 - val_accuracy: 0.9791 - val_precision: 0.9792 - val_recall: 0.9789 - val_binary_accuracy: 0.9791 - val_false_positives: 135.0000 - val_false_negatives: 137.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 18/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.0566 - accuracy: 0.9791 - precision: 0.9790 - recall: 0.9792 - binary_accuracy: 0.9791 - false_positives: 637.0000 - false_negatives: 631.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0586 - val_accuracy: 0.9786 - val_precision: 0.9786 - val_recall: 0.9786 - val_binary_accuracy: 0.9786 - val_false_positives: 139.0000 - val_false_negatives: 139.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 19/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0535 - accuracy: 0.9801 - precision: 0.9800 - recall: 0.9802 - binary_accuracy: 0.9801 - false_positives: 608.0000 - false_negatives: 601.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0677 - val_accuracy: 0.9734 - val_precision: 0.9735 - val_recall: 0.9732 - val_binary_accuracy: 0.9734 - val_false_positives: 172.0000 - val_false_negatives: 174.0000 - val_sensitivity_at_specificity: 0.9989\n",
            "Epoch 20/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0552 - accuracy: 0.9789 - precision: 0.9789 - recall: 0.9789 - binary_accuracy: 0.9789 - false_positives: 640.0000 - false_negatives: 641.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0586 - val_accuracy: 0.9794 - val_precision: 0.9792 - val_recall: 0.9794 - val_binary_accuracy: 0.9793 - val_false_positives: 135.0000 - val_false_negatives: 134.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 21/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0501 - accuracy: 0.9805 - precision: 0.9804 - recall: 0.9805 - binary_accuracy: 0.9805 - false_positives: 593.0000 - false_negatives: 592.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0527 - val_accuracy: 0.9806 - val_precision: 0.9803 - val_recall: 0.9806 - val_binary_accuracy: 0.9805 - val_false_positives: 128.0000 - val_false_negatives: 126.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 22/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0512 - accuracy: 0.9797 - precision: 0.9797 - recall: 0.9799 - binary_accuracy: 0.9798 - false_positives: 615.0000 - false_negatives: 611.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0554 - val_accuracy: 0.9817 - val_precision: 0.9814 - val_recall: 0.9817 - val_binary_accuracy: 0.9815 - val_false_positives: 121.0000 - val_false_negatives: 119.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 23/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0507 - accuracy: 0.9807 - precision: 0.9808 - recall: 0.9808 - binary_accuracy: 0.9808 - false_positives: 582.0000 - false_negatives: 581.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0547 - val_accuracy: 0.9809 - val_precision: 0.9811 - val_recall: 0.9812 - val_binary_accuracy: 0.9812 - val_false_positives: 123.0000 - val_false_negatives: 122.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 24/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0476 - accuracy: 0.9822 - precision: 0.9822 - recall: 0.9823 - binary_accuracy: 0.9823 - false_positives: 539.0000 - false_negatives: 537.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0610 - val_accuracy: 0.9802 - val_precision: 0.9800 - val_recall: 0.9802 - val_binary_accuracy: 0.9801 - val_false_positives: 130.0000 - val_false_negatives: 129.0000 - val_sensitivity_at_specificity: 0.9989\n",
            "Epoch 25/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0496 - accuracy: 0.9807 - precision: 0.9807 - recall: 0.9808 - binary_accuracy: 0.9808 - false_positives: 584.0000 - false_negatives: 582.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0507 - val_accuracy: 0.9828 - val_precision: 0.9829 - val_recall: 0.9828 - val_binary_accuracy: 0.9828 - val_false_positives: 111.0000 - val_false_negatives: 112.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Test loss: 0.04807567968964577\n",
            "Test accuracy: 0.9818461537361145\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 149, 2, 32)        416       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 74, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 63, 2, 64)         24640     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 31, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1984)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1984)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 3970      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 29346 (114.63 KB)\n",
            "Trainable params: 29346 (114.63 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "474/474 [==============================] - 6s 8ms/step - loss: 0.2829 - accuracy: 0.8704 - precision: 0.8698 - recall: 0.8691 - binary_accuracy: 0.8695 - false_positives: 3944.0000 - false_negatives: 3971.0000 - sensitivity_at_specificity: 0.9948 - val_loss: 0.1929 - val_accuracy: 0.9152 - val_precision: 0.9165 - val_recall: 0.9124 - val_binary_accuracy: 0.9147 - val_false_positives: 540.0000 - val_false_negatives: 569.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 2/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1714 - accuracy: 0.9297 - precision: 0.9289 - recall: 0.9284 - binary_accuracy: 0.9287 - false_positives: 2154.0000 - false_negatives: 2170.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.1303 - val_accuracy: 0.9481 - val_precision: 0.9483 - val_recall: 0.9485 - val_binary_accuracy: 0.9484 - val_false_positives: 336.0000 - val_false_negatives: 335.0000 - val_sensitivity_at_specificity: 1.0000\n",
            "Epoch 3/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1331 - accuracy: 0.9482 - precision: 0.9478 - recall: 0.9484 - binary_accuracy: 0.9481 - false_positives: 1583.0000 - false_negatives: 1566.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.1121 - val_accuracy: 0.9568 - val_precision: 0.9570 - val_recall: 0.9563 - val_binary_accuracy: 0.9567 - val_false_positives: 279.0000 - val_false_negatives: 284.0000 - val_sensitivity_at_specificity: 1.0000\n",
            "Epoch 4/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1145 - accuracy: 0.9557 - precision: 0.9561 - recall: 0.9554 - binary_accuracy: 0.9558 - false_positives: 1330.0000 - false_negatives: 1354.0000 - sensitivity_at_specificity: 0.9993 - val_loss: 0.0961 - val_accuracy: 0.9637 - val_precision: 0.9638 - val_recall: 0.9637 - val_binary_accuracy: 0.9638 - val_false_positives: 235.0000 - val_false_negatives: 236.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 5/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1044 - accuracy: 0.9613 - precision: 0.9611 - recall: 0.9608 - binary_accuracy: 0.9610 - false_positives: 1179.0000 - false_negatives: 1188.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0837 - val_accuracy: 0.9697 - val_precision: 0.9701 - val_recall: 0.9701 - val_binary_accuracy: 0.9701 - val_false_positives: 194.0000 - val_false_negatives: 194.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 6/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0908 - accuracy: 0.9649 - precision: 0.9647 - recall: 0.9649 - binary_accuracy: 0.9648 - false_positives: 1072.0000 - false_negatives: 1066.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0787 - val_accuracy: 0.9698 - val_precision: 0.9697 - val_recall: 0.9703 - val_binary_accuracy: 0.9700 - val_false_positives: 197.0000 - val_false_negatives: 193.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 7/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0868 - accuracy: 0.9674 - precision: 0.9674 - recall: 0.9675 - binary_accuracy: 0.9675 - false_positives: 988.0000 - false_negatives: 986.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0775 - val_accuracy: 0.9717 - val_precision: 0.9713 - val_recall: 0.9723 - val_binary_accuracy: 0.9718 - val_false_positives: 187.0000 - val_false_negatives: 180.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 8/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0802 - accuracy: 0.9694 - precision: 0.9692 - recall: 0.9691 - binary_accuracy: 0.9692 - false_positives: 935.0000 - false_negatives: 936.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0830 - val_accuracy: 0.9700 - val_precision: 0.9700 - val_recall: 0.9700 - val_binary_accuracy: 0.9700 - val_false_positives: 195.0000 - val_false_negatives: 195.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 9/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0767 - accuracy: 0.9709 - precision: 0.9710 - recall: 0.9709 - binary_accuracy: 0.9709 - false_positives: 880.0000 - false_negatives: 883.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0759 - val_accuracy: 0.9708 - val_precision: 0.9706 - val_recall: 0.9708 - val_binary_accuracy: 0.9707 - val_false_positives: 191.0000 - val_false_negatives: 190.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 10/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0726 - accuracy: 0.9726 - precision: 0.9728 - recall: 0.9729 - binary_accuracy: 0.9728 - false_positives: 824.0000 - false_negatives: 823.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0625 - val_accuracy: 0.9774 - val_precision: 0.9772 - val_recall: 0.9780 - val_binary_accuracy: 0.9776 - val_false_positives: 148.0000 - val_false_negatives: 143.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 11/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0694 - accuracy: 0.9743 - precision: 0.9742 - recall: 0.9742 - binary_accuracy: 0.9742 - false_positives: 783.0000 - false_negatives: 781.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0676 - val_accuracy: 0.9752 - val_precision: 0.9751 - val_recall: 0.9755 - val_binary_accuracy: 0.9753 - val_false_positives: 162.0000 - val_false_negatives: 159.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 12/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0672 - accuracy: 0.9738 - precision: 0.9736 - recall: 0.9739 - binary_accuracy: 0.9738 - false_positives: 800.0000 - false_negatives: 791.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0734 - val_accuracy: 0.9723 - val_precision: 0.9723 - val_recall: 0.9726 - val_binary_accuracy: 0.9725 - val_false_positives: 180.0000 - val_false_negatives: 178.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 13/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0632 - accuracy: 0.9761 - precision: 0.9761 - recall: 0.9763 - binary_accuracy: 0.9762 - false_positives: 724.0000 - false_negatives: 720.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0635 - val_accuracy: 0.9768 - val_precision: 0.9769 - val_recall: 0.9771 - val_binary_accuracy: 0.9770 - val_false_positives: 150.0000 - val_false_negatives: 149.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 14/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0620 - accuracy: 0.9768 - precision: 0.9768 - recall: 0.9767 - binary_accuracy: 0.9767 - false_positives: 705.0000 - false_negatives: 708.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0566 - val_accuracy: 0.9812 - val_precision: 0.9812 - val_recall: 0.9812 - val_binary_accuracy: 0.9812 - val_false_positives: 122.0000 - val_false_negatives: 122.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 15/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.0599 - accuracy: 0.9778 - precision: 0.9780 - recall: 0.9778 - binary_accuracy: 0.9779 - false_positives: 668.0000 - false_negatives: 673.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0594 - val_accuracy: 0.9789 - val_precision: 0.9789 - val_recall: 0.9788 - val_binary_accuracy: 0.9788 - val_false_positives: 137.0000 - val_false_negatives: 138.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 16/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0594 - accuracy: 0.9783 - precision: 0.9785 - recall: 0.9785 - binary_accuracy: 0.9785 - false_positives: 653.0000 - false_negatives: 653.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0552 - val_accuracy: 0.9815 - val_precision: 0.9812 - val_recall: 0.9815 - val_binary_accuracy: 0.9814 - val_false_positives: 122.0000 - val_false_negatives: 120.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 17/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0571 - accuracy: 0.9781 - precision: 0.9780 - recall: 0.9783 - binary_accuracy: 0.9781 - false_positives: 668.0000 - false_negatives: 659.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0586 - val_accuracy: 0.9788 - val_precision: 0.9791 - val_recall: 0.9785 - val_binary_accuracy: 0.9788 - val_false_positives: 136.0000 - val_false_negatives: 140.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 18/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0541 - accuracy: 0.9793 - precision: 0.9795 - recall: 0.9793 - binary_accuracy: 0.9794 - false_positives: 622.0000 - false_negatives: 628.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0609 - val_accuracy: 0.9783 - val_precision: 0.9778 - val_recall: 0.9782 - val_binary_accuracy: 0.9780 - val_false_positives: 144.0000 - val_false_negatives: 142.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 19/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0554 - accuracy: 0.9789 - precision: 0.9791 - recall: 0.9789 - binary_accuracy: 0.9790 - false_positives: 634.0000 - false_negatives: 640.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0550 - val_accuracy: 0.9812 - val_precision: 0.9811 - val_recall: 0.9812 - val_binary_accuracy: 0.9812 - val_false_positives: 123.0000 - val_false_negatives: 122.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 20/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0502 - accuracy: 0.9807 - precision: 0.9807 - recall: 0.9809 - binary_accuracy: 0.9808 - false_positives: 586.0000 - false_negatives: 580.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0556 - val_accuracy: 0.9805 - val_precision: 0.9805 - val_recall: 0.9802 - val_binary_accuracy: 0.9803 - val_false_positives: 127.0000 - val_false_negatives: 129.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 21/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0489 - accuracy: 0.9822 - precision: 0.9822 - recall: 0.9821 - binary_accuracy: 0.9822 - false_positives: 540.0000 - false_negatives: 542.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0480 - val_accuracy: 0.9831 - val_precision: 0.9831 - val_recall: 0.9829 - val_binary_accuracy: 0.9830 - val_false_positives: 110.0000 - val_false_negatives: 111.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 22/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0496 - accuracy: 0.9811 - precision: 0.9812 - recall: 0.9811 - binary_accuracy: 0.9811 - false_positives: 571.0000 - false_negatives: 573.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0523 - val_accuracy: 0.9829 - val_precision: 0.9829 - val_recall: 0.9829 - val_binary_accuracy: 0.9829 - val_false_positives: 111.0000 - val_false_negatives: 111.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 23/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0481 - accuracy: 0.9814 - precision: 0.9815 - recall: 0.9815 - binary_accuracy: 0.9815 - false_positives: 562.0000 - false_negatives: 562.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0486 - val_accuracy: 0.9843 - val_precision: 0.9840 - val_recall: 0.9845 - val_binary_accuracy: 0.9842 - val_false_positives: 104.0000 - val_false_negatives: 101.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 24/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0466 - accuracy: 0.9831 - precision: 0.9832 - recall: 0.9830 - binary_accuracy: 0.9831 - false_positives: 509.0000 - false_negatives: 515.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0535 - val_accuracy: 0.9835 - val_precision: 0.9835 - val_recall: 0.9835 - val_binary_accuracy: 0.9835 - val_false_positives: 107.0000 - val_false_negatives: 107.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 25/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0475 - accuracy: 0.9824 - precision: 0.9824 - recall: 0.9824 - binary_accuracy: 0.9824 - false_positives: 533.0000 - false_negatives: 534.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0525 - val_accuracy: 0.9814 - val_precision: 0.9812 - val_recall: 0.9814 - val_binary_accuracy: 0.9813 - val_false_positives: 122.0000 - val_false_negatives: 121.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Test loss: 0.048886507749557495\n",
            "Test accuracy: 0.9806153774261475\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 148, 2, 32)        448       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 74, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 62, 2, 64)         26688     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 31, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1984)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1984)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 3970      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31426 (122.76 KB)\n",
            "Trainable params: 31426 (122.76 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "474/474 [==============================] - 6s 8ms/step - loss: 0.2666 - accuracy: 0.8787 - precision: 0.8763 - recall: 0.8758 - binary_accuracy: 0.8761 - false_positives: 3750.0000 - false_negatives: 3768.0000 - sensitivity_at_specificity: 0.9964 - val_loss: 0.1712 - val_accuracy: 0.9255 - val_precision: 0.9251 - val_recall: 0.9271 - val_binary_accuracy: 0.9260 - val_false_positives: 488.0000 - val_false_negatives: 474.0000 - val_sensitivity_at_specificity: 1.0000\n",
            "Epoch 2/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1567 - accuracy: 0.9345 - precision: 0.9351 - recall: 0.9329 - binary_accuracy: 0.9341 - false_positives: 1964.0000 - false_negatives: 2034.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.1204 - val_accuracy: 0.9529 - val_precision: 0.9541 - val_recall: 0.9523 - val_binary_accuracy: 0.9532 - val_false_positives: 298.0000 - val_false_negatives: 310.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 3/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1217 - accuracy: 0.9528 - precision: 0.9521 - recall: 0.9521 - binary_accuracy: 0.9521 - false_positives: 1452.0000 - false_negatives: 1454.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.1057 - val_accuracy: 0.9615 - val_precision: 0.9619 - val_recall: 0.9603 - val_binary_accuracy: 0.9611 - val_false_positives: 247.0000 - val_false_negatives: 258.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 4/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1007 - accuracy: 0.9607 - precision: 0.9610 - recall: 0.9605 - binary_accuracy: 0.9608 - false_positives: 1181.0000 - false_negatives: 1199.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0860 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9674 - val_binary_accuracy: 0.9678 - val_false_positives: 206.0000 - val_false_negatives: 212.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 5/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0937 - accuracy: 0.9649 - precision: 0.9647 - recall: 0.9643 - binary_accuracy: 0.9645 - false_positives: 1070.0000 - false_negatives: 1083.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0844 - val_accuracy: 0.9680 - val_precision: 0.9677 - val_recall: 0.9680 - val_binary_accuracy: 0.9678 - val_false_positives: 210.0000 - val_false_negatives: 208.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 6/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0851 - accuracy: 0.9673 - precision: 0.9670 - recall: 0.9675 - binary_accuracy: 0.9673 - false_positives: 1000.0000 - false_negatives: 986.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0782 - val_accuracy: 0.9725 - val_precision: 0.9725 - val_recall: 0.9725 - val_binary_accuracy: 0.9725 - val_false_positives: 179.0000 - val_false_negatives: 179.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 7/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0809 - accuracy: 0.9697 - precision: 0.9699 - recall: 0.9694 - binary_accuracy: 0.9697 - false_positives: 912.0000 - false_negatives: 927.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0707 - val_accuracy: 0.9741 - val_precision: 0.9744 - val_recall: 0.9741 - val_binary_accuracy: 0.9743 - val_false_positives: 166.0000 - val_false_negatives: 168.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 8/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0758 - accuracy: 0.9717 - precision: 0.9718 - recall: 0.9716 - binary_accuracy: 0.9717 - false_positives: 855.0000 - false_negatives: 861.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0791 - val_accuracy: 0.9697 - val_precision: 0.9694 - val_recall: 0.9694 - val_binary_accuracy: 0.9694 - val_false_positives: 199.0000 - val_false_negatives: 199.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 9/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0735 - accuracy: 0.9723 - precision: 0.9723 - recall: 0.9724 - binary_accuracy: 0.9724 - false_positives: 840.0000 - false_negatives: 836.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0671 - val_accuracy: 0.9757 - val_precision: 0.9754 - val_recall: 0.9758 - val_binary_accuracy: 0.9756 - val_false_positives: 160.0000 - val_false_negatives: 157.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 10/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0733 - accuracy: 0.9735 - precision: 0.9735 - recall: 0.9733 - binary_accuracy: 0.9734 - false_positives: 802.0000 - false_negatives: 809.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0760 - val_accuracy: 0.9714 - val_precision: 0.9711 - val_recall: 0.9715 - val_binary_accuracy: 0.9713 - val_false_positives: 188.0000 - val_false_negatives: 185.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 11/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0682 - accuracy: 0.9737 - precision: 0.9736 - recall: 0.9738 - binary_accuracy: 0.9737 - false_positives: 801.0000 - false_negatives: 794.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0609 - val_accuracy: 0.9772 - val_precision: 0.9774 - val_recall: 0.9772 - val_binary_accuracy: 0.9773 - val_false_positives: 147.0000 - val_false_negatives: 148.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 12/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0678 - accuracy: 0.9740 - precision: 0.9740 - recall: 0.9740 - binary_accuracy: 0.9740 - false_positives: 788.0000 - false_negatives: 789.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0612 - val_accuracy: 0.9769 - val_precision: 0.9768 - val_recall: 0.9771 - val_binary_accuracy: 0.9769 - val_false_positives: 151.0000 - val_false_negatives: 149.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 13/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0628 - accuracy: 0.9760 - precision: 0.9760 - recall: 0.9761 - binary_accuracy: 0.9760 - false_positives: 728.0000 - false_negatives: 726.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0615 - val_accuracy: 0.9772 - val_precision: 0.9771 - val_recall: 0.9774 - val_binary_accuracy: 0.9772 - val_false_positives: 149.0000 - val_false_negatives: 147.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 14/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0599 - accuracy: 0.9776 - precision: 0.9775 - recall: 0.9776 - binary_accuracy: 0.9775 - false_positives: 684.0000 - false_negatives: 678.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0601 - val_accuracy: 0.9778 - val_precision: 0.9775 - val_recall: 0.9778 - val_binary_accuracy: 0.9777 - val_false_positives: 146.0000 - val_false_negatives: 144.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 15/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0587 - accuracy: 0.9781 - precision: 0.9781 - recall: 0.9783 - binary_accuracy: 0.9782 - false_positives: 663.0000 - false_negatives: 657.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0655 - val_accuracy: 0.9737 - val_precision: 0.9738 - val_recall: 0.9735 - val_binary_accuracy: 0.9737 - val_false_positives: 170.0000 - val_false_negatives: 172.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 16/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.0568 - accuracy: 0.9784 - precision: 0.9783 - recall: 0.9783 - binary_accuracy: 0.9783 - false_positives: 657.0000 - false_negatives: 659.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0794 - val_accuracy: 0.9688 - val_precision: 0.9688 - val_recall: 0.9685 - val_binary_accuracy: 0.9686 - val_false_positives: 203.0000 - val_false_negatives: 205.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 17/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0565 - accuracy: 0.9782 - precision: 0.9782 - recall: 0.9781 - binary_accuracy: 0.9782 - false_positives: 661.0000 - false_negatives: 664.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0543 - val_accuracy: 0.9818 - val_precision: 0.9818 - val_recall: 0.9817 - val_binary_accuracy: 0.9818 - val_false_positives: 118.0000 - val_false_negatives: 119.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 18/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0563 - accuracy: 0.9790 - precision: 0.9789 - recall: 0.9789 - binary_accuracy: 0.9789 - false_positives: 641.0000 - false_negatives: 641.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0554 - val_accuracy: 0.9797 - val_precision: 0.9798 - val_recall: 0.9795 - val_binary_accuracy: 0.9797 - val_false_positives: 131.0000 - val_false_negatives: 133.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 19/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0545 - accuracy: 0.9797 - precision: 0.9797 - recall: 0.9796 - binary_accuracy: 0.9797 - false_positives: 615.0000 - false_negatives: 619.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0556 - val_accuracy: 0.9783 - val_precision: 0.9785 - val_recall: 0.9782 - val_binary_accuracy: 0.9783 - val_false_positives: 140.0000 - val_false_negatives: 142.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 20/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0494 - accuracy: 0.9810 - precision: 0.9809 - recall: 0.9809 - binary_accuracy: 0.9809 - false_positives: 579.0000 - false_negatives: 579.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0581 - val_accuracy: 0.9792 - val_precision: 0.9792 - val_recall: 0.9791 - val_binary_accuracy: 0.9792 - val_false_positives: 135.0000 - val_false_negatives: 136.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 21/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0489 - accuracy: 0.9813 - precision: 0.9814 - recall: 0.9813 - binary_accuracy: 0.9814 - false_positives: 565.0000 - false_negatives: 566.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0534 - val_accuracy: 0.9806 - val_precision: 0.9806 - val_recall: 0.9806 - val_binary_accuracy: 0.9806 - val_false_positives: 126.0000 - val_false_negatives: 126.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 22/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0495 - accuracy: 0.9815 - precision: 0.9816 - recall: 0.9814 - binary_accuracy: 0.9815 - false_positives: 558.0000 - false_negatives: 565.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0568 - val_accuracy: 0.9806 - val_precision: 0.9806 - val_recall: 0.9805 - val_binary_accuracy: 0.9805 - val_false_positives: 126.0000 - val_false_negatives: 127.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 23/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0444 - accuracy: 0.9830 - precision: 0.9831 - recall: 0.9831 - binary_accuracy: 0.9831 - false_positives: 511.0000 - false_negatives: 513.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0535 - val_accuracy: 0.9798 - val_precision: 0.9800 - val_recall: 0.9797 - val_binary_accuracy: 0.9798 - val_false_positives: 130.0000 - val_false_negatives: 132.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 24/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0468 - accuracy: 0.9823 - precision: 0.9823 - recall: 0.9822 - binary_accuracy: 0.9822 - false_positives: 538.0000 - false_negatives: 539.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0559 - val_accuracy: 0.9794 - val_precision: 0.9795 - val_recall: 0.9794 - val_binary_accuracy: 0.9795 - val_false_positives: 133.0000 - val_false_negatives: 134.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 25/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0453 - accuracy: 0.9822 - precision: 0.9823 - recall: 0.9822 - binary_accuracy: 0.9822 - false_positives: 536.0000 - false_negatives: 541.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0536 - val_accuracy: 0.9803 - val_precision: 0.9803 - val_recall: 0.9803 - val_binary_accuracy: 0.9803 - val_false_positives: 128.0000 - val_false_negatives: 128.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Test loss: 0.04891234263777733\n",
            "Test accuracy: 0.9829230904579163\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 147, 2, 32)        480       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 73, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 60, 2, 64)         28736     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 30, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1920)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1920)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 3842      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 33378 (130.38 KB)\n",
            "Trainable params: 33378 (130.38 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "474/474 [==============================] - 6s 8ms/step - loss: 0.2640 - accuracy: 0.8811 - precision: 0.8791 - recall: 0.8805 - binary_accuracy: 0.8797 - false_positives: 3672.0000 - false_negatives: 3625.0000 - sensitivity_at_specificity: 0.9965 - val_loss: 0.1753 - val_accuracy: 0.9215 - val_precision: 0.9244 - val_recall: 0.9197 - val_binary_accuracy: 0.9222 - val_false_positives: 489.0000 - val_false_negatives: 522.0000 - val_sensitivity_at_specificity: 1.0000\n",
            "Epoch 2/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1557 - accuracy: 0.9378 - precision: 0.9376 - recall: 0.9362 - binary_accuracy: 0.9369 - false_positives: 1889.0000 - false_negatives: 1936.0000 - sensitivity_at_specificity: 0.9992 - val_loss: 0.1194 - val_accuracy: 0.9506 - val_precision: 0.9508 - val_recall: 0.9518 - val_binary_accuracy: 0.9513 - val_false_positives: 320.0000 - val_false_negatives: 313.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 3/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1199 - accuracy: 0.9534 - precision: 0.9534 - recall: 0.9527 - binary_accuracy: 0.9531 - false_positives: 1411.0000 - false_negatives: 1434.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0986 - val_accuracy: 0.9637 - val_precision: 0.9628 - val_recall: 0.9646 - val_binary_accuracy: 0.9637 - val_false_positives: 242.0000 - val_false_negatives: 230.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 4/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1044 - accuracy: 0.9612 - precision: 0.9613 - recall: 0.9613 - binary_accuracy: 0.9613 - false_positives: 1175.0000 - false_negatives: 1174.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0886 - val_accuracy: 0.9677 - val_precision: 0.9675 - val_recall: 0.9674 - val_binary_accuracy: 0.9675 - val_false_positives: 211.0000 - val_false_negatives: 212.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 5/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0953 - accuracy: 0.9647 - precision: 0.9647 - recall: 0.9648 - binary_accuracy: 0.9648 - false_positives: 1070.0000 - false_negatives: 1067.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0815 - val_accuracy: 0.9700 - val_precision: 0.9699 - val_recall: 0.9703 - val_binary_accuracy: 0.9701 - val_false_positives: 196.0000 - val_false_negatives: 193.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 6/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0860 - accuracy: 0.9676 - precision: 0.9669 - recall: 0.9679 - binary_accuracy: 0.9674 - false_positives: 1004.0000 - false_negatives: 974.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0763 - val_accuracy: 0.9712 - val_precision: 0.9715 - val_recall: 0.9709 - val_binary_accuracy: 0.9712 - val_false_positives: 185.0000 - val_false_negatives: 189.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 7/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0820 - accuracy: 0.9694 - precision: 0.9689 - recall: 0.9693 - binary_accuracy: 0.9691 - false_positives: 942.0000 - false_negatives: 932.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0765 - val_accuracy: 0.9721 - val_precision: 0.9723 - val_recall: 0.9721 - val_binary_accuracy: 0.9722 - val_false_positives: 180.0000 - val_false_negatives: 181.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 8/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0770 - accuracy: 0.9712 - precision: 0.9712 - recall: 0.9714 - binary_accuracy: 0.9713 - false_positives: 875.0000 - false_negatives: 868.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0673 - val_accuracy: 0.9738 - val_precision: 0.9741 - val_recall: 0.9740 - val_binary_accuracy: 0.9741 - val_false_positives: 168.0000 - val_false_negatives: 169.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 9/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0729 - accuracy: 0.9730 - precision: 0.9728 - recall: 0.9729 - binary_accuracy: 0.9728 - false_positives: 826.0000 - false_negatives: 822.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0652 - val_accuracy: 0.9766 - val_precision: 0.9771 - val_recall: 0.9766 - val_binary_accuracy: 0.9768 - val_false_positives: 149.0000 - val_false_negatives: 152.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 10/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0712 - accuracy: 0.9727 - precision: 0.9728 - recall: 0.9728 - binary_accuracy: 0.9728 - false_positives: 826.0000 - false_negatives: 825.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0642 - val_accuracy: 0.9757 - val_precision: 0.9755 - val_recall: 0.9752 - val_binary_accuracy: 0.9754 - val_false_positives: 159.0000 - val_false_negatives: 161.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 11/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0661 - accuracy: 0.9753 - precision: 0.9751 - recall: 0.9752 - binary_accuracy: 0.9752 - false_positives: 755.0000 - false_negatives: 752.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0643 - val_accuracy: 0.9778 - val_precision: 0.9778 - val_recall: 0.9780 - val_binary_accuracy: 0.9779 - val_false_positives: 144.0000 - val_false_negatives: 143.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 12/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0645 - accuracy: 0.9761 - precision: 0.9763 - recall: 0.9759 - binary_accuracy: 0.9761 - false_positives: 720.0000 - false_negatives: 732.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0605 - val_accuracy: 0.9783 - val_precision: 0.9782 - val_recall: 0.9785 - val_binary_accuracy: 0.9783 - val_false_positives: 142.0000 - val_false_negatives: 140.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 13/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0620 - accuracy: 0.9764 - precision: 0.9762 - recall: 0.9763 - binary_accuracy: 0.9762 - false_positives: 723.0000 - false_negatives: 719.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0579 - val_accuracy: 0.9814 - val_precision: 0.9812 - val_recall: 0.9814 - val_binary_accuracy: 0.9813 - val_false_positives: 122.0000 - val_false_negatives: 121.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 14/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0585 - accuracy: 0.9782 - precision: 0.9784 - recall: 0.9784 - binary_accuracy: 0.9784 - false_positives: 655.0000 - false_negatives: 655.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0645 - val_accuracy: 0.9771 - val_precision: 0.9771 - val_recall: 0.9772 - val_binary_accuracy: 0.9772 - val_false_positives: 149.0000 - val_false_negatives: 148.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 15/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.0582 - accuracy: 0.9787 - precision: 0.9787 - recall: 0.9787 - binary_accuracy: 0.9787 - false_positives: 645.0000 - false_negatives: 645.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0591 - val_accuracy: 0.9783 - val_precision: 0.9782 - val_recall: 0.9783 - val_binary_accuracy: 0.9782 - val_false_positives: 142.0000 - val_false_negatives: 141.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 16/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0530 - accuracy: 0.9798 - precision: 0.9798 - recall: 0.9800 - binary_accuracy: 0.9799 - false_positives: 612.0000 - false_negatives: 608.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0616 - val_accuracy: 0.9758 - val_precision: 0.9755 - val_recall: 0.9758 - val_binary_accuracy: 0.9757 - val_false_positives: 159.0000 - val_false_negatives: 157.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 17/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0546 - accuracy: 0.9792 - precision: 0.9793 - recall: 0.9791 - binary_accuracy: 0.9792 - false_positives: 629.0000 - false_negatives: 634.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0527 - val_accuracy: 0.9825 - val_precision: 0.9825 - val_recall: 0.9826 - val_binary_accuracy: 0.9825 - val_false_positives: 114.0000 - val_false_negatives: 113.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 18/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0516 - accuracy: 0.9806 - precision: 0.9805 - recall: 0.9806 - binary_accuracy: 0.9805 - false_positives: 592.0000 - false_negatives: 588.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0540 - val_accuracy: 0.9806 - val_precision: 0.9805 - val_recall: 0.9806 - val_binary_accuracy: 0.9805 - val_false_positives: 127.0000 - val_false_negatives: 126.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 19/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0507 - accuracy: 0.9806 - precision: 0.9806 - recall: 0.9807 - binary_accuracy: 0.9807 - false_positives: 588.0000 - false_negatives: 585.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0507 - val_accuracy: 0.9835 - val_precision: 0.9835 - val_recall: 0.9835 - val_binary_accuracy: 0.9835 - val_false_positives: 107.0000 - val_false_negatives: 107.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 20/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0478 - accuracy: 0.9821 - precision: 0.9820 - recall: 0.9819 - binary_accuracy: 0.9820 - false_positives: 545.0000 - false_negatives: 549.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0523 - val_accuracy: 0.9822 - val_precision: 0.9823 - val_recall: 0.9822 - val_binary_accuracy: 0.9822 - val_false_positives: 115.0000 - val_false_negatives: 116.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 21/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0471 - accuracy: 0.9819 - precision: 0.9820 - recall: 0.9820 - binary_accuracy: 0.9820 - false_positives: 547.0000 - false_negatives: 547.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0522 - val_accuracy: 0.9818 - val_precision: 0.9818 - val_recall: 0.9818 - val_binary_accuracy: 0.9818 - val_false_positives: 118.0000 - val_false_negatives: 118.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 22/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0451 - accuracy: 0.9827 - precision: 0.9829 - recall: 0.9827 - binary_accuracy: 0.9828 - false_positives: 520.0000 - false_negatives: 524.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0581 - val_accuracy: 0.9786 - val_precision: 0.9786 - val_recall: 0.9788 - val_binary_accuracy: 0.9787 - val_false_positives: 139.0000 - val_false_negatives: 138.0000 - val_sensitivity_at_specificity: 0.9989\n",
            "Epoch 23/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0471 - accuracy: 0.9832 - precision: 0.9831 - recall: 0.9832 - binary_accuracy: 0.9832 - false_positives: 512.0000 - false_negatives: 508.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0512 - val_accuracy: 0.9829 - val_precision: 0.9829 - val_recall: 0.9829 - val_binary_accuracy: 0.9829 - val_false_positives: 111.0000 - val_false_negatives: 111.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 24/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0425 - accuracy: 0.9845 - precision: 0.9843 - recall: 0.9845 - binary_accuracy: 0.9844 - false_positives: 475.0000 - false_negatives: 469.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0641 - val_accuracy: 0.9777 - val_precision: 0.9778 - val_recall: 0.9777 - val_binary_accuracy: 0.9778 - val_false_positives: 144.0000 - val_false_negatives: 145.0000 - val_sensitivity_at_specificity: 0.9988\n",
            "Epoch 25/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0434 - accuracy: 0.9842 - precision: 0.9842 - recall: 0.9840 - binary_accuracy: 0.9841 - false_positives: 480.0000 - false_negatives: 485.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0544 - val_accuracy: 0.9814 - val_precision: 0.9815 - val_recall: 0.9814 - val_binary_accuracy: 0.9815 - val_false_positives: 120.0000 - val_false_negatives: 121.0000 - val_sensitivity_at_specificity: 0.9989\n",
            "Test loss: 0.04869687929749489\n",
            "Test accuracy: 0.982769250869751\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 146, 2, 32)        512       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 73, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 59, 2, 64)         30784     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 29, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1856)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1856)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 3714      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 35330 (138.01 KB)\n",
            "Trainable params: 35330 (138.01 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "474/474 [==============================] - 6s 8ms/step - loss: 0.2686 - accuracy: 0.8790 - precision: 0.8770 - recall: 0.8768 - binary_accuracy: 0.8769 - false_positives: 3731.0000 - false_negatives: 3735.0000 - sensitivity_at_specificity: 0.9957 - val_loss: 0.1758 - val_accuracy: 0.9257 - val_precision: 0.9253 - val_recall: 0.9257 - val_binary_accuracy: 0.9255 - val_false_positives: 486.0000 - val_false_negatives: 483.0000 - val_sensitivity_at_specificity: 1.0000\n",
            "Epoch 2/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1582 - accuracy: 0.9345 - precision: 0.9346 - recall: 0.9343 - binary_accuracy: 0.9345 - false_positives: 1984.0000 - false_negatives: 1992.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.1701 - val_accuracy: 0.9246 - val_precision: 0.9234 - val_recall: 0.9252 - val_binary_accuracy: 0.9242 - val_false_positives: 499.0000 - val_false_negatives: 486.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 3/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1219 - accuracy: 0.9518 - precision: 0.9508 - recall: 0.9519 - binary_accuracy: 0.9513 - false_positives: 1493.0000 - false_negatives: 1460.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0959 - val_accuracy: 0.9645 - val_precision: 0.9638 - val_recall: 0.9655 - val_binary_accuracy: 0.9646 - val_false_positives: 236.0000 - val_false_negatives: 224.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 4/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1019 - accuracy: 0.9608 - precision: 0.9607 - recall: 0.9605 - binary_accuracy: 0.9606 - false_positives: 1192.0000 - false_negatives: 1197.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0837 - val_accuracy: 0.9709 - val_precision: 0.9713 - val_recall: 0.9700 - val_binary_accuracy: 0.9707 - val_false_positives: 186.0000 - val_false_negatives: 195.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 5/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0908 - accuracy: 0.9648 - precision: 0.9645 - recall: 0.9648 - binary_accuracy: 0.9646 - false_positives: 1078.0000 - false_negatives: 1068.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.0802 - val_accuracy: 0.9715 - val_precision: 0.9714 - val_recall: 0.9711 - val_binary_accuracy: 0.9712 - val_false_positives: 186.0000 - val_false_negatives: 188.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 6/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0846 - accuracy: 0.9668 - precision: 0.9671 - recall: 0.9670 - binary_accuracy: 0.9671 - false_positives: 997.0000 - false_negatives: 1000.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0775 - val_accuracy: 0.9728 - val_precision: 0.9735 - val_recall: 0.9723 - val_binary_accuracy: 0.9729 - val_false_positives: 172.0000 - val_false_negatives: 180.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 7/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0762 - accuracy: 0.9717 - precision: 0.9717 - recall: 0.9715 - binary_accuracy: 0.9716 - false_positives: 859.0000 - false_negatives: 863.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0696 - val_accuracy: 0.9732 - val_precision: 0.9735 - val_recall: 0.9726 - val_binary_accuracy: 0.9731 - val_false_positives: 172.0000 - val_false_negatives: 178.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 8/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0750 - accuracy: 0.9723 - precision: 0.9721 - recall: 0.9718 - binary_accuracy: 0.9720 - false_positives: 845.0000 - false_negatives: 856.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0648 - val_accuracy: 0.9774 - val_precision: 0.9775 - val_recall: 0.9774 - val_binary_accuracy: 0.9775 - val_false_positives: 146.0000 - val_false_negatives: 147.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 9/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0699 - accuracy: 0.9737 - precision: 0.9738 - recall: 0.9735 - binary_accuracy: 0.9737 - false_positives: 795.0000 - false_negatives: 803.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0613 - val_accuracy: 0.9786 - val_precision: 0.9786 - val_recall: 0.9785 - val_binary_accuracy: 0.9785 - val_false_positives: 139.0000 - val_false_negatives: 140.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 10/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0662 - accuracy: 0.9748 - precision: 0.9749 - recall: 0.9747 - binary_accuracy: 0.9748 - false_positives: 762.0000 - false_negatives: 767.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0676 - val_accuracy: 0.9757 - val_precision: 0.9754 - val_recall: 0.9758 - val_binary_accuracy: 0.9756 - val_false_positives: 160.0000 - val_false_negatives: 157.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 11/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0628 - accuracy: 0.9766 - precision: 0.9765 - recall: 0.9764 - binary_accuracy: 0.9764 - false_positives: 713.0000 - false_negatives: 717.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0583 - val_accuracy: 0.9809 - val_precision: 0.9808 - val_recall: 0.9809 - val_binary_accuracy: 0.9808 - val_false_positives: 125.0000 - val_false_negatives: 124.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 12/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0625 - accuracy: 0.9767 - precision: 0.9766 - recall: 0.9768 - binary_accuracy: 0.9767 - false_positives: 711.0000 - false_negatives: 703.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0562 - val_accuracy: 0.9812 - val_precision: 0.9812 - val_recall: 0.9811 - val_binary_accuracy: 0.9812 - val_false_positives: 122.0000 - val_false_negatives: 123.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 13/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0590 - accuracy: 0.9780 - precision: 0.9776 - recall: 0.9783 - binary_accuracy: 0.9780 - false_positives: 680.0000 - false_negatives: 657.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0571 - val_accuracy: 0.9800 - val_precision: 0.9797 - val_recall: 0.9805 - val_binary_accuracy: 0.9801 - val_false_positives: 132.0000 - val_false_negatives: 127.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 14/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0549 - accuracy: 0.9789 - precision: 0.9790 - recall: 0.9789 - binary_accuracy: 0.9790 - false_positives: 636.0000 - false_negatives: 640.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0608 - val_accuracy: 0.9792 - val_precision: 0.9792 - val_recall: 0.9797 - val_binary_accuracy: 0.9795 - val_false_positives: 135.0000 - val_false_negatives: 132.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 15/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0545 - accuracy: 0.9799 - precision: 0.9800 - recall: 0.9802 - binary_accuracy: 0.9801 - false_positives: 607.0000 - false_negatives: 600.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0562 - val_accuracy: 0.9802 - val_precision: 0.9803 - val_recall: 0.9802 - val_binary_accuracy: 0.9802 - val_false_positives: 128.0000 - val_false_negatives: 129.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 16/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0513 - accuracy: 0.9807 - precision: 0.9808 - recall: 0.9807 - binary_accuracy: 0.9808 - false_positives: 583.0000 - false_negatives: 584.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0510 - val_accuracy: 0.9837 - val_precision: 0.9832 - val_recall: 0.9840 - val_binary_accuracy: 0.9836 - val_false_positives: 109.0000 - val_false_negatives: 104.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 17/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0515 - accuracy: 0.9806 - precision: 0.9807 - recall: 0.9806 - binary_accuracy: 0.9806 - false_positives: 586.0000 - false_negatives: 588.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0522 - val_accuracy: 0.9818 - val_precision: 0.9815 - val_recall: 0.9820 - val_binary_accuracy: 0.9818 - val_false_positives: 120.0000 - val_false_negatives: 117.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 18/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0505 - accuracy: 0.9808 - precision: 0.9808 - recall: 0.9809 - binary_accuracy: 0.9808 - false_positives: 582.0000 - false_negatives: 580.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0551 - val_accuracy: 0.9802 - val_precision: 0.9802 - val_recall: 0.9802 - val_binary_accuracy: 0.9802 - val_false_positives: 129.0000 - val_false_negatives: 129.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 19/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0518 - accuracy: 0.9803 - precision: 0.9803 - recall: 0.9804 - binary_accuracy: 0.9803 - false_positives: 599.0000 - false_negatives: 593.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0592 - val_accuracy: 0.9788 - val_precision: 0.9788 - val_recall: 0.9786 - val_binary_accuracy: 0.9787 - val_false_positives: 138.0000 - val_false_negatives: 139.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 20/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0476 - accuracy: 0.9821 - precision: 0.9819 - recall: 0.9821 - binary_accuracy: 0.9820 - false_positives: 549.0000 - false_negatives: 543.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0510 - val_accuracy: 0.9840 - val_precision: 0.9838 - val_recall: 0.9840 - val_binary_accuracy: 0.9839 - val_false_positives: 105.0000 - val_false_negatives: 104.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 21/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0468 - accuracy: 0.9828 - precision: 0.9829 - recall: 0.9828 - binary_accuracy: 0.9829 - false_positives: 518.0000 - false_negatives: 521.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0520 - val_accuracy: 0.9828 - val_precision: 0.9829 - val_recall: 0.9826 - val_binary_accuracy: 0.9828 - val_false_positives: 111.0000 - val_false_negatives: 113.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 22/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0430 - accuracy: 0.9841 - precision: 0.9840 - recall: 0.9840 - binary_accuracy: 0.9840 - false_positives: 485.0000 - false_negatives: 485.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0548 - val_accuracy: 0.9825 - val_precision: 0.9826 - val_recall: 0.9823 - val_binary_accuracy: 0.9825 - val_false_positives: 113.0000 - val_false_negatives: 115.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 23/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0439 - accuracy: 0.9832 - precision: 0.9832 - recall: 0.9832 - binary_accuracy: 0.9832 - false_positives: 511.0000 - false_negatives: 508.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0492 - val_accuracy: 0.9840 - val_precision: 0.9841 - val_recall: 0.9840 - val_binary_accuracy: 0.9841 - val_false_positives: 103.0000 - val_false_negatives: 104.0000 - val_sensitivity_at_specificity: 0.9988\n",
            "Epoch 24/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0425 - accuracy: 0.9836 - precision: 0.9838 - recall: 0.9835 - binary_accuracy: 0.9837 - false_positives: 491.0000 - false_negatives: 499.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0495 - val_accuracy: 0.9842 - val_precision: 0.9840 - val_recall: 0.9842 - val_binary_accuracy: 0.9841 - val_false_positives: 104.0000 - val_false_negatives: 103.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 25/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0404 - accuracy: 0.9845 - precision: 0.9846 - recall: 0.9844 - binary_accuracy: 0.9845 - false_positives: 468.0000 - false_negatives: 472.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0559 - val_accuracy: 0.9809 - val_precision: 0.9808 - val_recall: 0.9809 - val_binary_accuracy: 0.9808 - val_false_positives: 125.0000 - val_false_negatives: 124.0000 - val_sensitivity_at_specificity: 0.9988\n",
            "Test loss: 0.049796611070632935\n",
            "Test accuracy: 0.9821538329124451\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 145, 2, 32)        544       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 72, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 57, 2, 64)         32832     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 28, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1792)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1792)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 3586      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 37282 (145.63 KB)\n",
            "Trainable params: 37282 (145.63 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "474/474 [==============================] - 6s 8ms/step - loss: 0.2657 - accuracy: 0.8804 - precision: 0.8786 - recall: 0.8770 - binary_accuracy: 0.8779 - false_positives: 3675.0000 - false_negatives: 3729.0000 - sensitivity_at_specificity: 0.9964 - val_loss: 0.1651 - val_accuracy: 0.9297 - val_precision: 0.9323 - val_recall: 0.9257 - val_binary_accuracy: 0.9292 - val_false_positives: 437.0000 - val_false_negatives: 483.0000 - val_sensitivity_at_specificity: 1.0000\n",
            "Epoch 2/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1509 - accuracy: 0.9376 - precision: 0.9378 - recall: 0.9368 - binary_accuracy: 0.9373 - false_positives: 1884.0000 - false_negatives: 1918.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.1166 - val_accuracy: 0.9543 - val_precision: 0.9540 - val_recall: 0.9543 - val_binary_accuracy: 0.9541 - val_false_positives: 299.0000 - val_false_negatives: 297.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 3/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1163 - accuracy: 0.9551 - precision: 0.9545 - recall: 0.9551 - binary_accuracy: 0.9548 - false_positives: 1381.0000 - false_negatives: 1361.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0941 - val_accuracy: 0.9612 - val_precision: 0.9628 - val_recall: 0.9598 - val_binary_accuracy: 0.9614 - val_false_positives: 241.0000 - val_false_negatives: 261.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 4/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1046 - accuracy: 0.9597 - precision: 0.9601 - recall: 0.9593 - binary_accuracy: 0.9597 - false_positives: 1210.0000 - false_negatives: 1234.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.0862 - val_accuracy: 0.9685 - val_precision: 0.9689 - val_recall: 0.9680 - val_binary_accuracy: 0.9685 - val_false_positives: 202.0000 - val_false_negatives: 208.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 5/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0906 - accuracy: 0.9656 - precision: 0.9653 - recall: 0.9650 - binary_accuracy: 0.9652 - false_positives: 1051.0000 - false_negatives: 1061.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0749 - val_accuracy: 0.9718 - val_precision: 0.9718 - val_recall: 0.9720 - val_binary_accuracy: 0.9719 - val_false_positives: 183.0000 - val_false_negatives: 182.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 6/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0806 - accuracy: 0.9692 - precision: 0.9697 - recall: 0.9690 - binary_accuracy: 0.9694 - false_positives: 917.0000 - false_negatives: 939.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0720 - val_accuracy: 0.9734 - val_precision: 0.9740 - val_recall: 0.9732 - val_binary_accuracy: 0.9736 - val_false_positives: 169.0000 - val_false_negatives: 174.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 7/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0762 - accuracy: 0.9714 - precision: 0.9709 - recall: 0.9716 - binary_accuracy: 0.9712 - false_positives: 883.0000 - false_negatives: 861.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.0706 - val_accuracy: 0.9731 - val_precision: 0.9732 - val_recall: 0.9731 - val_binary_accuracy: 0.9731 - val_false_positives: 174.0000 - val_false_negatives: 175.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 8/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0734 - accuracy: 0.9728 - precision: 0.9730 - recall: 0.9730 - binary_accuracy: 0.9730 - false_positives: 818.0000 - false_negatives: 819.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.0595 - val_accuracy: 0.9788 - val_precision: 0.9785 - val_recall: 0.9788 - val_binary_accuracy: 0.9786 - val_false_positives: 140.0000 - val_false_negatives: 138.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 9/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0687 - accuracy: 0.9736 - precision: 0.9735 - recall: 0.9737 - binary_accuracy: 0.9736 - false_positives: 805.0000 - false_negatives: 797.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0597 - val_accuracy: 0.9792 - val_precision: 0.9797 - val_recall: 0.9783 - val_binary_accuracy: 0.9790 - val_false_positives: 132.0000 - val_false_negatives: 141.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 10/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0616 - accuracy: 0.9761 - precision: 0.9760 - recall: 0.9762 - binary_accuracy: 0.9761 - false_positives: 729.0000 - false_negatives: 721.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0625 - val_accuracy: 0.9772 - val_precision: 0.9772 - val_recall: 0.9777 - val_binary_accuracy: 0.9775 - val_false_positives: 148.0000 - val_false_negatives: 145.0000 - val_sensitivity_at_specificity: 0.9989\n",
            "Epoch 11/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0626 - accuracy: 0.9761 - precision: 0.9759 - recall: 0.9762 - binary_accuracy: 0.9760 - false_positives: 731.0000 - false_negatives: 722.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0567 - val_accuracy: 0.9823 - val_precision: 0.9823 - val_recall: 0.9823 - val_binary_accuracy: 0.9823 - val_false_positives: 115.0000 - val_false_negatives: 115.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 12/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0586 - accuracy: 0.9777 - precision: 0.9774 - recall: 0.9773 - binary_accuracy: 0.9774 - false_positives: 685.0000 - false_negatives: 687.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0584 - val_accuracy: 0.9788 - val_precision: 0.9789 - val_recall: 0.9788 - val_binary_accuracy: 0.9788 - val_false_positives: 137.0000 - val_false_negatives: 138.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 13/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0565 - accuracy: 0.9787 - precision: 0.9786 - recall: 0.9788 - binary_accuracy: 0.9787 - false_positives: 649.0000 - false_negatives: 644.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0537 - val_accuracy: 0.9808 - val_precision: 0.9809 - val_recall: 0.9803 - val_binary_accuracy: 0.9806 - val_false_positives: 124.0000 - val_false_negatives: 128.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 14/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0543 - accuracy: 0.9790 - precision: 0.9789 - recall: 0.9791 - binary_accuracy: 0.9790 - false_positives: 640.0000 - false_negatives: 633.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0536 - val_accuracy: 0.9818 - val_precision: 0.9820 - val_recall: 0.9815 - val_binary_accuracy: 0.9818 - val_false_positives: 117.0000 - val_false_negatives: 120.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 15/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0533 - accuracy: 0.9798 - precision: 0.9798 - recall: 0.9797 - binary_accuracy: 0.9798 - false_positives: 612.0000 - false_negatives: 615.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0578 - val_accuracy: 0.9795 - val_precision: 0.9794 - val_recall: 0.9797 - val_binary_accuracy: 0.9795 - val_false_positives: 134.0000 - val_false_negatives: 132.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 16/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0528 - accuracy: 0.9803 - precision: 0.9801 - recall: 0.9804 - binary_accuracy: 0.9803 - false_positives: 603.0000 - false_negatives: 594.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0588 - val_accuracy: 0.9778 - val_precision: 0.9777 - val_recall: 0.9780 - val_binary_accuracy: 0.9778 - val_false_positives: 145.0000 - val_false_negatives: 143.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 17/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0495 - accuracy: 0.9812 - precision: 0.9812 - recall: 0.9813 - binary_accuracy: 0.9813 - false_positives: 570.0000 - false_negatives: 567.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0506 - val_accuracy: 0.9837 - val_precision: 0.9835 - val_recall: 0.9837 - val_binary_accuracy: 0.9836 - val_false_positives: 107.0000 - val_false_negatives: 106.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 18/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0470 - accuracy: 0.9826 - precision: 0.9825 - recall: 0.9827 - binary_accuracy: 0.9826 - false_positives: 532.0000 - false_negatives: 525.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0489 - val_accuracy: 0.9835 - val_precision: 0.9835 - val_recall: 0.9834 - val_binary_accuracy: 0.9835 - val_false_positives: 107.0000 - val_false_negatives: 108.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 19/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0466 - accuracy: 0.9824 - precision: 0.9823 - recall: 0.9823 - binary_accuracy: 0.9823 - false_positives: 538.0000 - false_negatives: 537.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0497 - val_accuracy: 0.9838 - val_precision: 0.9840 - val_recall: 0.9840 - val_binary_accuracy: 0.9840 - val_false_positives: 104.0000 - val_false_negatives: 104.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 20/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0460 - accuracy: 0.9827 - precision: 0.9827 - recall: 0.9826 - binary_accuracy: 0.9826 - false_positives: 526.0000 - false_negatives: 527.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0571 - val_accuracy: 0.9800 - val_precision: 0.9800 - val_recall: 0.9800 - val_binary_accuracy: 0.9800 - val_false_positives: 130.0000 - val_false_negatives: 130.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 21/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0450 - accuracy: 0.9829 - precision: 0.9828 - recall: 0.9829 - binary_accuracy: 0.9829 - false_positives: 521.0000 - false_negatives: 518.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0487 - val_accuracy: 0.9852 - val_precision: 0.9855 - val_recall: 0.9855 - val_binary_accuracy: 0.9855 - val_false_positives: 94.0000 - val_false_negatives: 94.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 22/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0422 - accuracy: 0.9832 - precision: 0.9832 - recall: 0.9832 - binary_accuracy: 0.9832 - false_positives: 508.0000 - false_negatives: 509.0000 - sensitivity_at_specificity: 0.9999 - val_loss: 0.0502 - val_accuracy: 0.9829 - val_precision: 0.9828 - val_recall: 0.9829 - val_binary_accuracy: 0.9828 - val_false_positives: 112.0000 - val_false_negatives: 111.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 23/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0413 - accuracy: 0.9840 - precision: 0.9842 - recall: 0.9840 - binary_accuracy: 0.9841 - false_positives: 480.0000 - false_negatives: 486.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0509 - val_accuracy: 0.9837 - val_precision: 0.9835 - val_recall: 0.9837 - val_binary_accuracy: 0.9836 - val_false_positives: 107.0000 - val_false_negatives: 106.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 24/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0415 - accuracy: 0.9843 - precision: 0.9844 - recall: 0.9842 - binary_accuracy: 0.9843 - false_positives: 473.0000 - false_negatives: 480.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0527 - val_accuracy: 0.9818 - val_precision: 0.9818 - val_recall: 0.9820 - val_binary_accuracy: 0.9819 - val_false_positives: 118.0000 - val_false_negatives: 117.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 25/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0403 - accuracy: 0.9836 - precision: 0.9838 - recall: 0.9839 - binary_accuracy: 0.9838 - false_positives: 491.0000 - false_negatives: 489.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0509 - val_accuracy: 0.9829 - val_precision: 0.9831 - val_recall: 0.9829 - val_binary_accuracy: 0.9830 - val_false_positives: 110.0000 - val_false_negatives: 111.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Test loss: 0.04079541191458702\n",
            "Test accuracy: 0.9866153597831726\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 144, 2, 32)        576       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 72, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 56, 2, 64)         34880     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 28, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1792)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1792)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 3586      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 39362 (153.76 KB)\n",
            "Trainable params: 39362 (153.76 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "474/474 [==============================] - 6s 8ms/step - loss: 0.2585 - accuracy: 0.8835 - precision: 0.8816 - recall: 0.8816 - binary_accuracy: 0.8816 - false_positives: 3591.0000 - false_negatives: 3592.0000 - sensitivity_at_specificity: 0.9969 - val_loss: 0.1692 - val_accuracy: 0.9240 - val_precision: 0.9240 - val_recall: 0.9244 - val_binary_accuracy: 0.9242 - val_false_positives: 494.0000 - val_false_negatives: 491.0000 - val_sensitivity_at_specificity: 1.0000\n",
            "Epoch 2/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1472 - accuracy: 0.9399 - precision: 0.9398 - recall: 0.9389 - binary_accuracy: 0.9394 - false_positives: 1824.0000 - false_negatives: 1853.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.1154 - val_accuracy: 0.9612 - val_precision: 0.9622 - val_recall: 0.9600 - val_binary_accuracy: 0.9611 - val_false_positives: 245.0000 - val_false_negatives: 260.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 3/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1132 - accuracy: 0.9574 - precision: 0.9568 - recall: 0.9566 - binary_accuracy: 0.9567 - false_positives: 1310.0000 - false_negatives: 1317.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0876 - val_accuracy: 0.9680 - val_precision: 0.9686 - val_recall: 0.9668 - val_binary_accuracy: 0.9677 - val_false_positives: 204.0000 - val_false_negatives: 216.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 4/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0992 - accuracy: 0.9636 - precision: 0.9628 - recall: 0.9634 - binary_accuracy: 0.9631 - false_positives: 1128.0000 - false_negatives: 1111.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0748 - val_accuracy: 0.9721 - val_precision: 0.9730 - val_recall: 0.9721 - val_binary_accuracy: 0.9726 - val_false_positives: 175.0000 - val_false_negatives: 181.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 5/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0867 - accuracy: 0.9670 - precision: 0.9671 - recall: 0.9668 - binary_accuracy: 0.9670 - false_positives: 996.0000 - false_negatives: 1006.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0724 - val_accuracy: 0.9745 - val_precision: 0.9749 - val_recall: 0.9743 - val_binary_accuracy: 0.9746 - val_false_positives: 163.0000 - val_false_negatives: 167.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 6/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0812 - accuracy: 0.9696 - precision: 0.9697 - recall: 0.9695 - binary_accuracy: 0.9696 - false_positives: 920.0000 - false_negatives: 925.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0727 - val_accuracy: 0.9741 - val_precision: 0.9740 - val_recall: 0.9740 - val_binary_accuracy: 0.9740 - val_false_positives: 169.0000 - val_false_negatives: 169.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 7/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0741 - accuracy: 0.9729 - precision: 0.9729 - recall: 0.9729 - binary_accuracy: 0.9729 - false_positives: 821.0000 - false_negatives: 822.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0713 - val_accuracy: 0.9745 - val_precision: 0.9743 - val_recall: 0.9746 - val_binary_accuracy: 0.9745 - val_false_positives: 167.0000 - val_false_negatives: 165.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 8/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0710 - accuracy: 0.9747 - precision: 0.9747 - recall: 0.9747 - binary_accuracy: 0.9747 - false_positives: 768.0000 - false_negatives: 767.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0603 - val_accuracy: 0.9788 - val_precision: 0.9788 - val_recall: 0.9788 - val_binary_accuracy: 0.9788 - val_false_positives: 138.0000 - val_false_negatives: 138.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 9/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0682 - accuracy: 0.9749 - precision: 0.9747 - recall: 0.9748 - binary_accuracy: 0.9748 - false_positives: 767.0000 - false_negatives: 763.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0702 - val_accuracy: 0.9731 - val_precision: 0.9734 - val_recall: 0.9735 - val_binary_accuracy: 0.9735 - val_false_positives: 173.0000 - val_false_negatives: 172.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 10/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0648 - accuracy: 0.9760 - precision: 0.9757 - recall: 0.9763 - binary_accuracy: 0.9760 - false_positives: 736.0000 - false_negatives: 720.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0567 - val_accuracy: 0.9795 - val_precision: 0.9794 - val_recall: 0.9794 - val_binary_accuracy: 0.9794 - val_false_positives: 134.0000 - val_false_negatives: 134.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 11/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0634 - accuracy: 0.9762 - precision: 0.9763 - recall: 0.9763 - binary_accuracy: 0.9763 - false_positives: 719.0000 - false_negatives: 720.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.0584 - val_accuracy: 0.9792 - val_precision: 0.9794 - val_recall: 0.9792 - val_binary_accuracy: 0.9793 - val_false_positives: 134.0000 - val_false_negatives: 135.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 12/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.0570 - accuracy: 0.9795 - precision: 0.9795 - recall: 0.9795 - binary_accuracy: 0.9795 - false_positives: 622.0000 - false_negatives: 623.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0524 - val_accuracy: 0.9808 - val_precision: 0.9812 - val_recall: 0.9812 - val_binary_accuracy: 0.9812 - val_false_positives: 122.0000 - val_false_negatives: 122.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 13/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0563 - accuracy: 0.9795 - precision: 0.9794 - recall: 0.9797 - binary_accuracy: 0.9795 - false_positives: 624.0000 - false_negatives: 617.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0549 - val_accuracy: 0.9805 - val_precision: 0.9806 - val_recall: 0.9800 - val_binary_accuracy: 0.9803 - val_false_positives: 126.0000 - val_false_negatives: 130.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 14/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0540 - accuracy: 0.9796 - precision: 0.9792 - recall: 0.9795 - binary_accuracy: 0.9794 - false_positives: 630.0000 - false_negatives: 621.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0491 - val_accuracy: 0.9832 - val_precision: 0.9832 - val_recall: 0.9832 - val_binary_accuracy: 0.9832 - val_false_positives: 109.0000 - val_false_negatives: 109.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 15/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0513 - accuracy: 0.9814 - precision: 0.9814 - recall: 0.9813 - binary_accuracy: 0.9814 - false_positives: 564.0000 - false_negatives: 567.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0510 - val_accuracy: 0.9815 - val_precision: 0.9814 - val_recall: 0.9815 - val_binary_accuracy: 0.9815 - val_false_positives: 121.0000 - val_false_negatives: 120.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 16/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0496 - accuracy: 0.9816 - precision: 0.9815 - recall: 0.9815 - binary_accuracy: 0.9815 - false_positives: 560.0000 - false_negatives: 560.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0590 - val_accuracy: 0.9795 - val_precision: 0.9795 - val_recall: 0.9792 - val_binary_accuracy: 0.9794 - val_false_positives: 133.0000 - val_false_negatives: 135.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 17/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0499 - accuracy: 0.9813 - precision: 0.9814 - recall: 0.9812 - binary_accuracy: 0.9813 - false_positives: 564.0000 - false_negatives: 571.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0618 - val_accuracy: 0.9818 - val_precision: 0.9817 - val_recall: 0.9817 - val_binary_accuracy: 0.9817 - val_false_positives: 119.0000 - val_false_negatives: 119.0000 - val_sensitivity_at_specificity: 0.9986\n",
            "Epoch 18/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0470 - accuracy: 0.9824 - precision: 0.9824 - recall: 0.9823 - binary_accuracy: 0.9823 - false_positives: 533.0000 - false_negatives: 538.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0540 - val_accuracy: 0.9817 - val_precision: 0.9818 - val_recall: 0.9818 - val_binary_accuracy: 0.9818 - val_false_positives: 118.0000 - val_false_negatives: 118.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 19/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0452 - accuracy: 0.9834 - precision: 0.9834 - recall: 0.9834 - binary_accuracy: 0.9834 - false_positives: 503.0000 - false_negatives: 503.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0489 - val_accuracy: 0.9835 - val_precision: 0.9835 - val_recall: 0.9837 - val_binary_accuracy: 0.9836 - val_false_positives: 107.0000 - val_false_negatives: 106.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 20/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0446 - accuracy: 0.9835 - precision: 0.9836 - recall: 0.9836 - binary_accuracy: 0.9836 - false_positives: 496.0000 - false_negatives: 498.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0509 - val_accuracy: 0.9831 - val_precision: 0.9831 - val_recall: 0.9831 - val_binary_accuracy: 0.9831 - val_false_positives: 110.0000 - val_false_negatives: 110.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 21/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0406 - accuracy: 0.9850 - precision: 0.9849 - recall: 0.9850 - binary_accuracy: 0.9849 - false_positives: 458.0000 - false_negatives: 456.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0473 - val_accuracy: 0.9843 - val_precision: 0.9840 - val_recall: 0.9845 - val_binary_accuracy: 0.9842 - val_false_positives: 104.0000 - val_false_negatives: 101.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 22/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0435 - accuracy: 0.9837 - precision: 0.9837 - recall: 0.9836 - binary_accuracy: 0.9837 - false_positives: 493.0000 - false_negatives: 496.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0478 - val_accuracy: 0.9842 - val_precision: 0.9840 - val_recall: 0.9843 - val_binary_accuracy: 0.9842 - val_false_positives: 104.0000 - val_false_negatives: 102.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 23/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0403 - accuracy: 0.9838 - precision: 0.9841 - recall: 0.9838 - binary_accuracy: 0.9839 - false_positives: 483.0000 - false_negatives: 492.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0482 - val_accuracy: 0.9838 - val_precision: 0.9838 - val_recall: 0.9842 - val_binary_accuracy: 0.9840 - val_false_positives: 105.0000 - val_false_negatives: 103.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 24/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0406 - accuracy: 0.9852 - precision: 0.9852 - recall: 0.9852 - binary_accuracy: 0.9852 - false_positives: 449.0000 - false_negatives: 449.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0459 - val_accuracy: 0.9852 - val_precision: 0.9852 - val_recall: 0.9852 - val_binary_accuracy: 0.9852 - val_false_positives: 96.0000 - val_false_negatives: 96.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 25/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0384 - accuracy: 0.9860 - precision: 0.9860 - recall: 0.9858 - binary_accuracy: 0.9859 - false_positives: 426.0000 - false_negatives: 430.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0437 - val_accuracy: 0.9849 - val_precision: 0.9849 - val_recall: 0.9851 - val_binary_accuracy: 0.9850 - val_false_positives: 98.0000 - val_false_negatives: 97.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Test loss: 0.04223007336258888\n",
            "Test accuracy: 0.9844615459442139\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 143, 2, 32)        608       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 71, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 54, 2, 64)         36928     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 27, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1728)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1728)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 3458      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 41314 (161.38 KB)\n",
            "Trainable params: 41314 (161.38 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "474/474 [==============================] - 6s 8ms/step - loss: 0.2530 - accuracy: 0.8866 - precision: 0.8849 - recall: 0.8852 - binary_accuracy: 0.8851 - false_positives: 3491.0000 - false_negatives: 3481.0000 - sensitivity_at_specificity: 0.9971 - val_loss: 0.1608 - val_accuracy: 0.9335 - val_precision: 0.9293 - val_recall: 0.9346 - val_binary_accuracy: 0.9318 - val_false_positives: 462.0000 - val_false_negatives: 425.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 2/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1439 - accuracy: 0.9427 - precision: 0.9421 - recall: 0.9418 - binary_accuracy: 0.9419 - false_positives: 1756.0000 - false_negatives: 1766.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.1221 - val_accuracy: 0.9545 - val_precision: 0.9550 - val_recall: 0.9534 - val_binary_accuracy: 0.9542 - val_false_positives: 292.0000 - val_false_negatives: 303.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 3/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1099 - accuracy: 0.9576 - precision: 0.9572 - recall: 0.9573 - binary_accuracy: 0.9572 - false_positives: 1299.0000 - false_negatives: 1295.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0869 - val_accuracy: 0.9685 - val_precision: 0.9680 - val_recall: 0.9688 - val_binary_accuracy: 0.9684 - val_false_positives: 208.0000 - val_false_negatives: 203.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 4/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0992 - accuracy: 0.9626 - precision: 0.9621 - recall: 0.9623 - binary_accuracy: 0.9622 - false_positives: 1149.0000 - false_negatives: 1143.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.0775 - val_accuracy: 0.9735 - val_precision: 0.9741 - val_recall: 0.9728 - val_binary_accuracy: 0.9735 - val_false_positives: 168.0000 - val_false_negatives: 177.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 5/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0890 - accuracy: 0.9670 - precision: 0.9669 - recall: 0.9667 - binary_accuracy: 0.9668 - false_positives: 1005.0000 - false_negatives: 1009.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0688 - val_accuracy: 0.9771 - val_precision: 0.9769 - val_recall: 0.9768 - val_binary_accuracy: 0.9768 - val_false_positives: 150.0000 - val_false_negatives: 151.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 6/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0810 - accuracy: 0.9699 - precision: 0.9701 - recall: 0.9700 - binary_accuracy: 0.9700 - false_positives: 907.0000 - false_negatives: 911.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0651 - val_accuracy: 0.9772 - val_precision: 0.9771 - val_recall: 0.9775 - val_binary_accuracy: 0.9773 - val_false_positives: 149.0000 - val_false_negatives: 146.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 7/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0754 - accuracy: 0.9725 - precision: 0.9723 - recall: 0.9721 - binary_accuracy: 0.9722 - false_positives: 840.0000 - false_negatives: 846.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0752 - val_accuracy: 0.9711 - val_precision: 0.9706 - val_recall: 0.9709 - val_binary_accuracy: 0.9708 - val_false_positives: 191.0000 - val_false_negatives: 189.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 8/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0712 - accuracy: 0.9740 - precision: 0.9739 - recall: 0.9738 - binary_accuracy: 0.9739 - false_positives: 790.0000 - false_negatives: 796.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0631 - val_accuracy: 0.9786 - val_precision: 0.9789 - val_recall: 0.9786 - val_binary_accuracy: 0.9788 - val_false_positives: 137.0000 - val_false_negatives: 139.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 9/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.0657 - accuracy: 0.9755 - precision: 0.9757 - recall: 0.9756 - binary_accuracy: 0.9756 - false_positives: 737.0000 - false_negatives: 741.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0668 - val_accuracy: 0.9757 - val_precision: 0.9757 - val_recall: 0.9757 - val_binary_accuracy: 0.9757 - val_false_positives: 158.0000 - val_false_negatives: 158.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 10/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.0658 - accuracy: 0.9746 - precision: 0.9745 - recall: 0.9746 - binary_accuracy: 0.9745 - false_positives: 775.0000 - false_negatives: 770.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0570 - val_accuracy: 0.9811 - val_precision: 0.9806 - val_recall: 0.9809 - val_binary_accuracy: 0.9808 - val_false_positives: 126.0000 - val_false_negatives: 124.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 11/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0637 - accuracy: 0.9773 - precision: 0.9771 - recall: 0.9773 - binary_accuracy: 0.9772 - false_positives: 695.0000 - false_negatives: 688.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.0623 - val_accuracy: 0.9783 - val_precision: 0.9782 - val_recall: 0.9788 - val_binary_accuracy: 0.9785 - val_false_positives: 142.0000 - val_false_negatives: 138.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 12/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0608 - accuracy: 0.9772 - precision: 0.9771 - recall: 0.9770 - binary_accuracy: 0.9770 - false_positives: 696.0000 - false_negatives: 697.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0689 - val_accuracy: 0.9735 - val_precision: 0.9735 - val_recall: 0.9735 - val_binary_accuracy: 0.9735 - val_false_positives: 172.0000 - val_false_negatives: 172.0000 - val_sensitivity_at_specificity: 0.9989\n",
            "Epoch 13/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0585 - accuracy: 0.9780 - precision: 0.9779 - recall: 0.9779 - binary_accuracy: 0.9779 - false_positives: 670.0000 - false_negatives: 669.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0559 - val_accuracy: 0.9786 - val_precision: 0.9786 - val_recall: 0.9783 - val_binary_accuracy: 0.9785 - val_false_positives: 139.0000 - val_false_negatives: 141.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 14/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0539 - accuracy: 0.9800 - precision: 0.9800 - recall: 0.9802 - binary_accuracy: 0.9801 - false_positives: 607.0000 - false_negatives: 601.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0650 - val_accuracy: 0.9751 - val_precision: 0.9751 - val_recall: 0.9757 - val_binary_accuracy: 0.9754 - val_false_positives: 162.0000 - val_false_negatives: 158.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 15/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0533 - accuracy: 0.9802 - precision: 0.9804 - recall: 0.9802 - binary_accuracy: 0.9803 - false_positives: 595.0000 - false_negatives: 599.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0617 - val_accuracy: 0.9760 - val_precision: 0.9761 - val_recall: 0.9758 - val_binary_accuracy: 0.9760 - val_false_positives: 155.0000 - val_false_negatives: 157.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 16/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0505 - accuracy: 0.9808 - precision: 0.9810 - recall: 0.9808 - binary_accuracy: 0.9809 - false_positives: 575.0000 - false_negatives: 582.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0566 - val_accuracy: 0.9788 - val_precision: 0.9789 - val_recall: 0.9786 - val_binary_accuracy: 0.9788 - val_false_positives: 137.0000 - val_false_negatives: 139.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 17/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0518 - accuracy: 0.9808 - precision: 0.9806 - recall: 0.9808 - binary_accuracy: 0.9807 - false_positives: 588.0000 - false_negatives: 581.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0524 - val_accuracy: 0.9815 - val_precision: 0.9818 - val_recall: 0.9812 - val_binary_accuracy: 0.9815 - val_false_positives: 118.0000 - val_false_negatives: 122.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 18/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0484 - accuracy: 0.9819 - precision: 0.9818 - recall: 0.9817 - binary_accuracy: 0.9817 - false_positives: 553.0000 - false_negatives: 556.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0567 - val_accuracy: 0.9814 - val_precision: 0.9815 - val_recall: 0.9812 - val_binary_accuracy: 0.9814 - val_false_positives: 120.0000 - val_false_negatives: 122.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 19/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0463 - accuracy: 0.9822 - precision: 0.9822 - recall: 0.9825 - binary_accuracy: 0.9824 - false_positives: 540.0000 - false_negatives: 530.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0601 - val_accuracy: 0.9798 - val_precision: 0.9798 - val_recall: 0.9800 - val_binary_accuracy: 0.9799 - val_false_positives: 131.0000 - val_false_negatives: 130.0000 - val_sensitivity_at_specificity: 0.9988\n",
            "Epoch 20/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0462 - accuracy: 0.9827 - precision: 0.9828 - recall: 0.9827 - binary_accuracy: 0.9828 - false_positives: 521.0000 - false_negatives: 524.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0468 - val_accuracy: 0.9838 - val_precision: 0.9838 - val_recall: 0.9838 - val_binary_accuracy: 0.9838 - val_false_positives: 105.0000 - val_false_negatives: 105.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 21/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0441 - accuracy: 0.9832 - precision: 0.9832 - recall: 0.9833 - binary_accuracy: 0.9832 - false_positives: 511.0000 - false_negatives: 507.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0585 - val_accuracy: 0.9811 - val_precision: 0.9812 - val_recall: 0.9811 - val_binary_accuracy: 0.9812 - val_false_positives: 122.0000 - val_false_negatives: 123.0000 - val_sensitivity_at_specificity: 0.9988\n",
            "Epoch 22/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0426 - accuracy: 0.9836 - precision: 0.9836 - recall: 0.9835 - binary_accuracy: 0.9836 - false_positives: 496.0000 - false_negatives: 500.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0515 - val_accuracy: 0.9814 - val_precision: 0.9814 - val_recall: 0.9814 - val_binary_accuracy: 0.9814 - val_false_positives: 121.0000 - val_false_negatives: 121.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 23/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0444 - accuracy: 0.9830 - precision: 0.9831 - recall: 0.9830 - binary_accuracy: 0.9830 - false_positives: 513.0000 - false_negatives: 517.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0622 - val_accuracy: 0.9802 - val_precision: 0.9803 - val_recall: 0.9802 - val_binary_accuracy: 0.9802 - val_false_positives: 128.0000 - val_false_negatives: 129.0000 - val_sensitivity_at_specificity: 0.9986\n",
            "Epoch 24/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0419 - accuracy: 0.9843 - precision: 0.9842 - recall: 0.9842 - binary_accuracy: 0.9842 - false_positives: 480.0000 - false_negatives: 478.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0434 - val_accuracy: 0.9849 - val_precision: 0.9851 - val_recall: 0.9849 - val_binary_accuracy: 0.9850 - val_false_positives: 97.0000 - val_false_negatives: 98.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 25/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0406 - accuracy: 0.9846 - precision: 0.9848 - recall: 0.9846 - binary_accuracy: 0.9847 - false_positives: 461.0000 - false_negatives: 467.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0479 - val_accuracy: 0.9822 - val_precision: 0.9822 - val_recall: 0.9822 - val_binary_accuracy: 0.9822 - val_false_positives: 116.0000 - val_false_negatives: 116.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Test loss: 0.0441850870847702\n",
            "Test accuracy: 0.9844615459442139\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 142, 2, 32)        640       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 71, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 53, 2, 64)         38976     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 26, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1664)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1664)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 3330      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 43266 (169.01 KB)\n",
            "Trainable params: 43266 (169.01 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "474/474 [==============================] - 6s 8ms/step - loss: 0.2492 - accuracy: 0.8891 - precision: 0.8868 - recall: 0.8885 - binary_accuracy: 0.8875 - false_positives: 3441.0000 - false_negatives: 3382.0000 - sensitivity_at_specificity: 0.9974 - val_loss: 0.1615 - val_accuracy: 0.9341 - val_precision: 0.9329 - val_recall: 0.9352 - val_binary_accuracy: 0.9340 - val_false_positives: 437.0000 - val_false_negatives: 421.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 2/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1437 - accuracy: 0.9434 - precision: 0.9426 - recall: 0.9430 - binary_accuracy: 0.9428 - false_positives: 1742.0000 - false_negatives: 1730.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.1160 - val_accuracy: 0.9521 - val_precision: 0.9526 - val_recall: 0.9521 - val_binary_accuracy: 0.9524 - val_false_positives: 308.0000 - val_false_negatives: 311.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 3/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1106 - accuracy: 0.9573 - precision: 0.9574 - recall: 0.9573 - binary_accuracy: 0.9573 - false_positives: 1293.0000 - false_negatives: 1295.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.0943 - val_accuracy: 0.9646 - val_precision: 0.9655 - val_recall: 0.9640 - val_binary_accuracy: 0.9648 - val_false_positives: 224.0000 - val_false_negatives: 234.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 4/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0964 - accuracy: 0.9640 - precision: 0.9640 - recall: 0.9631 - binary_accuracy: 0.9636 - false_positives: 1091.0000 - false_negatives: 1119.0000 - sensitivity_at_specificity: 0.9992 - val_loss: 0.0794 - val_accuracy: 0.9706 - val_precision: 0.9702 - val_recall: 0.9711 - val_binary_accuracy: 0.9706 - val_false_positives: 194.0000 - val_false_negatives: 188.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 5/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0827 - accuracy: 0.9687 - precision: 0.9687 - recall: 0.9683 - binary_accuracy: 0.9685 - false_positives: 950.0000 - false_negatives: 960.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0709 - val_accuracy: 0.9762 - val_precision: 0.9760 - val_recall: 0.9758 - val_binary_accuracy: 0.9759 - val_false_positives: 156.0000 - val_false_negatives: 157.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 6/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0793 - accuracy: 0.9702 - precision: 0.9699 - recall: 0.9700 - binary_accuracy: 0.9700 - false_positives: 912.0000 - false_negatives: 910.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0739 - val_accuracy: 0.9741 - val_precision: 0.9741 - val_recall: 0.9740 - val_binary_accuracy: 0.9741 - val_false_positives: 168.0000 - val_false_negatives: 169.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 7/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0729 - accuracy: 0.9722 - precision: 0.9725 - recall: 0.9721 - binary_accuracy: 0.9723 - false_positives: 835.0000 - false_negatives: 846.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0688 - val_accuracy: 0.9737 - val_precision: 0.9734 - val_recall: 0.9738 - val_binary_accuracy: 0.9736 - val_false_positives: 173.0000 - val_false_negatives: 170.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 8/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0688 - accuracy: 0.9750 - precision: 0.9748 - recall: 0.9748 - binary_accuracy: 0.9748 - false_positives: 765.0000 - false_negatives: 765.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0739 - val_accuracy: 0.9700 - val_precision: 0.9703 - val_recall: 0.9698 - val_binary_accuracy: 0.9701 - val_false_positives: 193.0000 - val_false_negatives: 196.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 9/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.0663 - accuracy: 0.9751 - precision: 0.9748 - recall: 0.9752 - binary_accuracy: 0.9750 - false_positives: 763.0000 - false_negatives: 753.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0566 - val_accuracy: 0.9806 - val_precision: 0.9806 - val_recall: 0.9805 - val_binary_accuracy: 0.9805 - val_false_positives: 126.0000 - val_false_negatives: 127.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 10/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.0630 - accuracy: 0.9758 - precision: 0.9758 - recall: 0.9758 - binary_accuracy: 0.9758 - false_positives: 734.0000 - false_negatives: 734.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0587 - val_accuracy: 0.9800 - val_precision: 0.9801 - val_recall: 0.9798 - val_binary_accuracy: 0.9800 - val_false_positives: 129.0000 - val_false_negatives: 131.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 11/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0600 - accuracy: 0.9783 - precision: 0.9785 - recall: 0.9780 - binary_accuracy: 0.9782 - false_positives: 653.0000 - false_negatives: 667.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0580 - val_accuracy: 0.9786 - val_precision: 0.9782 - val_recall: 0.9789 - val_binary_accuracy: 0.9785 - val_false_positives: 142.0000 - val_false_negatives: 137.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 12/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0583 - accuracy: 0.9778 - precision: 0.9778 - recall: 0.9774 - binary_accuracy: 0.9776 - false_positives: 673.0000 - false_negatives: 684.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0518 - val_accuracy: 0.9820 - val_precision: 0.9821 - val_recall: 0.9818 - val_binary_accuracy: 0.9820 - val_false_positives: 116.0000 - val_false_negatives: 118.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 13/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0520 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9809 - binary_accuracy: 0.9810 - false_positives: 575.0000 - false_negatives: 580.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0576 - val_accuracy: 0.9798 - val_precision: 0.9797 - val_recall: 0.9800 - val_binary_accuracy: 0.9798 - val_false_positives: 132.0000 - val_false_negatives: 130.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 14/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0518 - accuracy: 0.9808 - precision: 0.9808 - recall: 0.9809 - binary_accuracy: 0.9809 - false_positives: 582.0000 - false_negatives: 578.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0537 - val_accuracy: 0.9822 - val_precision: 0.9820 - val_recall: 0.9820 - val_binary_accuracy: 0.9820 - val_false_positives: 117.0000 - val_false_negatives: 117.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 15/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0508 - accuracy: 0.9811 - precision: 0.9808 - recall: 0.9812 - binary_accuracy: 0.9810 - false_positives: 581.0000 - false_negatives: 570.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0547 - val_accuracy: 0.9822 - val_precision: 0.9818 - val_recall: 0.9822 - val_binary_accuracy: 0.9820 - val_false_positives: 118.0000 - val_false_negatives: 116.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 16/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0502 - accuracy: 0.9810 - precision: 0.9811 - recall: 0.9810 - binary_accuracy: 0.9811 - false_positives: 572.0000 - false_negatives: 575.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0583 - val_accuracy: 0.9808 - val_precision: 0.9808 - val_recall: 0.9806 - val_binary_accuracy: 0.9807 - val_false_positives: 125.0000 - val_false_negatives: 126.0000 - val_sensitivity_at_specificity: 0.9989\n",
            "Epoch 17/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0474 - accuracy: 0.9826 - precision: 0.9825 - recall: 0.9827 - binary_accuracy: 0.9826 - false_positives: 532.0000 - false_negatives: 526.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0582 - val_accuracy: 0.9806 - val_precision: 0.9811 - val_recall: 0.9805 - val_binary_accuracy: 0.9808 - val_false_positives: 123.0000 - val_false_negatives: 127.0000 - val_sensitivity_at_specificity: 0.9988\n",
            "Epoch 18/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0463 - accuracy: 0.9832 - precision: 0.9831 - recall: 0.9830 - binary_accuracy: 0.9830 - false_positives: 513.0000 - false_negatives: 516.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0613 - val_accuracy: 0.9782 - val_precision: 0.9782 - val_recall: 0.9783 - val_binary_accuracy: 0.9782 - val_false_positives: 142.0000 - val_false_negatives: 141.0000 - val_sensitivity_at_specificity: 0.9988\n",
            "Epoch 19/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0442 - accuracy: 0.9838 - precision: 0.9838 - recall: 0.9837 - binary_accuracy: 0.9838 - false_positives: 491.0000 - false_negatives: 494.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0509 - val_accuracy: 0.9826 - val_precision: 0.9828 - val_recall: 0.9828 - val_binary_accuracy: 0.9828 - val_false_positives: 112.0000 - val_false_negatives: 112.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 20/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0448 - accuracy: 0.9834 - precision: 0.9833 - recall: 0.9833 - binary_accuracy: 0.9833 - false_positives: 505.0000 - false_negatives: 506.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0481 - val_accuracy: 0.9851 - val_precision: 0.9849 - val_recall: 0.9849 - val_binary_accuracy: 0.9849 - val_false_positives: 98.0000 - val_false_negatives: 98.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 21/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0411 - accuracy: 0.9849 - precision: 0.9850 - recall: 0.9849 - binary_accuracy: 0.9850 - false_positives: 454.0000 - false_negatives: 457.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0474 - val_accuracy: 0.9842 - val_precision: 0.9842 - val_recall: 0.9842 - val_binary_accuracy: 0.9842 - val_false_positives: 103.0000 - val_false_negatives: 103.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 22/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0399 - accuracy: 0.9849 - precision: 0.9850 - recall: 0.9850 - binary_accuracy: 0.9850 - false_positives: 456.0000 - false_negatives: 454.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0510 - val_accuracy: 0.9829 - val_precision: 0.9831 - val_recall: 0.9831 - val_binary_accuracy: 0.9831 - val_false_positives: 110.0000 - val_false_negatives: 110.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 23/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0390 - accuracy: 0.9855 - precision: 0.9854 - recall: 0.9854 - binary_accuracy: 0.9854 - false_positives: 443.0000 - false_negatives: 443.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0498 - val_accuracy: 0.9826 - val_precision: 0.9826 - val_recall: 0.9825 - val_binary_accuracy: 0.9825 - val_false_positives: 113.0000 - val_false_negatives: 114.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 24/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0389 - accuracy: 0.9860 - precision: 0.9861 - recall: 0.9860 - binary_accuracy: 0.9860 - false_positives: 423.0000 - false_negatives: 426.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0516 - val_accuracy: 0.9845 - val_precision: 0.9845 - val_recall: 0.9845 - val_binary_accuracy: 0.9845 - val_false_positives: 101.0000 - val_false_negatives: 101.0000 - val_sensitivity_at_specificity: 0.9986\n",
            "Epoch 25/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0385 - accuracy: 0.9848 - precision: 0.9849 - recall: 0.9848 - binary_accuracy: 0.9848 - false_positives: 458.0000 - false_negatives: 462.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0457 - val_accuracy: 0.9855 - val_precision: 0.9855 - val_recall: 0.9855 - val_binary_accuracy: 0.9855 - val_false_positives: 94.0000 - val_false_negatives: 94.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Test loss: 0.03705510497093201\n",
            "Test accuracy: 0.9872307777404785\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 141, 2, 32)        672       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 70, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 51, 2, 64)         41024     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 25, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1600)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1600)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 3202      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 45218 (176.63 KB)\n",
            "Trainable params: 45218 (176.63 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "474/474 [==============================] - 6s 8ms/step - loss: 0.2533 - accuracy: 0.8843 - precision: 0.8822 - recall: 0.8830 - binary_accuracy: 0.8826 - false_positives: 3576.0000 - false_negatives: 3547.0000 - sensitivity_at_specificity: 0.9977 - val_loss: 0.1567 - val_accuracy: 0.9408 - val_precision: 0.9421 - val_recall: 0.9397 - val_binary_accuracy: 0.9410 - val_false_positives: 375.0000 - val_false_negatives: 392.0000 - val_sensitivity_at_specificity: 1.0000\n",
            "Epoch 2/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1490 - accuracy: 0.9400 - precision: 0.9394 - recall: 0.9384 - binary_accuracy: 0.9390 - false_positives: 1835.0000 - false_negatives: 1867.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.1215 - val_accuracy: 0.9511 - val_precision: 0.9500 - val_recall: 0.9511 - val_binary_accuracy: 0.9505 - val_false_positives: 325.0000 - val_false_negatives: 318.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 3/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1149 - accuracy: 0.9561 - precision: 0.9559 - recall: 0.9560 - binary_accuracy: 0.9559 - false_positives: 1339.0000 - false_negatives: 1334.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.0929 - val_accuracy: 0.9652 - val_precision: 0.9652 - val_recall: 0.9654 - val_binary_accuracy: 0.9653 - val_false_positives: 226.0000 - val_false_negatives: 225.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 4/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0964 - accuracy: 0.9634 - precision: 0.9630 - recall: 0.9630 - binary_accuracy: 0.9630 - false_positives: 1121.0000 - false_negatives: 1121.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0786 - val_accuracy: 0.9723 - val_precision: 0.9729 - val_recall: 0.9723 - val_binary_accuracy: 0.9726 - val_false_positives: 176.0000 - val_false_negatives: 180.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 5/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0907 - accuracy: 0.9658 - precision: 0.9658 - recall: 0.9652 - binary_accuracy: 0.9655 - false_positives: 1037.0000 - false_negatives: 1056.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.0753 - val_accuracy: 0.9743 - val_precision: 0.9734 - val_recall: 0.9743 - val_binary_accuracy: 0.9738 - val_false_positives: 173.0000 - val_false_negatives: 167.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 6/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0768 - accuracy: 0.9714 - precision: 0.9713 - recall: 0.9711 - binary_accuracy: 0.9712 - false_positives: 869.0000 - false_negatives: 877.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0672 - val_accuracy: 0.9766 - val_precision: 0.9769 - val_recall: 0.9765 - val_binary_accuracy: 0.9767 - val_false_positives: 150.0000 - val_false_negatives: 153.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 7/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0711 - accuracy: 0.9722 - precision: 0.9721 - recall: 0.9723 - binary_accuracy: 0.9722 - false_positives: 845.0000 - false_negatives: 841.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0706 - val_accuracy: 0.9751 - val_precision: 0.9752 - val_recall: 0.9751 - val_binary_accuracy: 0.9752 - val_false_positives: 161.0000 - val_false_negatives: 162.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 8/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0696 - accuracy: 0.9741 - precision: 0.9741 - recall: 0.9742 - binary_accuracy: 0.9741 - false_positives: 787.0000 - false_negatives: 781.0000 - sensitivity_at_specificity: 0.9993 - val_loss: 0.0619 - val_accuracy: 0.9782 - val_precision: 0.9782 - val_recall: 0.9785 - val_binary_accuracy: 0.9783 - val_false_positives: 142.0000 - val_false_negatives: 140.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 9/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0657 - accuracy: 0.9753 - precision: 0.9754 - recall: 0.9753 - binary_accuracy: 0.9754 - false_positives: 747.0000 - false_negatives: 748.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0682 - val_accuracy: 0.9752 - val_precision: 0.9751 - val_recall: 0.9751 - val_binary_accuracy: 0.9751 - val_false_positives: 162.0000 - val_false_negatives: 162.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 10/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0603 - accuracy: 0.9778 - precision: 0.9776 - recall: 0.9777 - binary_accuracy: 0.9777 - false_positives: 678.0000 - false_negatives: 676.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0519 - val_accuracy: 0.9809 - val_precision: 0.9811 - val_recall: 0.9806 - val_binary_accuracy: 0.9808 - val_false_positives: 123.0000 - val_false_negatives: 126.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 11/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0570 - accuracy: 0.9788 - precision: 0.9787 - recall: 0.9790 - binary_accuracy: 0.9788 - false_positives: 647.0000 - false_negatives: 638.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0525 - val_accuracy: 0.9805 - val_precision: 0.9808 - val_recall: 0.9808 - val_binary_accuracy: 0.9808 - val_false_positives: 125.0000 - val_false_negatives: 125.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 12/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0538 - accuracy: 0.9793 - precision: 0.9794 - recall: 0.9794 - binary_accuracy: 0.9794 - false_positives: 625.0000 - false_negatives: 625.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0542 - val_accuracy: 0.9809 - val_precision: 0.9811 - val_recall: 0.9809 - val_binary_accuracy: 0.9810 - val_false_positives: 123.0000 - val_false_negatives: 124.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 13/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0548 - accuracy: 0.9791 - precision: 0.9791 - recall: 0.9793 - binary_accuracy: 0.9792 - false_positives: 635.0000 - false_negatives: 628.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0503 - val_accuracy: 0.9837 - val_precision: 0.9840 - val_recall: 0.9838 - val_binary_accuracy: 0.9839 - val_false_positives: 104.0000 - val_false_negatives: 105.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 14/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0525 - accuracy: 0.9804 - precision: 0.9804 - recall: 0.9804 - binary_accuracy: 0.9804 - false_positives: 595.0000 - false_negatives: 595.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0539 - val_accuracy: 0.9832 - val_precision: 0.9831 - val_recall: 0.9829 - val_binary_accuracy: 0.9830 - val_false_positives: 110.0000 - val_false_negatives: 111.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 15/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0506 - accuracy: 0.9808 - precision: 0.9808 - recall: 0.9809 - binary_accuracy: 0.9808 - false_positives: 583.0000 - false_negatives: 580.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0467 - val_accuracy: 0.9835 - val_precision: 0.9835 - val_recall: 0.9835 - val_binary_accuracy: 0.9835 - val_false_positives: 107.0000 - val_false_negatives: 107.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 16/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0505 - accuracy: 0.9815 - precision: 0.9815 - recall: 0.9814 - binary_accuracy: 0.9814 - false_positives: 562.0000 - false_negatives: 564.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0499 - val_accuracy: 0.9842 - val_precision: 0.9841 - val_recall: 0.9838 - val_binary_accuracy: 0.9840 - val_false_positives: 103.0000 - val_false_negatives: 105.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 17/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0460 - accuracy: 0.9827 - precision: 0.9828 - recall: 0.9828 - binary_accuracy: 0.9828 - false_positives: 522.0000 - false_negatives: 523.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0503 - val_accuracy: 0.9823 - val_precision: 0.9823 - val_recall: 0.9823 - val_binary_accuracy: 0.9823 - val_false_positives: 115.0000 - val_false_negatives: 115.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 18/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0440 - accuracy: 0.9834 - precision: 0.9832 - recall: 0.9834 - binary_accuracy: 0.9833 - false_positives: 509.0000 - false_negatives: 503.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0493 - val_accuracy: 0.9818 - val_precision: 0.9820 - val_recall: 0.9820 - val_binary_accuracy: 0.9820 - val_false_positives: 117.0000 - val_false_negatives: 117.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 19/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0452 - accuracy: 0.9832 - precision: 0.9830 - recall: 0.9832 - binary_accuracy: 0.9831 - false_positives: 516.0000 - false_negatives: 509.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0524 - val_accuracy: 0.9812 - val_precision: 0.9815 - val_recall: 0.9812 - val_binary_accuracy: 0.9814 - val_false_positives: 120.0000 - val_false_negatives: 122.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 20/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0419 - accuracy: 0.9839 - precision: 0.9838 - recall: 0.9839 - binary_accuracy: 0.9839 - false_positives: 490.0000 - false_negatives: 489.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0470 - val_accuracy: 0.9843 - val_precision: 0.9843 - val_recall: 0.9843 - val_binary_accuracy: 0.9843 - val_false_positives: 102.0000 - val_false_negatives: 102.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 21/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0391 - accuracy: 0.9851 - precision: 0.9852 - recall: 0.9851 - binary_accuracy: 0.9851 - false_positives: 449.0000 - false_negatives: 453.0000 - sensitivity_at_specificity: 0.9999 - val_loss: 0.0489 - val_accuracy: 0.9838 - val_precision: 0.9837 - val_recall: 0.9838 - val_binary_accuracy: 0.9838 - val_false_positives: 106.0000 - val_false_negatives: 105.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 22/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0381 - accuracy: 0.9860 - precision: 0.9860 - recall: 0.9860 - binary_accuracy: 0.9860 - false_positives: 426.0000 - false_negatives: 425.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0457 - val_accuracy: 0.9855 - val_precision: 0.9857 - val_recall: 0.9855 - val_binary_accuracy: 0.9856 - val_false_positives: 93.0000 - val_false_negatives: 94.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 23/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0376 - accuracy: 0.9862 - precision: 0.9862 - recall: 0.9861 - binary_accuracy: 0.9861 - false_positives: 419.0000 - false_negatives: 422.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0422 - val_accuracy: 0.9857 - val_precision: 0.9855 - val_recall: 0.9851 - val_binary_accuracy: 0.9853 - val_false_positives: 94.0000 - val_false_negatives: 97.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 24/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0384 - accuracy: 0.9854 - precision: 0.9854 - recall: 0.9855 - binary_accuracy: 0.9855 - false_positives: 442.0000 - false_negatives: 439.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0413 - val_accuracy: 0.9865 - val_precision: 0.9865 - val_recall: 0.9863 - val_binary_accuracy: 0.9864 - val_false_positives: 88.0000 - val_false_negatives: 89.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 25/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0367 - accuracy: 0.9856 - precision: 0.9857 - recall: 0.9856 - binary_accuracy: 0.9856 - false_positives: 435.0000 - false_negatives: 436.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0428 - val_accuracy: 0.9868 - val_precision: 0.9868 - val_recall: 0.9866 - val_binary_accuracy: 0.9867 - val_false_positives: 86.0000 - val_false_negatives: 87.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Test loss: 0.039379555732011795\n",
            "Test accuracy: 0.9846153855323792\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 140, 2, 32)        704       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 70, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 50, 2, 64)         43072     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 25, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1600)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1600)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 3202      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 47298 (184.76 KB)\n",
            "Trainable params: 47298 (184.76 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "474/474 [==============================] - 6s 8ms/step - loss: 0.2452 - accuracy: 0.8915 - precision: 0.8892 - recall: 0.8890 - binary_accuracy: 0.8891 - false_positives: 3358.0000 - false_negatives: 3366.0000 - sensitivity_at_specificity: 0.9979 - val_loss: 0.1511 - val_accuracy: 0.9409 - val_precision: 0.9371 - val_recall: 0.9448 - val_binary_accuracy: 0.9407 - val_false_positives: 412.0000 - val_false_negatives: 359.0000 - val_sensitivity_at_specificity: 1.0000\n",
            "Epoch 2/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1481 - accuracy: 0.9411 - precision: 0.9399 - recall: 0.9410 - binary_accuracy: 0.9404 - false_positives: 1826.0000 - false_negatives: 1790.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.1133 - val_accuracy: 0.9541 - val_precision: 0.9550 - val_recall: 0.9541 - val_binary_accuracy: 0.9546 - val_false_positives: 292.0000 - val_false_negatives: 298.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 3/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1140 - accuracy: 0.9565 - precision: 0.9571 - recall: 0.9563 - binary_accuracy: 0.9567 - false_positives: 1301.0000 - false_negatives: 1326.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0981 - val_accuracy: 0.9611 - val_precision: 0.9614 - val_recall: 0.9620 - val_binary_accuracy: 0.9617 - val_false_positives: 251.0000 - val_false_negatives: 247.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 4/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0953 - accuracy: 0.9640 - precision: 0.9636 - recall: 0.9638 - binary_accuracy: 0.9637 - false_positives: 1103.0000 - false_negatives: 1098.0000 - sensitivity_at_specificity: 0.9993 - val_loss: 0.1070 - val_accuracy: 0.9537 - val_precision: 0.9541 - val_recall: 0.9534 - val_binary_accuracy: 0.9538 - val_false_positives: 298.0000 - val_false_negatives: 303.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 5/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0862 - accuracy: 0.9679 - precision: 0.9679 - recall: 0.9678 - binary_accuracy: 0.9679 - false_positives: 972.0000 - false_negatives: 978.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0876 - val_accuracy: 0.9675 - val_precision: 0.9678 - val_recall: 0.9680 - val_binary_accuracy: 0.9679 - val_false_positives: 209.0000 - val_false_negatives: 208.0000 - val_sensitivity_at_specificity: 0.9989\n",
            "Epoch 6/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0783 - accuracy: 0.9706 - precision: 0.9705 - recall: 0.9703 - binary_accuracy: 0.9704 - false_positives: 893.0000 - false_negatives: 902.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0723 - val_accuracy: 0.9752 - val_precision: 0.9752 - val_recall: 0.9748 - val_binary_accuracy: 0.9750 - val_false_positives: 161.0000 - val_false_negatives: 164.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 7/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0712 - accuracy: 0.9736 - precision: 0.9734 - recall: 0.9734 - binary_accuracy: 0.9734 - false_positives: 806.0000 - false_negatives: 807.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0769 - val_accuracy: 0.9731 - val_precision: 0.9728 - val_recall: 0.9728 - val_binary_accuracy: 0.9728 - val_false_positives: 177.0000 - val_false_negatives: 177.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 8/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0676 - accuracy: 0.9747 - precision: 0.9744 - recall: 0.9746 - binary_accuracy: 0.9745 - false_positives: 775.0000 - false_negatives: 771.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0651 - val_accuracy: 0.9772 - val_precision: 0.9772 - val_recall: 0.9775 - val_binary_accuracy: 0.9774 - val_false_positives: 148.0000 - val_false_negatives: 146.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 9/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0651 - accuracy: 0.9766 - precision: 0.9764 - recall: 0.9768 - binary_accuracy: 0.9766 - false_positives: 716.0000 - false_negatives: 705.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0590 - val_accuracy: 0.9797 - val_precision: 0.9795 - val_recall: 0.9797 - val_binary_accuracy: 0.9796 - val_false_positives: 133.0000 - val_false_negatives: 132.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 10/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0630 - accuracy: 0.9765 - precision: 0.9765 - recall: 0.9768 - binary_accuracy: 0.9767 - false_positives: 713.0000 - false_negatives: 703.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0589 - val_accuracy: 0.9802 - val_precision: 0.9800 - val_recall: 0.9806 - val_binary_accuracy: 0.9803 - val_false_positives: 130.0000 - val_false_negatives: 126.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 11/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0594 - accuracy: 0.9784 - precision: 0.9786 - recall: 0.9781 - binary_accuracy: 0.9784 - false_positives: 649.0000 - false_negatives: 663.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.0518 - val_accuracy: 0.9815 - val_precision: 0.9815 - val_recall: 0.9818 - val_binary_accuracy: 0.9817 - val_false_positives: 120.0000 - val_false_negatives: 118.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 12/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0583 - accuracy: 0.9783 - precision: 0.9781 - recall: 0.9785 - binary_accuracy: 0.9783 - false_positives: 664.0000 - false_negatives: 652.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0562 - val_accuracy: 0.9795 - val_precision: 0.9797 - val_recall: 0.9797 - val_binary_accuracy: 0.9797 - val_false_positives: 132.0000 - val_false_negatives: 132.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 13/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0547 - accuracy: 0.9806 - precision: 0.9806 - recall: 0.9807 - binary_accuracy: 0.9807 - false_positives: 588.0000 - false_negatives: 584.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0563 - val_accuracy: 0.9806 - val_precision: 0.9808 - val_recall: 0.9806 - val_binary_accuracy: 0.9807 - val_false_positives: 125.0000 - val_false_negatives: 126.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 14/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0514 - accuracy: 0.9806 - precision: 0.9806 - recall: 0.9804 - binary_accuracy: 0.9805 - false_positives: 588.0000 - false_negatives: 594.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0562 - val_accuracy: 0.9805 - val_precision: 0.9803 - val_recall: 0.9803 - val_binary_accuracy: 0.9803 - val_false_positives: 128.0000 - val_false_negatives: 128.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 15/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0495 - accuracy: 0.9808 - precision: 0.9809 - recall: 0.9808 - binary_accuracy: 0.9808 - false_positives: 580.0000 - false_negatives: 582.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0528 - val_accuracy: 0.9837 - val_precision: 0.9837 - val_recall: 0.9837 - val_binary_accuracy: 0.9837 - val_false_positives: 106.0000 - val_false_negatives: 106.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 16/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0491 - accuracy: 0.9813 - precision: 0.9813 - recall: 0.9811 - binary_accuracy: 0.9812 - false_positives: 566.0000 - false_negatives: 572.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0572 - val_accuracy: 0.9808 - val_precision: 0.9808 - val_recall: 0.9808 - val_binary_accuracy: 0.9808 - val_false_positives: 125.0000 - val_false_negatives: 125.0000 - val_sensitivity_at_specificity: 0.9986\n",
            "Epoch 17/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0478 - accuracy: 0.9820 - precision: 0.9818 - recall: 0.9818 - binary_accuracy: 0.9818 - false_positives: 551.0000 - false_negatives: 553.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0576 - val_accuracy: 0.9792 - val_precision: 0.9795 - val_recall: 0.9794 - val_binary_accuracy: 0.9795 - val_false_positives: 133.0000 - val_false_negatives: 134.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 18/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0465 - accuracy: 0.9831 - precision: 0.9830 - recall: 0.9830 - binary_accuracy: 0.9830 - false_positives: 515.0000 - false_negatives: 515.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0479 - val_accuracy: 0.9842 - val_precision: 0.9842 - val_recall: 0.9842 - val_binary_accuracy: 0.9842 - val_false_positives: 103.0000 - val_false_negatives: 103.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 19/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0465 - accuracy: 0.9830 - precision: 0.9829 - recall: 0.9830 - binary_accuracy: 0.9830 - false_positives: 518.0000 - false_negatives: 515.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0517 - val_accuracy: 0.9823 - val_precision: 0.9822 - val_recall: 0.9823 - val_binary_accuracy: 0.9822 - val_false_positives: 116.0000 - val_false_negatives: 115.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 20/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0426 - accuracy: 0.9838 - precision: 0.9837 - recall: 0.9839 - binary_accuracy: 0.9838 - false_positives: 494.0000 - false_negatives: 489.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0566 - val_accuracy: 0.9815 - val_precision: 0.9815 - val_recall: 0.9814 - val_binary_accuracy: 0.9815 - val_false_positives: 120.0000 - val_false_negatives: 121.0000 - val_sensitivity_at_specificity: 0.9985\n",
            "Epoch 21/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0429 - accuracy: 0.9841 - precision: 0.9841 - recall: 0.9841 - binary_accuracy: 0.9841 - false_positives: 482.0000 - false_negatives: 481.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0522 - val_accuracy: 0.9823 - val_precision: 0.9823 - val_recall: 0.9823 - val_binary_accuracy: 0.9823 - val_false_positives: 115.0000 - val_false_negatives: 115.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 22/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0394 - accuracy: 0.9853 - precision: 0.9852 - recall: 0.9852 - binary_accuracy: 0.9852 - false_positives: 448.0000 - false_negatives: 448.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0522 - val_accuracy: 0.9826 - val_precision: 0.9828 - val_recall: 0.9826 - val_binary_accuracy: 0.9827 - val_false_positives: 112.0000 - val_false_negatives: 113.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 23/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0398 - accuracy: 0.9845 - precision: 0.9846 - recall: 0.9847 - binary_accuracy: 0.9846 - false_positives: 467.0000 - false_negatives: 465.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0456 - val_accuracy: 0.9857 - val_precision: 0.9855 - val_recall: 0.9855 - val_binary_accuracy: 0.9855 - val_false_positives: 94.0000 - val_false_negatives: 94.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 24/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0391 - accuracy: 0.9858 - precision: 0.9858 - recall: 0.9857 - binary_accuracy: 0.9858 - false_positives: 431.0000 - false_negatives: 433.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0595 - val_accuracy: 0.9798 - val_precision: 0.9800 - val_recall: 0.9798 - val_binary_accuracy: 0.9799 - val_false_positives: 130.0000 - val_false_negatives: 131.0000 - val_sensitivity_at_specificity: 0.9988\n",
            "Epoch 25/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0391 - accuracy: 0.9849 - precision: 0.9850 - recall: 0.9849 - binary_accuracy: 0.9849 - false_positives: 456.0000 - false_negatives: 458.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0509 - val_accuracy: 0.9842 - val_precision: 0.9840 - val_recall: 0.9842 - val_binary_accuracy: 0.9841 - val_false_positives: 104.0000 - val_false_negatives: 103.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Test loss: 0.05043596774339676\n",
            "Test accuracy: 0.9835384488105774\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 139, 2, 32)        736       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 69, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 48, 2, 64)         45120     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 24, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1536)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1536)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 3074      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 49250 (192.38 KB)\n",
            "Trainable params: 49250 (192.38 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "474/474 [==============================] - 6s 9ms/step - loss: 0.2495 - accuracy: 0.8880 - precision: 0.8868 - recall: 0.8855 - binary_accuracy: 0.8862 - false_positives: 3427.0000 - false_negatives: 3473.0000 - sensitivity_at_specificity: 0.9969 - val_loss: 0.1513 - val_accuracy: 0.9409 - val_precision: 0.9413 - val_recall: 0.9394 - val_binary_accuracy: 0.9404 - val_false_positives: 381.0000 - val_false_negatives: 394.0000 - val_sensitivity_at_specificity: 1.0000\n",
            "Epoch 2/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1383 - accuracy: 0.9455 - precision: 0.9457 - recall: 0.9451 - binary_accuracy: 0.9454 - false_positives: 1645.0000 - false_negatives: 1664.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.1026 - val_accuracy: 0.9621 - val_precision: 0.9617 - val_recall: 0.9623 - val_binary_accuracy: 0.9620 - val_false_positives: 249.0000 - val_false_negatives: 245.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 3/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1090 - accuracy: 0.9582 - precision: 0.9588 - recall: 0.9581 - binary_accuracy: 0.9584 - false_positives: 1250.0000 - false_negatives: 1272.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.1031 - val_accuracy: 0.9592 - val_precision: 0.9598 - val_recall: 0.9589 - val_binary_accuracy: 0.9594 - val_false_positives: 261.0000 - val_false_negatives: 267.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 4/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0921 - accuracy: 0.9655 - precision: 0.9650 - recall: 0.9650 - binary_accuracy: 0.9650 - false_positives: 1062.0000 - false_negatives: 1062.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0758 - val_accuracy: 0.9720 - val_precision: 0.9721 - val_recall: 0.9721 - val_binary_accuracy: 0.9721 - val_false_positives: 181.0000 - val_false_negatives: 181.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 5/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0853 - accuracy: 0.9677 - precision: 0.9676 - recall: 0.9677 - binary_accuracy: 0.9676 - false_positives: 984.0000 - false_negatives: 980.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0637 - val_accuracy: 0.9785 - val_precision: 0.9785 - val_recall: 0.9783 - val_binary_accuracy: 0.9784 - val_false_positives: 140.0000 - val_false_negatives: 141.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 6/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0770 - accuracy: 0.9709 - precision: 0.9704 - recall: 0.9708 - binary_accuracy: 0.9706 - false_positives: 898.0000 - false_negatives: 885.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0708 - val_accuracy: 0.9758 - val_precision: 0.9752 - val_recall: 0.9757 - val_binary_accuracy: 0.9755 - val_false_positives: 161.0000 - val_false_negatives: 158.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 7/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0699 - accuracy: 0.9732 - precision: 0.9733 - recall: 0.9732 - binary_accuracy: 0.9732 - false_positives: 811.0000 - false_negatives: 813.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0639 - val_accuracy: 0.9768 - val_precision: 0.9765 - val_recall: 0.9765 - val_binary_accuracy: 0.9765 - val_false_positives: 153.0000 - val_false_negatives: 153.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 8/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0663 - accuracy: 0.9751 - precision: 0.9752 - recall: 0.9747 - binary_accuracy: 0.9750 - false_positives: 753.0000 - false_negatives: 766.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0536 - val_accuracy: 0.9823 - val_precision: 0.9825 - val_recall: 0.9826 - val_binary_accuracy: 0.9825 - val_false_positives: 114.0000 - val_false_negatives: 113.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 9/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0636 - accuracy: 0.9751 - precision: 0.9754 - recall: 0.9749 - binary_accuracy: 0.9752 - false_positives: 746.0000 - false_negatives: 761.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0566 - val_accuracy: 0.9809 - val_precision: 0.9809 - val_recall: 0.9809 - val_binary_accuracy: 0.9809 - val_false_positives: 124.0000 - val_false_negatives: 124.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 10/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0601 - accuracy: 0.9779 - precision: 0.9779 - recall: 0.9781 - binary_accuracy: 0.9780 - false_positives: 671.0000 - false_negatives: 665.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0534 - val_accuracy: 0.9814 - val_precision: 0.9818 - val_recall: 0.9811 - val_binary_accuracy: 0.9815 - val_false_positives: 118.0000 - val_false_negatives: 123.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 11/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0576 - accuracy: 0.9790 - precision: 0.9788 - recall: 0.9789 - binary_accuracy: 0.9788 - false_positives: 643.0000 - false_negatives: 640.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0491 - val_accuracy: 0.9838 - val_precision: 0.9835 - val_recall: 0.9840 - val_binary_accuracy: 0.9838 - val_false_positives: 107.0000 - val_false_negatives: 104.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 12/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0561 - accuracy: 0.9789 - precision: 0.9786 - recall: 0.9791 - binary_accuracy: 0.9788 - false_positives: 649.0000 - false_negatives: 635.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0679 - val_accuracy: 0.9741 - val_precision: 0.9741 - val_recall: 0.9741 - val_binary_accuracy: 0.9741 - val_false_positives: 168.0000 - val_false_negatives: 168.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 13/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0542 - accuracy: 0.9800 - precision: 0.9799 - recall: 0.9802 - binary_accuracy: 0.9801 - false_positives: 611.0000 - false_negatives: 599.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0527 - val_accuracy: 0.9820 - val_precision: 0.9820 - val_recall: 0.9823 - val_binary_accuracy: 0.9822 - val_false_positives: 117.0000 - val_false_negatives: 115.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 14/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0521 - accuracy: 0.9800 - precision: 0.9801 - recall: 0.9800 - binary_accuracy: 0.9800 - false_positives: 604.0000 - false_negatives: 607.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0476 - val_accuracy: 0.9852 - val_precision: 0.9852 - val_recall: 0.9854 - val_binary_accuracy: 0.9853 - val_false_positives: 96.0000 - val_false_negatives: 95.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 15/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0468 - accuracy: 0.9828 - precision: 0.9829 - recall: 0.9828 - binary_accuracy: 0.9828 - false_positives: 518.0000 - false_negatives: 523.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0442 - val_accuracy: 0.9874 - val_precision: 0.9874 - val_recall: 0.9875 - val_binary_accuracy: 0.9875 - val_false_positives: 82.0000 - val_false_negatives: 81.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 16/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0481 - accuracy: 0.9822 - precision: 0.9821 - recall: 0.9822 - binary_accuracy: 0.9821 - false_positives: 544.0000 - false_negatives: 540.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0466 - val_accuracy: 0.9840 - val_precision: 0.9838 - val_recall: 0.9842 - val_binary_accuracy: 0.9840 - val_false_positives: 105.0000 - val_false_negatives: 103.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 17/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0456 - accuracy: 0.9827 - precision: 0.9827 - recall: 0.9828 - binary_accuracy: 0.9828 - false_positives: 525.0000 - false_negatives: 521.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0477 - val_accuracy: 0.9838 - val_precision: 0.9840 - val_recall: 0.9838 - val_binary_accuracy: 0.9839 - val_false_positives: 104.0000 - val_false_negatives: 105.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 18/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0447 - accuracy: 0.9834 - precision: 0.9834 - recall: 0.9835 - binary_accuracy: 0.9835 - false_positives: 503.0000 - false_negatives: 499.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0434 - val_accuracy: 0.9880 - val_precision: 0.9880 - val_recall: 0.9877 - val_binary_accuracy: 0.9878 - val_false_positives: 78.0000 - val_false_negatives: 80.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 19/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0418 - accuracy: 0.9839 - precision: 0.9838 - recall: 0.9839 - binary_accuracy: 0.9839 - false_positives: 490.0000 - false_negatives: 487.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0444 - val_accuracy: 0.9862 - val_precision: 0.9863 - val_recall: 0.9863 - val_binary_accuracy: 0.9863 - val_false_positives: 89.0000 - val_false_negatives: 89.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 20/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0425 - accuracy: 0.9840 - precision: 0.9839 - recall: 0.9839 - binary_accuracy: 0.9839 - false_positives: 487.0000 - false_negatives: 489.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0536 - val_accuracy: 0.9811 - val_precision: 0.9814 - val_recall: 0.9811 - val_binary_accuracy: 0.9812 - val_false_positives: 121.0000 - val_false_negatives: 123.0000 - val_sensitivity_at_specificity: 0.9989\n",
            "Epoch 21/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0390 - accuracy: 0.9853 - precision: 0.9852 - recall: 0.9854 - binary_accuracy: 0.9853 - false_positives: 449.0000 - false_negatives: 444.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0505 - val_accuracy: 0.9834 - val_precision: 0.9832 - val_recall: 0.9835 - val_binary_accuracy: 0.9834 - val_false_positives: 109.0000 - val_false_negatives: 107.0000 - val_sensitivity_at_specificity: 0.9988\n",
            "Epoch 22/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0398 - accuracy: 0.9849 - precision: 0.9849 - recall: 0.9849 - binary_accuracy: 0.9849 - false_positives: 457.0000 - false_negatives: 457.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0506 - val_accuracy: 0.9848 - val_precision: 0.9848 - val_recall: 0.9848 - val_binary_accuracy: 0.9848 - val_false_positives: 99.0000 - val_false_negatives: 99.0000 - val_sensitivity_at_specificity: 0.9989\n",
            "Epoch 23/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0383 - accuracy: 0.9858 - precision: 0.9858 - recall: 0.9859 - binary_accuracy: 0.9858 - false_positives: 430.0000 - false_negatives: 429.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0481 - val_accuracy: 0.9858 - val_precision: 0.9858 - val_recall: 0.9858 - val_binary_accuracy: 0.9858 - val_false_positives: 92.0000 - val_false_negatives: 92.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 24/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0381 - accuracy: 0.9861 - precision: 0.9861 - recall: 0.9861 - binary_accuracy: 0.9861 - false_positives: 423.0000 - false_negatives: 423.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0473 - val_accuracy: 0.9855 - val_precision: 0.9855 - val_recall: 0.9855 - val_binary_accuracy: 0.9855 - val_false_positives: 94.0000 - val_false_negatives: 94.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 25/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0350 - accuracy: 0.9866 - precision: 0.9866 - recall: 0.9866 - binary_accuracy: 0.9866 - false_positives: 407.0000 - false_negatives: 406.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0541 - val_accuracy: 0.9823 - val_precision: 0.9823 - val_recall: 0.9825 - val_binary_accuracy: 0.9824 - val_false_positives: 115.0000 - val_false_negatives: 114.0000 - val_sensitivity_at_specificity: 0.9988\n",
            "Test loss: 0.05230444297194481\n",
            "Test accuracy: 0.9832307696342468\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 138, 2, 32)        768       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 69, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 47, 2, 64)         47168     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 23, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1472)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1472)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 2946      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51202 (200.01 KB)\n",
            "Trainable params: 51202 (200.01 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "474/474 [==============================] - 6s 9ms/step - loss: 0.2408 - accuracy: 0.8936 - precision: 0.8926 - recall: 0.8918 - binary_accuracy: 0.8922 - false_positives: 3255.0000 - false_negatives: 3282.0000 - sensitivity_at_specificity: 0.9977 - val_loss: 0.1422 - val_accuracy: 0.9471 - val_precision: 0.9468 - val_recall: 0.9469 - val_binary_accuracy: 0.9468 - val_false_positives: 346.0000 - val_false_negatives: 345.0000 - val_sensitivity_at_specificity: 1.0000\n",
            "Epoch 2/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1322 - accuracy: 0.9472 - precision: 0.9475 - recall: 0.9472 - binary_accuracy: 0.9474 - false_positives: 1591.0000 - false_negatives: 1600.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0994 - val_accuracy: 0.9621 - val_precision: 0.9618 - val_recall: 0.9612 - val_binary_accuracy: 0.9615 - val_false_positives: 248.0000 - val_false_negatives: 252.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 3/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1033 - accuracy: 0.9595 - precision: 0.9587 - recall: 0.9589 - binary_accuracy: 0.9588 - false_positives: 1253.0000 - false_negatives: 1245.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0752 - val_accuracy: 0.9746 - val_precision: 0.9740 - val_recall: 0.9755 - val_binary_accuracy: 0.9748 - val_false_positives: 169.0000 - val_false_negatives: 159.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 4/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0862 - accuracy: 0.9684 - precision: 0.9683 - recall: 0.9682 - binary_accuracy: 0.9683 - false_positives: 960.0000 - false_negatives: 965.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0655 - val_accuracy: 0.9768 - val_precision: 0.9771 - val_recall: 0.9762 - val_binary_accuracy: 0.9766 - val_false_positives: 149.0000 - val_false_negatives: 155.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 5/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0771 - accuracy: 0.9699 - precision: 0.9701 - recall: 0.9701 - binary_accuracy: 0.9701 - false_positives: 906.0000 - false_negatives: 907.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0618 - val_accuracy: 0.9794 - val_precision: 0.9795 - val_recall: 0.9795 - val_binary_accuracy: 0.9795 - val_false_positives: 133.0000 - val_false_negatives: 133.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 6/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0740 - accuracy: 0.9730 - precision: 0.9727 - recall: 0.9727 - binary_accuracy: 0.9727 - false_positives: 827.0000 - false_negatives: 829.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0598 - val_accuracy: 0.9788 - val_precision: 0.9785 - val_recall: 0.9792 - val_binary_accuracy: 0.9788 - val_false_positives: 140.0000 - val_false_negatives: 135.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 7/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0680 - accuracy: 0.9750 - precision: 0.9748 - recall: 0.9752 - binary_accuracy: 0.9750 - false_positives: 766.0000 - false_negatives: 751.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0701 - val_accuracy: 0.9735 - val_precision: 0.9736 - val_recall: 0.9741 - val_binary_accuracy: 0.9738 - val_false_positives: 172.0000 - val_false_negatives: 168.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 8/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0632 - accuracy: 0.9771 - precision: 0.9773 - recall: 0.9769 - binary_accuracy: 0.9771 - false_positives: 687.0000 - false_negatives: 700.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0576 - val_accuracy: 0.9786 - val_precision: 0.9785 - val_recall: 0.9786 - val_binary_accuracy: 0.9785 - val_false_positives: 140.0000 - val_false_negatives: 139.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 9/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0585 - accuracy: 0.9779 - precision: 0.9779 - recall: 0.9778 - binary_accuracy: 0.9779 - false_positives: 670.0000 - false_negatives: 673.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0538 - val_accuracy: 0.9817 - val_precision: 0.9814 - val_recall: 0.9823 - val_binary_accuracy: 0.9818 - val_false_positives: 121.0000 - val_false_negatives: 115.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 10/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0574 - accuracy: 0.9785 - precision: 0.9787 - recall: 0.9787 - binary_accuracy: 0.9787 - false_positives: 647.0000 - false_negatives: 646.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0628 - val_accuracy: 0.9780 - val_precision: 0.9777 - val_recall: 0.9778 - val_binary_accuracy: 0.9778 - val_false_positives: 145.0000 - val_false_negatives: 144.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 11/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0530 - accuracy: 0.9798 - precision: 0.9796 - recall: 0.9801 - binary_accuracy: 0.9799 - false_positives: 618.0000 - false_negatives: 604.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0480 - val_accuracy: 0.9829 - val_precision: 0.9831 - val_recall: 0.9826 - val_binary_accuracy: 0.9828 - val_false_positives: 110.0000 - val_false_negatives: 113.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 12/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0534 - accuracy: 0.9800 - precision: 0.9801 - recall: 0.9799 - binary_accuracy: 0.9800 - false_positives: 604.0000 - false_negatives: 609.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0495 - val_accuracy: 0.9849 - val_precision: 0.9851 - val_recall: 0.9848 - val_binary_accuracy: 0.9849 - val_false_positives: 97.0000 - val_false_negatives: 99.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 13/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0509 - accuracy: 0.9808 - precision: 0.9807 - recall: 0.9808 - binary_accuracy: 0.9808 - false_positives: 584.0000 - false_negatives: 583.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0463 - val_accuracy: 0.9843 - val_precision: 0.9840 - val_recall: 0.9842 - val_binary_accuracy: 0.9841 - val_false_positives: 104.0000 - val_false_negatives: 103.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 14/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0491 - accuracy: 0.9812 - precision: 0.9813 - recall: 0.9814 - binary_accuracy: 0.9814 - false_positives: 566.0000 - false_negatives: 563.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0459 - val_accuracy: 0.9849 - val_precision: 0.9848 - val_recall: 0.9852 - val_binary_accuracy: 0.9850 - val_false_positives: 99.0000 - val_false_negatives: 96.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 15/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0447 - accuracy: 0.9826 - precision: 0.9827 - recall: 0.9828 - binary_accuracy: 0.9828 - false_positives: 525.0000 - false_negatives: 521.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0458 - val_accuracy: 0.9852 - val_precision: 0.9851 - val_recall: 0.9852 - val_binary_accuracy: 0.9852 - val_false_positives: 97.0000 - val_false_negatives: 96.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 16/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0466 - accuracy: 0.9828 - precision: 0.9829 - recall: 0.9829 - binary_accuracy: 0.9829 - false_positives: 518.0000 - false_negatives: 519.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0509 - val_accuracy: 0.9825 - val_precision: 0.9825 - val_recall: 0.9825 - val_binary_accuracy: 0.9825 - val_false_positives: 114.0000 - val_false_negatives: 114.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 17/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0452 - accuracy: 0.9832 - precision: 0.9832 - recall: 0.9832 - binary_accuracy: 0.9832 - false_positives: 511.0000 - false_negatives: 508.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0413 - val_accuracy: 0.9860 - val_precision: 0.9860 - val_recall: 0.9860 - val_binary_accuracy: 0.9860 - val_false_positives: 91.0000 - val_false_negatives: 91.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 18/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0392 - accuracy: 0.9853 - precision: 0.9854 - recall: 0.9853 - binary_accuracy: 0.9853 - false_positives: 443.0000 - false_negatives: 446.0000 - sensitivity_at_specificity: 0.9999 - val_loss: 0.0471 - val_accuracy: 0.9834 - val_precision: 0.9838 - val_recall: 0.9837 - val_binary_accuracy: 0.9838 - val_false_positives: 105.0000 - val_false_negatives: 106.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 19/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0385 - accuracy: 0.9848 - precision: 0.9848 - recall: 0.9849 - binary_accuracy: 0.9848 - false_positives: 461.0000 - false_negatives: 458.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0462 - val_accuracy: 0.9842 - val_precision: 0.9841 - val_recall: 0.9840 - val_binary_accuracy: 0.9841 - val_false_positives: 103.0000 - val_false_negatives: 104.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 20/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0372 - accuracy: 0.9863 - precision: 0.9863 - recall: 0.9863 - binary_accuracy: 0.9863 - false_positives: 415.0000 - false_negatives: 415.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0443 - val_accuracy: 0.9868 - val_precision: 0.9868 - val_recall: 0.9868 - val_binary_accuracy: 0.9868 - val_false_positives: 86.0000 - val_false_negatives: 86.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 21/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0382 - accuracy: 0.9857 - precision: 0.9856 - recall: 0.9856 - binary_accuracy: 0.9856 - false_positives: 438.0000 - false_negatives: 436.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0487 - val_accuracy: 0.9838 - val_precision: 0.9838 - val_recall: 0.9838 - val_binary_accuracy: 0.9838 - val_false_positives: 105.0000 - val_false_negatives: 105.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 22/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0389 - accuracy: 0.9852 - precision: 0.9851 - recall: 0.9852 - binary_accuracy: 0.9851 - false_positives: 453.0000 - false_negatives: 448.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0428 - val_accuracy: 0.9845 - val_precision: 0.9848 - val_recall: 0.9840 - val_binary_accuracy: 0.9844 - val_false_positives: 99.0000 - val_false_negatives: 104.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 23/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0342 - accuracy: 0.9876 - precision: 0.9876 - recall: 0.9876 - binary_accuracy: 0.9876 - false_positives: 375.0000 - false_negatives: 377.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0432 - val_accuracy: 0.9865 - val_precision: 0.9865 - val_recall: 0.9865 - val_binary_accuracy: 0.9865 - val_false_positives: 88.0000 - val_false_negatives: 88.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 24/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0366 - accuracy: 0.9862 - precision: 0.9862 - recall: 0.9862 - binary_accuracy: 0.9862 - false_positives: 418.0000 - false_negatives: 418.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0477 - val_accuracy: 0.9826 - val_precision: 0.9828 - val_recall: 0.9828 - val_binary_accuracy: 0.9828 - val_false_positives: 112.0000 - val_false_negatives: 112.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 25/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0335 - accuracy: 0.9875 - precision: 0.9875 - recall: 0.9874 - binary_accuracy: 0.9874 - false_positives: 380.0000 - false_negatives: 382.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0507 - val_accuracy: 0.9854 - val_precision: 0.9855 - val_recall: 0.9854 - val_binary_accuracy: 0.9855 - val_false_positives: 94.0000 - val_false_negatives: 95.0000 - val_sensitivity_at_specificity: 0.9989\n",
            "Test loss: 0.04140113666653633\n",
            "Test accuracy: 0.9873846173286438\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 137, 2, 32)        800       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 68, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 45, 2, 64)         49216     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 22, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1408)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1408)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 2818      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 53154 (207.63 KB)\n",
            "Trainable params: 53154 (207.63 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "474/474 [==============================] - 7s 9ms/step - loss: 0.2492 - accuracy: 0.8883 - precision: 0.8863 - recall: 0.8867 - binary_accuracy: 0.8864 - false_positives: 3451.0000 - false_negatives: 3437.0000 - sensitivity_at_specificity: 0.9968 - val_loss: 0.1610 - val_accuracy: 0.9329 - val_precision: 0.9319 - val_recall: 0.9351 - val_binary_accuracy: 0.9334 - val_false_positives: 444.0000 - val_false_negatives: 422.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 2/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1459 - accuracy: 0.9397 - precision: 0.9391 - recall: 0.9384 - binary_accuracy: 0.9388 - false_positives: 1844.0000 - false_negatives: 1869.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.1070 - val_accuracy: 0.9611 - val_precision: 0.9620 - val_recall: 0.9585 - val_binary_accuracy: 0.9603 - val_false_positives: 246.0000 - val_false_negatives: 270.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 3/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1127 - accuracy: 0.9576 - precision: 0.9567 - recall: 0.9571 - binary_accuracy: 0.9569 - false_positives: 1313.0000 - false_negatives: 1301.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.1012 - val_accuracy: 0.9595 - val_precision: 0.9610 - val_recall: 0.9597 - val_binary_accuracy: 0.9604 - val_false_positives: 253.0000 - val_false_negatives: 262.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 4/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0972 - accuracy: 0.9640 - precision: 0.9635 - recall: 0.9634 - binary_accuracy: 0.9635 - false_positives: 1107.0000 - false_negatives: 1109.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0831 - val_accuracy: 0.9705 - val_precision: 0.9702 - val_recall: 0.9709 - val_binary_accuracy: 0.9705 - val_false_positives: 194.0000 - val_false_negatives: 189.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 5/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0865 - accuracy: 0.9678 - precision: 0.9677 - recall: 0.9677 - binary_accuracy: 0.9677 - false_positives: 980.0000 - false_negatives: 980.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0683 - val_accuracy: 0.9769 - val_precision: 0.9768 - val_recall: 0.9768 - val_binary_accuracy: 0.9768 - val_false_positives: 151.0000 - val_false_negatives: 151.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 6/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0781 - accuracy: 0.9699 - precision: 0.9698 - recall: 0.9699 - binary_accuracy: 0.9698 - false_positives: 917.0000 - false_negatives: 913.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0677 - val_accuracy: 0.9749 - val_precision: 0.9745 - val_recall: 0.9752 - val_binary_accuracy: 0.9748 - val_false_positives: 166.0000 - val_false_negatives: 161.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 7/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0703 - accuracy: 0.9734 - precision: 0.9732 - recall: 0.9735 - binary_accuracy: 0.9734 - false_positives: 812.0000 - false_negatives: 804.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0727 - val_accuracy: 0.9728 - val_precision: 0.9728 - val_recall: 0.9723 - val_binary_accuracy: 0.9725 - val_false_positives: 177.0000 - val_false_negatives: 180.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 8/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0683 - accuracy: 0.9733 - precision: 0.9732 - recall: 0.9735 - binary_accuracy: 0.9733 - false_positives: 812.0000 - false_negatives: 805.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0603 - val_accuracy: 0.9794 - val_precision: 0.9792 - val_recall: 0.9795 - val_binary_accuracy: 0.9794 - val_false_positives: 135.0000 - val_false_negatives: 133.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 9/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0639 - accuracy: 0.9762 - precision: 0.9762 - recall: 0.9763 - binary_accuracy: 0.9762 - false_positives: 723.0000 - false_negatives: 718.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0553 - val_accuracy: 0.9811 - val_precision: 0.9811 - val_recall: 0.9808 - val_binary_accuracy: 0.9809 - val_false_positives: 123.0000 - val_false_negatives: 125.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 10/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0616 - accuracy: 0.9767 - precision: 0.9766 - recall: 0.9767 - binary_accuracy: 0.9767 - false_positives: 710.0000 - false_negatives: 706.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0557 - val_accuracy: 0.9806 - val_precision: 0.9806 - val_recall: 0.9806 - val_binary_accuracy: 0.9806 - val_false_positives: 126.0000 - val_false_negatives: 126.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 11/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0598 - accuracy: 0.9780 - precision: 0.9780 - recall: 0.9782 - binary_accuracy: 0.9781 - false_positives: 668.0000 - false_negatives: 660.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0503 - val_accuracy: 0.9820 - val_precision: 0.9820 - val_recall: 0.9820 - val_binary_accuracy: 0.9820 - val_false_positives: 117.0000 - val_false_negatives: 117.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 12/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0541 - accuracy: 0.9799 - precision: 0.9800 - recall: 0.9797 - binary_accuracy: 0.9799 - false_positives: 605.0000 - false_negatives: 616.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0487 - val_accuracy: 0.9834 - val_precision: 0.9834 - val_recall: 0.9837 - val_binary_accuracy: 0.9835 - val_false_positives: 108.0000 - val_false_negatives: 106.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 13/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0530 - accuracy: 0.9800 - precision: 0.9800 - recall: 0.9798 - binary_accuracy: 0.9799 - false_positives: 606.0000 - false_negatives: 612.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0485 - val_accuracy: 0.9822 - val_precision: 0.9821 - val_recall: 0.9818 - val_binary_accuracy: 0.9820 - val_false_positives: 116.0000 - val_false_negatives: 118.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 14/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0483 - accuracy: 0.9817 - precision: 0.9816 - recall: 0.9815 - binary_accuracy: 0.9815 - false_positives: 558.0000 - false_negatives: 562.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0578 - val_accuracy: 0.9820 - val_precision: 0.9821 - val_recall: 0.9820 - val_binary_accuracy: 0.9821 - val_false_positives: 116.0000 - val_false_negatives: 117.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 15/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0500 - accuracy: 0.9817 - precision: 0.9818 - recall: 0.9818 - binary_accuracy: 0.9818 - false_positives: 552.0000 - false_negatives: 551.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0492 - val_accuracy: 0.9837 - val_precision: 0.9837 - val_recall: 0.9837 - val_binary_accuracy: 0.9837 - val_false_positives: 106.0000 - val_false_negatives: 106.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 16/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0454 - accuracy: 0.9826 - precision: 0.9826 - recall: 0.9826 - binary_accuracy: 0.9826 - false_positives: 528.0000 - false_negatives: 528.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0529 - val_accuracy: 0.9822 - val_precision: 0.9820 - val_recall: 0.9820 - val_binary_accuracy: 0.9820 - val_false_positives: 117.0000 - val_false_negatives: 117.0000 - val_sensitivity_at_specificity: 0.9989\n",
            "Epoch 17/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0450 - accuracy: 0.9827 - precision: 0.9825 - recall: 0.9826 - binary_accuracy: 0.9826 - false_positives: 531.0000 - false_negatives: 527.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0509 - val_accuracy: 0.9820 - val_precision: 0.9820 - val_recall: 0.9820 - val_binary_accuracy: 0.9820 - val_false_positives: 117.0000 - val_false_negatives: 117.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 18/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0436 - accuracy: 0.9839 - precision: 0.9837 - recall: 0.9840 - binary_accuracy: 0.9838 - false_positives: 495.0000 - false_negatives: 485.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0406 - val_accuracy: 0.9860 - val_precision: 0.9860 - val_recall: 0.9862 - val_binary_accuracy: 0.9861 - val_false_positives: 91.0000 - val_false_negatives: 90.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 19/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0433 - accuracy: 0.9834 - precision: 0.9834 - recall: 0.9832 - binary_accuracy: 0.9833 - false_positives: 503.0000 - false_negatives: 509.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0481 - val_accuracy: 0.9828 - val_precision: 0.9828 - val_recall: 0.9828 - val_binary_accuracy: 0.9828 - val_false_positives: 112.0000 - val_false_negatives: 112.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 20/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0403 - accuracy: 0.9857 - precision: 0.9858 - recall: 0.9856 - binary_accuracy: 0.9857 - false_positives: 431.0000 - false_negatives: 436.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0445 - val_accuracy: 0.9845 - val_precision: 0.9846 - val_recall: 0.9846 - val_binary_accuracy: 0.9846 - val_false_positives: 100.0000 - val_false_negatives: 100.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 21/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0401 - accuracy: 0.9847 - precision: 0.9847 - recall: 0.9848 - binary_accuracy: 0.9848 - false_positives: 463.0000 - false_negatives: 461.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0447 - val_accuracy: 0.9845 - val_precision: 0.9846 - val_recall: 0.9848 - val_binary_accuracy: 0.9847 - val_false_positives: 100.0000 - val_false_negatives: 99.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 22/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0405 - accuracy: 0.9843 - precision: 0.9842 - recall: 0.9842 - binary_accuracy: 0.9842 - false_positives: 479.0000 - false_negatives: 479.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0463 - val_accuracy: 0.9851 - val_precision: 0.9852 - val_recall: 0.9851 - val_binary_accuracy: 0.9852 - val_false_positives: 96.0000 - val_false_negatives: 97.0000 - val_sensitivity_at_specificity: 0.9989\n",
            "Epoch 23/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0387 - accuracy: 0.9858 - precision: 0.9858 - recall: 0.9858 - binary_accuracy: 0.9858 - false_positives: 432.0000 - false_negatives: 432.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0499 - val_accuracy: 0.9854 - val_precision: 0.9854 - val_recall: 0.9854 - val_binary_accuracy: 0.9854 - val_false_positives: 95.0000 - val_false_negatives: 95.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 24/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0359 - accuracy: 0.9859 - precision: 0.9859 - recall: 0.9858 - binary_accuracy: 0.9858 - false_positives: 428.0000 - false_negatives: 432.0000 - sensitivity_at_specificity: 0.9999 - val_loss: 0.0417 - val_accuracy: 0.9868 - val_precision: 0.9865 - val_recall: 0.9868 - val_binary_accuracy: 0.9866 - val_false_positives: 88.0000 - val_false_negatives: 86.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 25/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0351 - accuracy: 0.9866 - precision: 0.9866 - recall: 0.9866 - binary_accuracy: 0.9866 - false_positives: 407.0000 - false_negatives: 405.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0427 - val_accuracy: 0.9865 - val_precision: 0.9863 - val_recall: 0.9865 - val_binary_accuracy: 0.9864 - val_false_positives: 89.0000 - val_false_negatives: 88.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Test loss: 0.037166815251111984\n",
            "Test accuracy: 0.9873846173286438\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 136, 2, 32)        832       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 68, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 44, 2, 64)         51264     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 22, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1408)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1408)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 2818      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 55234 (215.76 KB)\n",
            "Trainable params: 55234 (215.76 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "474/474 [==============================] - 6s 8ms/step - loss: 0.2459 - accuracy: 0.8904 - precision: 0.8884 - recall: 0.8876 - binary_accuracy: 0.8881 - false_positives: 3381.0000 - false_negatives: 3409.0000 - sensitivity_at_specificity: 0.9979 - val_loss: 0.1669 - val_accuracy: 0.9229 - val_precision: 0.9216 - val_recall: 0.9246 - val_binary_accuracy: 0.9230 - val_false_positives: 511.0000 - val_false_negatives: 490.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 2/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1421 - accuracy: 0.9439 - precision: 0.9429 - recall: 0.9427 - binary_accuracy: 0.9428 - false_positives: 1731.0000 - false_negatives: 1738.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.1024 - val_accuracy: 0.9601 - val_precision: 0.9606 - val_recall: 0.9606 - val_binary_accuracy: 0.9606 - val_false_positives: 256.0000 - val_false_negatives: 256.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 3/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1100 - accuracy: 0.9571 - precision: 0.9568 - recall: 0.9574 - binary_accuracy: 0.9571 - false_positives: 1312.0000 - false_negatives: 1293.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.1026 - val_accuracy: 0.9625 - val_precision: 0.9622 - val_recall: 0.9631 - val_binary_accuracy: 0.9626 - val_false_positives: 246.0000 - val_false_negatives: 240.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 4/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0932 - accuracy: 0.9649 - precision: 0.9647 - recall: 0.9650 - binary_accuracy: 0.9649 - false_positives: 1070.0000 - false_negatives: 1062.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0770 - val_accuracy: 0.9732 - val_precision: 0.9731 - val_recall: 0.9725 - val_binary_accuracy: 0.9728 - val_false_positives: 175.0000 - val_false_negatives: 179.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 5/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0835 - accuracy: 0.9676 - precision: 0.9669 - recall: 0.9676 - binary_accuracy: 0.9672 - false_positives: 1003.0000 - false_negatives: 984.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.0680 - val_accuracy: 0.9771 - val_precision: 0.9772 - val_recall: 0.9762 - val_binary_accuracy: 0.9767 - val_false_positives: 148.0000 - val_false_negatives: 155.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 6/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0766 - accuracy: 0.9710 - precision: 0.9707 - recall: 0.9713 - binary_accuracy: 0.9710 - false_positives: 890.0000 - false_negatives: 871.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0705 - val_accuracy: 0.9741 - val_precision: 0.9743 - val_recall: 0.9741 - val_binary_accuracy: 0.9742 - val_false_positives: 167.0000 - val_false_negatives: 168.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 7/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0690 - accuracy: 0.9743 - precision: 0.9744 - recall: 0.9743 - binary_accuracy: 0.9744 - false_positives: 775.0000 - false_negatives: 779.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0555 - val_accuracy: 0.9812 - val_precision: 0.9812 - val_recall: 0.9815 - val_binary_accuracy: 0.9814 - val_false_positives: 122.0000 - val_false_negatives: 120.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 8/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0634 - accuracy: 0.9764 - precision: 0.9766 - recall: 0.9764 - binary_accuracy: 0.9765 - false_positives: 708.0000 - false_negatives: 717.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0588 - val_accuracy: 0.9797 - val_precision: 0.9795 - val_recall: 0.9800 - val_binary_accuracy: 0.9798 - val_false_positives: 133.0000 - val_false_negatives: 130.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 9/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0627 - accuracy: 0.9769 - precision: 0.9769 - recall: 0.9770 - binary_accuracy: 0.9769 - false_positives: 701.0000 - false_negatives: 698.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0533 - val_accuracy: 0.9823 - val_precision: 0.9820 - val_recall: 0.9822 - val_binary_accuracy: 0.9821 - val_false_positives: 117.0000 - val_false_negatives: 116.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 10/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0586 - accuracy: 0.9783 - precision: 0.9782 - recall: 0.9782 - binary_accuracy: 0.9782 - false_positives: 661.0000 - false_negatives: 662.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0551 - val_accuracy: 0.9800 - val_precision: 0.9799 - val_recall: 0.9805 - val_binary_accuracy: 0.9802 - val_false_positives: 131.0000 - val_false_negatives: 127.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 11/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0538 - accuracy: 0.9801 - precision: 0.9799 - recall: 0.9801 - binary_accuracy: 0.9800 - false_positives: 610.0000 - false_negatives: 605.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0477 - val_accuracy: 0.9837 - val_precision: 0.9840 - val_recall: 0.9832 - val_binary_accuracy: 0.9836 - val_false_positives: 104.0000 - val_false_negatives: 109.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 12/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0522 - accuracy: 0.9806 - precision: 0.9806 - recall: 0.9806 - binary_accuracy: 0.9806 - false_positives: 587.0000 - false_negatives: 589.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0540 - val_accuracy: 0.9834 - val_precision: 0.9834 - val_recall: 0.9832 - val_binary_accuracy: 0.9833 - val_false_positives: 108.0000 - val_false_negatives: 109.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 13/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0494 - accuracy: 0.9813 - precision: 0.9813 - recall: 0.9813 - binary_accuracy: 0.9813 - false_positives: 567.0000 - false_negatives: 568.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0491 - val_accuracy: 0.9817 - val_precision: 0.9817 - val_recall: 0.9817 - val_binary_accuracy: 0.9817 - val_false_positives: 119.0000 - val_false_negatives: 119.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 14/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0490 - accuracy: 0.9819 - precision: 0.9819 - recall: 0.9817 - binary_accuracy: 0.9818 - false_positives: 548.0000 - false_negatives: 555.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0623 - val_accuracy: 0.9771 - val_precision: 0.9772 - val_recall: 0.9769 - val_binary_accuracy: 0.9771 - val_false_positives: 148.0000 - val_false_negatives: 150.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 15/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0452 - accuracy: 0.9829 - precision: 0.9831 - recall: 0.9827 - binary_accuracy: 0.9829 - false_positives: 513.0000 - false_negatives: 524.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0470 - val_accuracy: 0.9837 - val_precision: 0.9837 - val_recall: 0.9835 - val_binary_accuracy: 0.9836 - val_false_positives: 106.0000 - val_false_negatives: 107.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 16/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0462 - accuracy: 0.9830 - precision: 0.9830 - recall: 0.9829 - binary_accuracy: 0.9829 - false_positives: 516.0000 - false_negatives: 519.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0442 - val_accuracy: 0.9852 - val_precision: 0.9851 - val_recall: 0.9852 - val_binary_accuracy: 0.9852 - val_false_positives: 97.0000 - val_false_negatives: 96.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 17/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0416 - accuracy: 0.9846 - precision: 0.9845 - recall: 0.9848 - binary_accuracy: 0.9847 - false_positives: 469.0000 - false_negatives: 461.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0475 - val_accuracy: 0.9828 - val_precision: 0.9825 - val_recall: 0.9829 - val_binary_accuracy: 0.9827 - val_false_positives: 114.0000 - val_false_negatives: 111.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 18/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0396 - accuracy: 0.9859 - precision: 0.9858 - recall: 0.9858 - binary_accuracy: 0.9858 - false_positives: 432.0000 - false_negatives: 431.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0437 - val_accuracy: 0.9843 - val_precision: 0.9845 - val_recall: 0.9843 - val_binary_accuracy: 0.9844 - val_false_positives: 101.0000 - val_false_negatives: 102.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 19/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0411 - accuracy: 0.9848 - precision: 0.9847 - recall: 0.9848 - binary_accuracy: 0.9847 - false_positives: 465.0000 - false_negatives: 462.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0444 - val_accuracy: 0.9849 - val_precision: 0.9849 - val_recall: 0.9848 - val_binary_accuracy: 0.9848 - val_false_positives: 98.0000 - val_false_negatives: 99.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 20/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0395 - accuracy: 0.9849 - precision: 0.9848 - recall: 0.9847 - binary_accuracy: 0.9848 - false_positives: 461.0000 - false_negatives: 463.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0450 - val_accuracy: 0.9848 - val_precision: 0.9846 - val_recall: 0.9849 - val_binary_accuracy: 0.9848 - val_false_positives: 100.0000 - val_false_negatives: 98.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 21/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0347 - accuracy: 0.9869 - precision: 0.9870 - recall: 0.9869 - binary_accuracy: 0.9870 - false_positives: 395.0000 - false_negatives: 396.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0458 - val_accuracy: 0.9834 - val_precision: 0.9834 - val_recall: 0.9835 - val_binary_accuracy: 0.9835 - val_false_positives: 108.0000 - val_false_negatives: 107.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 22/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0359 - accuracy: 0.9864 - precision: 0.9865 - recall: 0.9865 - binary_accuracy: 0.9865 - false_positives: 409.0000 - false_negatives: 410.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0477 - val_accuracy: 0.9840 - val_precision: 0.9842 - val_recall: 0.9843 - val_binary_accuracy: 0.9842 - val_false_positives: 103.0000 - val_false_negatives: 102.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 23/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0354 - accuracy: 0.9864 - precision: 0.9864 - recall: 0.9864 - binary_accuracy: 0.9864 - false_positives: 413.0000 - false_negatives: 413.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0496 - val_accuracy: 0.9848 - val_precision: 0.9848 - val_recall: 0.9848 - val_binary_accuracy: 0.9848 - val_false_positives: 99.0000 - val_false_negatives: 99.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 24/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0347 - accuracy: 0.9871 - precision: 0.9870 - recall: 0.9869 - binary_accuracy: 0.9870 - false_positives: 393.0000 - false_negatives: 396.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0519 - val_accuracy: 0.9828 - val_precision: 0.9831 - val_recall: 0.9828 - val_binary_accuracy: 0.9829 - val_false_positives: 110.0000 - val_false_negatives: 112.0000 - val_sensitivity_at_specificity: 0.9986\n",
            "Epoch 25/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0324 - accuracy: 0.9873 - precision: 0.9872 - recall: 0.9874 - binary_accuracy: 0.9873 - false_positives: 387.0000 - false_negatives: 382.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0594 - val_accuracy: 0.9800 - val_precision: 0.9800 - val_recall: 0.9802 - val_binary_accuracy: 0.9801 - val_false_positives: 130.0000 - val_false_negatives: 129.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Test loss: 0.049891941249370575\n",
            "Test accuracy: 0.9821538329124451\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 135, 2, 32)        864       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 67, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 42, 2, 64)         53312     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 21, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1344)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1344)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 2690      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 57186 (223.38 KB)\n",
            "Trainable params: 57186 (223.38 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "474/474 [==============================] - 6s 8ms/step - loss: 0.2355 - accuracy: 0.8966 - precision: 0.8946 - recall: 0.8920 - binary_accuracy: 0.8934 - false_positives: 3189.0000 - false_negatives: 3274.0000 - sensitivity_at_specificity: 0.9982 - val_loss: 0.1363 - val_accuracy: 0.9497 - val_precision: 0.9476 - val_recall: 0.9520 - val_binary_accuracy: 0.9497 - val_false_positives: 342.0000 - val_false_negatives: 312.0000 - val_sensitivity_at_specificity: 1.0000\n",
            "Epoch 2/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1314 - accuracy: 0.9480 - precision: 0.9472 - recall: 0.9467 - binary_accuracy: 0.9470 - false_positives: 1601.0000 - false_negatives: 1615.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0932 - val_accuracy: 0.9645 - val_precision: 0.9645 - val_recall: 0.9643 - val_binary_accuracy: 0.9644 - val_false_positives: 231.0000 - val_false_negatives: 232.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 3/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1026 - accuracy: 0.9610 - precision: 0.9608 - recall: 0.9603 - binary_accuracy: 0.9605 - false_positives: 1189.0000 - false_negatives: 1205.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0712 - val_accuracy: 0.9758 - val_precision: 0.9751 - val_recall: 0.9760 - val_binary_accuracy: 0.9755 - val_false_positives: 162.0000 - val_false_negatives: 156.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 4/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0874 - accuracy: 0.9672 - precision: 0.9668 - recall: 0.9671 - binary_accuracy: 0.9670 - false_positives: 1007.0000 - false_negatives: 997.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0714 - val_accuracy: 0.9752 - val_precision: 0.9757 - val_recall: 0.9745 - val_binary_accuracy: 0.9751 - val_false_positives: 158.0000 - val_false_negatives: 166.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 5/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0777 - accuracy: 0.9706 - precision: 0.9703 - recall: 0.9710 - binary_accuracy: 0.9706 - false_positives: 900.0000 - false_negatives: 881.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0643 - val_accuracy: 0.9766 - val_precision: 0.9768 - val_recall: 0.9765 - val_binary_accuracy: 0.9766 - val_false_positives: 151.0000 - val_false_negatives: 153.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 6/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0734 - accuracy: 0.9733 - precision: 0.9730 - recall: 0.9735 - binary_accuracy: 0.9732 - false_positives: 819.0000 - false_negatives: 804.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0767 - val_accuracy: 0.9720 - val_precision: 0.9723 - val_recall: 0.9720 - val_binary_accuracy: 0.9721 - val_false_positives: 180.0000 - val_false_negatives: 182.0000 - val_sensitivity_at_specificity: 0.9989\n",
            "Epoch 7/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0666 - accuracy: 0.9753 - precision: 0.9751 - recall: 0.9754 - binary_accuracy: 0.9753 - false_positives: 755.0000 - false_negatives: 745.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0560 - val_accuracy: 0.9797 - val_precision: 0.9796 - val_recall: 0.9805 - val_binary_accuracy: 0.9800 - val_false_positives: 133.0000 - val_false_negatives: 127.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 8/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0620 - accuracy: 0.9758 - precision: 0.9760 - recall: 0.9756 - binary_accuracy: 0.9758 - false_positives: 727.0000 - false_negatives: 741.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0579 - val_accuracy: 0.9780 - val_precision: 0.9780 - val_recall: 0.9777 - val_binary_accuracy: 0.9778 - val_false_positives: 143.0000 - val_false_negatives: 145.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 9/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.0597 - accuracy: 0.9791 - precision: 0.9788 - recall: 0.9790 - binary_accuracy: 0.9789 - false_positives: 644.0000 - false_negatives: 638.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0552 - val_accuracy: 0.9805 - val_precision: 0.9805 - val_recall: 0.9806 - val_binary_accuracy: 0.9805 - val_false_positives: 127.0000 - val_false_negatives: 126.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 10/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0571 - accuracy: 0.9787 - precision: 0.9788 - recall: 0.9787 - binary_accuracy: 0.9787 - false_positives: 643.0000 - false_negatives: 646.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0551 - val_accuracy: 0.9818 - val_precision: 0.9823 - val_recall: 0.9815 - val_binary_accuracy: 0.9819 - val_false_positives: 115.0000 - val_false_negatives: 120.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 11/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0546 - accuracy: 0.9799 - precision: 0.9797 - recall: 0.9799 - binary_accuracy: 0.9798 - false_positives: 617.0000 - false_negatives: 611.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.0509 - val_accuracy: 0.9834 - val_precision: 0.9832 - val_recall: 0.9834 - val_binary_accuracy: 0.9833 - val_false_positives: 109.0000 - val_false_negatives: 108.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 12/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0523 - accuracy: 0.9812 - precision: 0.9812 - recall: 0.9811 - binary_accuracy: 0.9812 - false_positives: 570.0000 - false_negatives: 572.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0499 - val_accuracy: 0.9834 - val_precision: 0.9831 - val_recall: 0.9838 - val_binary_accuracy: 0.9835 - val_false_positives: 110.0000 - val_false_negatives: 105.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 13/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0489 - accuracy: 0.9820 - precision: 0.9820 - recall: 0.9818 - binary_accuracy: 0.9819 - false_positives: 547.0000 - false_negatives: 551.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0516 - val_accuracy: 0.9809 - val_precision: 0.9808 - val_recall: 0.9808 - val_binary_accuracy: 0.9808 - val_false_positives: 125.0000 - val_false_negatives: 125.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 14/25\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.0487 - accuracy: 0.9814 - precision: 0.9813 - recall: 0.9814 - binary_accuracy: 0.9814 - false_positives: 568.0000 - false_negatives: 563.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0450 - val_accuracy: 0.9857 - val_precision: 0.9855 - val_recall: 0.9857 - val_binary_accuracy: 0.9856 - val_false_positives: 94.0000 - val_false_negatives: 93.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 15/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0454 - accuracy: 0.9832 - precision: 0.9832 - recall: 0.9831 - binary_accuracy: 0.9831 - false_positives: 511.0000 - false_negatives: 512.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0521 - val_accuracy: 0.9809 - val_precision: 0.9809 - val_recall: 0.9811 - val_binary_accuracy: 0.9810 - val_false_positives: 124.0000 - val_false_negatives: 123.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 16/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0445 - accuracy: 0.9837 - precision: 0.9839 - recall: 0.9837 - binary_accuracy: 0.9838 - false_positives: 489.0000 - false_negatives: 495.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0567 - val_accuracy: 0.9814 - val_precision: 0.9815 - val_recall: 0.9812 - val_binary_accuracy: 0.9814 - val_false_positives: 120.0000 - val_false_negatives: 122.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 17/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0433 - accuracy: 0.9840 - precision: 0.9839 - recall: 0.9840 - binary_accuracy: 0.9839 - false_positives: 488.0000 - false_negatives: 486.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0529 - val_accuracy: 0.9817 - val_precision: 0.9817 - val_recall: 0.9815 - val_binary_accuracy: 0.9816 - val_false_positives: 119.0000 - val_false_negatives: 120.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 18/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0402 - accuracy: 0.9852 - precision: 0.9849 - recall: 0.9852 - binary_accuracy: 0.9850 - false_positives: 459.0000 - false_negatives: 450.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0435 - val_accuracy: 0.9854 - val_precision: 0.9852 - val_recall: 0.9855 - val_binary_accuracy: 0.9854 - val_false_positives: 96.0000 - val_false_negatives: 94.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 19/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0385 - accuracy: 0.9861 - precision: 0.9861 - recall: 0.9862 - binary_accuracy: 0.9861 - false_positives: 423.0000 - false_negatives: 419.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0431 - val_accuracy: 0.9863 - val_precision: 0.9862 - val_recall: 0.9866 - val_binary_accuracy: 0.9864 - val_false_positives: 90.0000 - val_false_negatives: 87.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 20/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0382 - accuracy: 0.9850 - precision: 0.9849 - recall: 0.9849 - binary_accuracy: 0.9849 - false_positives: 459.0000 - false_negatives: 457.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0419 - val_accuracy: 0.9862 - val_precision: 0.9861 - val_recall: 0.9860 - val_binary_accuracy: 0.9861 - val_false_positives: 90.0000 - val_false_negatives: 91.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 21/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0369 - accuracy: 0.9859 - precision: 0.9860 - recall: 0.9859 - binary_accuracy: 0.9859 - false_positives: 425.0000 - false_negatives: 429.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0578 - val_accuracy: 0.9806 - val_precision: 0.9806 - val_recall: 0.9808 - val_binary_accuracy: 0.9807 - val_false_positives: 126.0000 - val_false_negatives: 125.0000 - val_sensitivity_at_specificity: 0.9989\n",
            "Epoch 22/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0341 - accuracy: 0.9876 - precision: 0.9876 - recall: 0.9875 - binary_accuracy: 0.9876 - false_positives: 376.0000 - false_negatives: 379.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0528 - val_accuracy: 0.9823 - val_precision: 0.9826 - val_recall: 0.9823 - val_binary_accuracy: 0.9825 - val_false_positives: 113.0000 - val_false_negatives: 115.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 23/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0359 - accuracy: 0.9870 - precision: 0.9869 - recall: 0.9869 - binary_accuracy: 0.9869 - false_positives: 397.0000 - false_negatives: 396.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0447 - val_accuracy: 0.9849 - val_precision: 0.9849 - val_recall: 0.9848 - val_binary_accuracy: 0.9848 - val_false_positives: 98.0000 - val_false_negatives: 99.0000 - val_sensitivity_at_specificity: 0.9988\n",
            "Epoch 24/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0334 - accuracy: 0.9877 - precision: 0.9877 - recall: 0.9878 - binary_accuracy: 0.9878 - false_positives: 373.0000 - false_negatives: 370.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0442 - val_accuracy: 0.9863 - val_precision: 0.9863 - val_recall: 0.9863 - val_binary_accuracy: 0.9863 - val_false_positives: 89.0000 - val_false_negatives: 89.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 25/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0332 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9872 - binary_accuracy: 0.9873 - false_positives: 384.0000 - false_negatives: 388.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0506 - val_accuracy: 0.9846 - val_precision: 0.9845 - val_recall: 0.9846 - val_binary_accuracy: 0.9845 - val_false_positives: 101.0000 - val_false_negatives: 100.0000 - val_sensitivity_at_specificity: 0.9989\n",
            "Test loss: 0.04623577743768692\n",
            "Test accuracy: 0.9835384488105774\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 134, 2, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 67, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 41, 2, 64)         55360     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 20, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1280)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 2562      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 59138 (231.01 KB)\n",
            "Trainable params: 59138 (231.01 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "474/474 [==============================] - 6s 8ms/step - loss: 0.2496 - accuracy: 0.8873 - precision: 0.8853 - recall: 0.8869 - binary_accuracy: 0.8860 - false_positives: 3486.0000 - false_negatives: 3429.0000 - sensitivity_at_specificity: 0.9973 - val_loss: 0.1748 - val_accuracy: 0.9266 - val_precision: 0.9273 - val_recall: 0.9265 - val_binary_accuracy: 0.9269 - val_false_positives: 472.0000 - val_false_negatives: 478.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 2/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1378 - accuracy: 0.9453 - precision: 0.9441 - recall: 0.9445 - binary_accuracy: 0.9443 - false_positives: 1696.0000 - false_negatives: 1682.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.1229 - val_accuracy: 0.9511 - val_precision: 0.9504 - val_recall: 0.9520 - val_binary_accuracy: 0.9511 - val_false_positives: 323.0000 - val_false_negatives: 312.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 3/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1031 - accuracy: 0.9608 - precision: 0.9601 - recall: 0.9611 - binary_accuracy: 0.9606 - false_positives: 1210.0000 - false_negatives: 1180.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.0899 - val_accuracy: 0.9680 - val_precision: 0.9671 - val_recall: 0.9685 - val_binary_accuracy: 0.9678 - val_false_positives: 214.0000 - val_false_negatives: 205.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 4/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0893 - accuracy: 0.9660 - precision: 0.9659 - recall: 0.9659 - binary_accuracy: 0.9659 - false_positives: 1034.0000 - false_negatives: 1033.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0721 - val_accuracy: 0.9748 - val_precision: 0.9742 - val_recall: 0.9749 - val_binary_accuracy: 0.9745 - val_false_positives: 168.0000 - val_false_negatives: 163.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 5/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0785 - accuracy: 0.9713 - precision: 0.9708 - recall: 0.9716 - binary_accuracy: 0.9712 - false_positives: 885.0000 - false_negatives: 862.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0642 - val_accuracy: 0.9766 - val_precision: 0.9768 - val_recall: 0.9771 - val_binary_accuracy: 0.9769 - val_false_positives: 151.0000 - val_false_negatives: 149.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 6/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0706 - accuracy: 0.9739 - precision: 0.9738 - recall: 0.9735 - binary_accuracy: 0.9736 - false_positives: 795.0000 - false_negatives: 805.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.0613 - val_accuracy: 0.9780 - val_precision: 0.9783 - val_recall: 0.9778 - val_binary_accuracy: 0.9781 - val_false_positives: 141.0000 - val_false_negatives: 144.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 7/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0643 - accuracy: 0.9756 - precision: 0.9760 - recall: 0.9755 - binary_accuracy: 0.9757 - false_positives: 729.0000 - false_negatives: 744.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0579 - val_accuracy: 0.9791 - val_precision: 0.9797 - val_recall: 0.9791 - val_binary_accuracy: 0.9794 - val_false_positives: 132.0000 - val_false_negatives: 136.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 8/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0593 - accuracy: 0.9782 - precision: 0.9781 - recall: 0.9780 - binary_accuracy: 0.9781 - false_positives: 663.0000 - false_negatives: 666.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0572 - val_accuracy: 0.9800 - val_precision: 0.9794 - val_recall: 0.9800 - val_binary_accuracy: 0.9797 - val_false_positives: 134.0000 - val_false_negatives: 130.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 9/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0578 - accuracy: 0.9786 - precision: 0.9785 - recall: 0.9788 - binary_accuracy: 0.9787 - false_positives: 651.0000 - false_negatives: 642.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0500 - val_accuracy: 0.9837 - val_precision: 0.9837 - val_recall: 0.9835 - val_binary_accuracy: 0.9836 - val_false_positives: 106.0000 - val_false_negatives: 107.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 10/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0549 - accuracy: 0.9790 - precision: 0.9791 - recall: 0.9788 - binary_accuracy: 0.9790 - false_positives: 633.0000 - false_negatives: 642.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0495 - val_accuracy: 0.9842 - val_precision: 0.9840 - val_recall: 0.9838 - val_binary_accuracy: 0.9839 - val_false_positives: 104.0000 - val_false_negatives: 105.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 11/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0517 - accuracy: 0.9803 - precision: 0.9805 - recall: 0.9805 - binary_accuracy: 0.9805 - false_positives: 591.0000 - false_negatives: 591.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0498 - val_accuracy: 0.9823 - val_precision: 0.9820 - val_recall: 0.9826 - val_binary_accuracy: 0.9823 - val_false_positives: 117.0000 - val_false_negatives: 113.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 12/25\n",
            "474/474 [==============================] - 4s 7ms/step - loss: 0.0492 - accuracy: 0.9808 - precision: 0.9810 - recall: 0.9807 - binary_accuracy: 0.9809 - false_positives: 576.0000 - false_negatives: 585.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0616 - val_accuracy: 0.9794 - val_precision: 0.9794 - val_recall: 0.9791 - val_binary_accuracy: 0.9792 - val_false_positives: 134.0000 - val_false_negatives: 136.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 13/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0477 - accuracy: 0.9822 - precision: 0.9822 - recall: 0.9822 - binary_accuracy: 0.9822 - false_positives: 540.0000 - false_negatives: 540.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0467 - val_accuracy: 0.9860 - val_precision: 0.9858 - val_recall: 0.9860 - val_binary_accuracy: 0.9859 - val_false_positives: 92.0000 - val_false_negatives: 91.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 14/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0450 - accuracy: 0.9833 - precision: 0.9834 - recall: 0.9832 - binary_accuracy: 0.9833 - false_positives: 503.0000 - false_negatives: 510.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0449 - val_accuracy: 0.9868 - val_precision: 0.9871 - val_recall: 0.9868 - val_binary_accuracy: 0.9869 - val_false_positives: 84.0000 - val_false_negatives: 86.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 15/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0430 - accuracy: 0.9833 - precision: 0.9833 - recall: 0.9831 - binary_accuracy: 0.9832 - false_positives: 505.0000 - false_negatives: 513.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0457 - val_accuracy: 0.9854 - val_precision: 0.9852 - val_recall: 0.9851 - val_binary_accuracy: 0.9852 - val_false_positives: 96.0000 - val_false_negatives: 97.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 16/25\n",
            "474/474 [==============================] - 4s 7ms/step - loss: 0.0416 - accuracy: 0.9846 - precision: 0.9846 - recall: 0.9845 - binary_accuracy: 0.9845 - false_positives: 468.0000 - false_negatives: 471.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0469 - val_accuracy: 0.9846 - val_precision: 0.9848 - val_recall: 0.9848 - val_binary_accuracy: 0.9848 - val_false_positives: 99.0000 - val_false_negatives: 99.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 17/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0408 - accuracy: 0.9851 - precision: 0.9851 - recall: 0.9852 - binary_accuracy: 0.9851 - false_positives: 453.0000 - false_negatives: 449.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0588 - val_accuracy: 0.9794 - val_precision: 0.9789 - val_recall: 0.9797 - val_binary_accuracy: 0.9793 - val_false_positives: 137.0000 - val_false_negatives: 132.0000 - val_sensitivity_at_specificity: 0.9985\n",
            "Epoch 18/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0382 - accuracy: 0.9858 - precision: 0.9858 - recall: 0.9858 - binary_accuracy: 0.9858 - false_positives: 430.0000 - false_negatives: 430.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0469 - val_accuracy: 0.9849 - val_precision: 0.9851 - val_recall: 0.9851 - val_binary_accuracy: 0.9851 - val_false_positives: 97.0000 - val_false_negatives: 97.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 19/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0365 - accuracy: 0.9861 - precision: 0.9862 - recall: 0.9861 - binary_accuracy: 0.9862 - false_positives: 417.0000 - false_negatives: 423.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0478 - val_accuracy: 0.9838 - val_precision: 0.9838 - val_recall: 0.9838 - val_binary_accuracy: 0.9838 - val_false_positives: 105.0000 - val_false_negatives: 105.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 20/25\n",
            "474/474 [==============================] - 4s 7ms/step - loss: 0.0374 - accuracy: 0.9857 - precision: 0.9857 - recall: 0.9857 - binary_accuracy: 0.9857 - false_positives: 435.0000 - false_negatives: 433.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0420 - val_accuracy: 0.9871 - val_precision: 0.9871 - val_recall: 0.9871 - val_binary_accuracy: 0.9871 - val_false_positives: 84.0000 - val_false_negatives: 84.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 21/25\n",
            "474/474 [==============================] - 4s 7ms/step - loss: 0.0360 - accuracy: 0.9868 - precision: 0.9866 - recall: 0.9868 - binary_accuracy: 0.9867 - false_positives: 407.0000 - false_negatives: 400.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0426 - val_accuracy: 0.9877 - val_precision: 0.9875 - val_recall: 0.9877 - val_binary_accuracy: 0.9876 - val_false_positives: 81.0000 - val_false_negatives: 80.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 22/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0337 - accuracy: 0.9872 - precision: 0.9873 - recall: 0.9874 - binary_accuracy: 0.9874 - false_positives: 384.0000 - false_negatives: 383.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0482 - val_accuracy: 0.9860 - val_precision: 0.9860 - val_recall: 0.9860 - val_binary_accuracy: 0.9860 - val_false_positives: 91.0000 - val_false_negatives: 91.0000 - val_sensitivity_at_specificity: 0.9988\n",
            "Epoch 23/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0339 - accuracy: 0.9869 - precision: 0.9868 - recall: 0.9870 - binary_accuracy: 0.9869 - false_positives: 399.0000 - false_negatives: 395.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0508 - val_accuracy: 0.9831 - val_precision: 0.9831 - val_recall: 0.9826 - val_binary_accuracy: 0.9828 - val_false_positives: 110.0000 - val_false_negatives: 113.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 24/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0327 - accuracy: 0.9877 - precision: 0.9878 - recall: 0.9876 - binary_accuracy: 0.9877 - false_positives: 370.0000 - false_negatives: 375.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0460 - val_accuracy: 0.9857 - val_precision: 0.9857 - val_recall: 0.9860 - val_binary_accuracy: 0.9858 - val_false_positives: 93.0000 - val_false_negatives: 91.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 25/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0312 - accuracy: 0.9887 - precision: 0.9888 - recall: 0.9887 - binary_accuracy: 0.9887 - false_positives: 341.0000 - false_negatives: 342.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0484 - val_accuracy: 0.9855 - val_precision: 0.9855 - val_recall: 0.9855 - val_binary_accuracy: 0.9855 - val_false_positives: 94.0000 - val_false_negatives: 94.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Test loss: 0.03823322802782059\n",
            "Test accuracy: 0.9876922965049744\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 133, 2, 32)        928       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 66, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 39, 2, 64)         57408     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 19, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1216)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1216)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 2434      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 61090 (238.63 KB)\n",
            "Trainable params: 61090 (238.63 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "474/474 [==============================] - 6s 9ms/step - loss: 0.2429 - accuracy: 0.8912 - precision: 0.8908 - recall: 0.8883 - binary_accuracy: 0.8897 - false_positives: 3303.0000 - false_negatives: 3387.0000 - sensitivity_at_specificity: 0.9977 - val_loss: 0.1586 - val_accuracy: 0.9355 - val_precision: 0.9354 - val_recall: 0.9355 - val_binary_accuracy: 0.9355 - val_false_positives: 420.0000 - val_false_negatives: 419.0000 - val_sensitivity_at_specificity: 1.0000\n",
            "Epoch 2/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1333 - accuracy: 0.9470 - precision: 0.9467 - recall: 0.9471 - binary_accuracy: 0.9469 - false_positives: 1617.0000 - false_negatives: 1604.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.1064 - val_accuracy: 0.9586 - val_precision: 0.9575 - val_recall: 0.9595 - val_binary_accuracy: 0.9585 - val_false_positives: 277.0000 - val_false_negatives: 263.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 3/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1053 - accuracy: 0.9598 - precision: 0.9593 - recall: 0.9597 - binary_accuracy: 0.9595 - false_positives: 1236.0000 - false_negatives: 1221.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0759 - val_accuracy: 0.9746 - val_precision: 0.9746 - val_recall: 0.9738 - val_binary_accuracy: 0.9742 - val_false_positives: 165.0000 - val_false_negatives: 170.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 4/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0893 - accuracy: 0.9667 - precision: 0.9664 - recall: 0.9666 - binary_accuracy: 0.9665 - false_positives: 1018.0000 - false_negatives: 1013.0000 - sensitivity_at_specificity: 0.9993 - val_loss: 0.0685 - val_accuracy: 0.9757 - val_precision: 0.9755 - val_recall: 0.9758 - val_binary_accuracy: 0.9757 - val_false_positives: 159.0000 - val_false_negatives: 157.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 5/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0795 - accuracy: 0.9709 - precision: 0.9703 - recall: 0.9707 - binary_accuracy: 0.9705 - false_positives: 901.0000 - false_negatives: 889.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0644 - val_accuracy: 0.9778 - val_precision: 0.9775 - val_recall: 0.9777 - val_binary_accuracy: 0.9776 - val_false_positives: 146.0000 - val_false_negatives: 145.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 6/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0726 - accuracy: 0.9736 - precision: 0.9734 - recall: 0.9735 - binary_accuracy: 0.9734 - false_positives: 806.0000 - false_negatives: 805.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0582 - val_accuracy: 0.9802 - val_precision: 0.9801 - val_recall: 0.9797 - val_binary_accuracy: 0.9799 - val_false_positives: 129.0000 - val_false_negatives: 132.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 7/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0675 - accuracy: 0.9741 - precision: 0.9746 - recall: 0.9739 - binary_accuracy: 0.9743 - false_positives: 770.0000 - false_negatives: 791.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0643 - val_accuracy: 0.9775 - val_precision: 0.9774 - val_recall: 0.9777 - val_binary_accuracy: 0.9775 - val_false_positives: 147.0000 - val_false_negatives: 145.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 8/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0649 - accuracy: 0.9755 - precision: 0.9755 - recall: 0.9754 - binary_accuracy: 0.9754 - false_positives: 744.0000 - false_negatives: 747.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.0537 - val_accuracy: 0.9818 - val_precision: 0.9815 - val_recall: 0.9820 - val_binary_accuracy: 0.9818 - val_false_positives: 120.0000 - val_false_negatives: 117.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 9/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0574 - accuracy: 0.9790 - precision: 0.9790 - recall: 0.9790 - binary_accuracy: 0.9790 - false_positives: 637.0000 - false_negatives: 638.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0552 - val_accuracy: 0.9823 - val_precision: 0.9823 - val_recall: 0.9820 - val_binary_accuracy: 0.9822 - val_false_positives: 115.0000 - val_false_negatives: 117.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 10/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0569 - accuracy: 0.9781 - precision: 0.9781 - recall: 0.9782 - binary_accuracy: 0.9782 - false_positives: 663.0000 - false_negatives: 660.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0524 - val_accuracy: 0.9817 - val_precision: 0.9817 - val_recall: 0.9817 - val_binary_accuracy: 0.9817 - val_false_positives: 119.0000 - val_false_negatives: 119.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 11/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0565 - accuracy: 0.9791 - precision: 0.9790 - recall: 0.9790 - binary_accuracy: 0.9790 - false_positives: 637.0000 - false_negatives: 637.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0519 - val_accuracy: 0.9840 - val_precision: 0.9837 - val_recall: 0.9837 - val_binary_accuracy: 0.9837 - val_false_positives: 106.0000 - val_false_negatives: 106.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 12/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0505 - accuracy: 0.9809 - precision: 0.9807 - recall: 0.9810 - binary_accuracy: 0.9808 - false_positives: 587.0000 - false_negatives: 577.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0487 - val_accuracy: 0.9826 - val_precision: 0.9825 - val_recall: 0.9828 - val_binary_accuracy: 0.9826 - val_false_positives: 114.0000 - val_false_negatives: 112.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 13/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0500 - accuracy: 0.9819 - precision: 0.9820 - recall: 0.9818 - binary_accuracy: 0.9819 - false_positives: 546.0000 - false_negatives: 553.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0482 - val_accuracy: 0.9834 - val_precision: 0.9837 - val_recall: 0.9832 - val_binary_accuracy: 0.9835 - val_false_positives: 106.0000 - val_false_negatives: 109.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 14/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0457 - accuracy: 0.9826 - precision: 0.9824 - recall: 0.9825 - binary_accuracy: 0.9824 - false_positives: 534.0000 - false_negatives: 532.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0572 - val_accuracy: 0.9792 - val_precision: 0.9791 - val_recall: 0.9791 - val_binary_accuracy: 0.9791 - val_false_positives: 136.0000 - val_false_negatives: 136.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 15/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0441 - accuracy: 0.9835 - precision: 0.9836 - recall: 0.9833 - binary_accuracy: 0.9835 - false_positives: 497.0000 - false_negatives: 505.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0603 - val_accuracy: 0.9805 - val_precision: 0.9800 - val_recall: 0.9803 - val_binary_accuracy: 0.9802 - val_false_positives: 130.0000 - val_false_negatives: 128.0000 - val_sensitivity_at_specificity: 0.9989\n",
            "Epoch 16/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0435 - accuracy: 0.9837 - precision: 0.9838 - recall: 0.9838 - binary_accuracy: 0.9838 - false_positives: 492.0000 - false_negatives: 492.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0492 - val_accuracy: 0.9832 - val_precision: 0.9832 - val_recall: 0.9834 - val_binary_accuracy: 0.9833 - val_false_positives: 109.0000 - val_false_negatives: 108.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 17/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0430 - accuracy: 0.9838 - precision: 0.9838 - recall: 0.9837 - binary_accuracy: 0.9838 - false_positives: 492.0000 - false_negatives: 493.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0438 - val_accuracy: 0.9860 - val_precision: 0.9858 - val_recall: 0.9860 - val_binary_accuracy: 0.9859 - val_false_positives: 92.0000 - val_false_negatives: 91.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 18/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0402 - accuracy: 0.9846 - precision: 0.9846 - recall: 0.9847 - binary_accuracy: 0.9846 - false_positives: 468.0000 - false_negatives: 464.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0507 - val_accuracy: 0.9831 - val_precision: 0.9829 - val_recall: 0.9831 - val_binary_accuracy: 0.9830 - val_false_positives: 111.0000 - val_false_negatives: 110.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 19/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0393 - accuracy: 0.9855 - precision: 0.9856 - recall: 0.9856 - binary_accuracy: 0.9856 - false_positives: 436.0000 - false_negatives: 436.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0485 - val_accuracy: 0.9846 - val_precision: 0.9846 - val_recall: 0.9846 - val_binary_accuracy: 0.9846 - val_false_positives: 100.0000 - val_false_negatives: 100.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 20/25\n",
            "474/474 [==============================] - 4s 7ms/step - loss: 0.0410 - accuracy: 0.9850 - precision: 0.9850 - recall: 0.9850 - binary_accuracy: 0.9850 - false_positives: 456.0000 - false_negatives: 455.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0499 - val_accuracy: 0.9823 - val_precision: 0.9826 - val_recall: 0.9823 - val_binary_accuracy: 0.9825 - val_false_positives: 113.0000 - val_false_negatives: 115.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 21/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0355 - accuracy: 0.9862 - precision: 0.9861 - recall: 0.9862 - binary_accuracy: 0.9862 - false_positives: 422.0000 - false_negatives: 418.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0436 - val_accuracy: 0.9852 - val_precision: 0.9852 - val_recall: 0.9852 - val_binary_accuracy: 0.9852 - val_false_positives: 96.0000 - val_false_negatives: 96.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 22/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0357 - accuracy: 0.9861 - precision: 0.9860 - recall: 0.9862 - binary_accuracy: 0.9861 - false_positives: 424.0000 - false_negatives: 418.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0567 - val_accuracy: 0.9826 - val_precision: 0.9826 - val_recall: 0.9826 - val_binary_accuracy: 0.9826 - val_false_positives: 113.0000 - val_false_negatives: 113.0000 - val_sensitivity_at_specificity: 0.9988\n",
            "Epoch 23/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0344 - accuracy: 0.9869 - precision: 0.9869 - recall: 0.9869 - binary_accuracy: 0.9869 - false_positives: 397.0000 - false_negatives: 396.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0606 - val_accuracy: 0.9811 - val_precision: 0.9809 - val_recall: 0.9811 - val_binary_accuracy: 0.9810 - val_false_positives: 124.0000 - val_false_negatives: 123.0000 - val_sensitivity_at_specificity: 0.9978\n",
            "Epoch 24/25\n",
            "474/474 [==============================] - 4s 7ms/step - loss: 0.0330 - accuracy: 0.9877 - precision: 0.9877 - recall: 0.9878 - binary_accuracy: 0.9878 - false_positives: 372.0000 - false_negatives: 371.0000 - sensitivity_at_specificity: 0.9999 - val_loss: 0.0464 - val_accuracy: 0.9858 - val_precision: 0.9855 - val_recall: 0.9857 - val_binary_accuracy: 0.9856 - val_false_positives: 94.0000 - val_false_negatives: 93.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 25/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0336 - accuracy: 0.9877 - precision: 0.9877 - recall: 0.9877 - binary_accuracy: 0.9877 - false_positives: 374.0000 - false_negatives: 372.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0441 - val_accuracy: 0.9872 - val_precision: 0.9872 - val_recall: 0.9874 - val_binary_accuracy: 0.9873 - val_false_positives: 83.0000 - val_false_negatives: 82.0000 - val_sensitivity_at_specificity: 0.9989\n",
            "Test loss: 0.0359978973865509\n",
            "Test accuracy: 0.9866153597831726\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 132, 2, 32)        960       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 66, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 38, 2, 64)         59456     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 19, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1216)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1216)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 2434      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 63170 (246.76 KB)\n",
            "Trainable params: 63170 (246.76 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "474/474 [==============================] - 6s 9ms/step - loss: 0.2406 - accuracy: 0.8916 - precision: 0.8903 - recall: 0.8886 - binary_accuracy: 0.8895 - false_positives: 3321.0000 - false_negatives: 3379.0000 - sensitivity_at_specificity: 0.9976 - val_loss: 0.1566 - val_accuracy: 0.9375 - val_precision: 0.9385 - val_recall: 0.9361 - val_binary_accuracy: 0.9374 - val_false_positives: 399.0000 - val_false_negatives: 415.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 2/25\n",
            "474/474 [==============================] - 4s 7ms/step - loss: 0.1370 - accuracy: 0.9458 - precision: 0.9446 - recall: 0.9451 - binary_accuracy: 0.9449 - false_positives: 1680.0000 - false_negatives: 1664.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.1070 - val_accuracy: 0.9592 - val_precision: 0.9589 - val_recall: 0.9592 - val_binary_accuracy: 0.9591 - val_false_positives: 267.0000 - val_false_negatives: 265.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 3/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1077 - accuracy: 0.9586 - precision: 0.9584 - recall: 0.9580 - binary_accuracy: 0.9582 - false_positives: 1260.0000 - false_negatives: 1273.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.0861 - val_accuracy: 0.9675 - val_precision: 0.9686 - val_recall: 0.9671 - val_binary_accuracy: 0.9678 - val_false_positives: 204.0000 - val_false_negatives: 214.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 4/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0912 - accuracy: 0.9654 - precision: 0.9658 - recall: 0.9648 - binary_accuracy: 0.9653 - false_positives: 1035.0000 - false_negatives: 1067.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0781 - val_accuracy: 0.9717 - val_precision: 0.9727 - val_recall: 0.9708 - val_binary_accuracy: 0.9718 - val_false_positives: 177.0000 - val_false_negatives: 190.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 5/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0820 - accuracy: 0.9691 - precision: 0.9689 - recall: 0.9689 - binary_accuracy: 0.9689 - false_positives: 942.0000 - false_negatives: 944.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0630 - val_accuracy: 0.9774 - val_precision: 0.9771 - val_recall: 0.9768 - val_binary_accuracy: 0.9769 - val_false_positives: 149.0000 - val_false_negatives: 151.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 6/25\n",
            "474/474 [==============================] - 4s 7ms/step - loss: 0.0721 - accuracy: 0.9732 - precision: 0.9735 - recall: 0.9734 - binary_accuracy: 0.9735 - false_positives: 803.0000 - false_negatives: 807.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0575 - val_accuracy: 0.9798 - val_precision: 0.9800 - val_recall: 0.9798 - val_binary_accuracy: 0.9799 - val_false_positives: 130.0000 - val_false_negatives: 131.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 7/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0652 - accuracy: 0.9755 - precision: 0.9756 - recall: 0.9750 - binary_accuracy: 0.9753 - false_positives: 741.0000 - false_negatives: 759.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0604 - val_accuracy: 0.9762 - val_precision: 0.9767 - val_recall: 0.9754 - val_binary_accuracy: 0.9761 - val_false_positives: 151.0000 - val_false_negatives: 160.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 8/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0618 - accuracy: 0.9769 - precision: 0.9768 - recall: 0.9769 - binary_accuracy: 0.9768 - false_positives: 705.0000 - false_negatives: 701.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0551 - val_accuracy: 0.9788 - val_precision: 0.9788 - val_recall: 0.9788 - val_binary_accuracy: 0.9788 - val_false_positives: 138.0000 - val_false_negatives: 138.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 9/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0599 - accuracy: 0.9770 - precision: 0.9767 - recall: 0.9768 - binary_accuracy: 0.9768 - false_positives: 707.0000 - false_negatives: 703.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0519 - val_accuracy: 0.9818 - val_precision: 0.9814 - val_recall: 0.9815 - val_binary_accuracy: 0.9815 - val_false_positives: 121.0000 - val_false_negatives: 120.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 10/25\n",
            "474/474 [==============================] - 4s 7ms/step - loss: 0.0547 - accuracy: 0.9792 - precision: 0.9795 - recall: 0.9792 - binary_accuracy: 0.9794 - false_positives: 620.0000 - false_negatives: 632.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0500 - val_accuracy: 0.9834 - val_precision: 0.9832 - val_recall: 0.9835 - val_binary_accuracy: 0.9834 - val_false_positives: 109.0000 - val_false_negatives: 107.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 11/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0534 - accuracy: 0.9799 - precision: 0.9797 - recall: 0.9799 - binary_accuracy: 0.9798 - false_positives: 616.0000 - false_negatives: 610.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0600 - val_accuracy: 0.9768 - val_precision: 0.9769 - val_recall: 0.9766 - val_binary_accuracy: 0.9768 - val_false_positives: 150.0000 - val_false_negatives: 152.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 12/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0540 - accuracy: 0.9804 - precision: 0.9803 - recall: 0.9803 - binary_accuracy: 0.9803 - false_positives: 598.0000 - false_negatives: 596.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0510 - val_accuracy: 0.9826 - val_precision: 0.9826 - val_recall: 0.9825 - val_binary_accuracy: 0.9825 - val_false_positives: 113.0000 - val_false_negatives: 114.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 13/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0493 - accuracy: 0.9815 - precision: 0.9813 - recall: 0.9813 - binary_accuracy: 0.9813 - false_positives: 566.0000 - false_negatives: 566.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0455 - val_accuracy: 0.9845 - val_precision: 0.9846 - val_recall: 0.9845 - val_binary_accuracy: 0.9845 - val_false_positives: 100.0000 - val_false_negatives: 101.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 14/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0467 - accuracy: 0.9830 - precision: 0.9830 - recall: 0.9831 - binary_accuracy: 0.9830 - false_positives: 517.0000 - false_negatives: 512.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0508 - val_accuracy: 0.9817 - val_precision: 0.9815 - val_recall: 0.9814 - val_binary_accuracy: 0.9815 - val_false_positives: 120.0000 - val_false_negatives: 121.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 15/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0456 - accuracy: 0.9822 - precision: 0.9823 - recall: 0.9823 - binary_accuracy: 0.9823 - false_positives: 538.0000 - false_negatives: 538.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0441 - val_accuracy: 0.9849 - val_precision: 0.9849 - val_recall: 0.9851 - val_binary_accuracy: 0.9850 - val_false_positives: 98.0000 - val_false_negatives: 97.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 16/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0419 - accuracy: 0.9838 - precision: 0.9838 - recall: 0.9837 - binary_accuracy: 0.9838 - false_positives: 490.0000 - false_negatives: 495.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0628 - val_accuracy: 0.9782 - val_precision: 0.9782 - val_recall: 0.9782 - val_binary_accuracy: 0.9782 - val_false_positives: 142.0000 - val_false_negatives: 142.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 17/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0409 - accuracy: 0.9844 - precision: 0.9844 - recall: 0.9844 - binary_accuracy: 0.9844 - false_positives: 474.0000 - false_negatives: 472.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0370 - val_accuracy: 0.9862 - val_precision: 0.9863 - val_recall: 0.9863 - val_binary_accuracy: 0.9863 - val_false_positives: 89.0000 - val_false_negatives: 89.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 18/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0399 - accuracy: 0.9854 - precision: 0.9854 - recall: 0.9853 - binary_accuracy: 0.9853 - false_positives: 443.0000 - false_negatives: 446.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0487 - val_accuracy: 0.9837 - val_precision: 0.9835 - val_recall: 0.9837 - val_binary_accuracy: 0.9836 - val_false_positives: 107.0000 - val_false_negatives: 106.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 19/25\n",
            "474/474 [==============================] - 4s 7ms/step - loss: 0.0376 - accuracy: 0.9860 - precision: 0.9860 - recall: 0.9860 - binary_accuracy: 0.9860 - false_positives: 425.0000 - false_negatives: 425.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0432 - val_accuracy: 0.9855 - val_precision: 0.9855 - val_recall: 0.9854 - val_binary_accuracy: 0.9855 - val_false_positives: 94.0000 - val_false_negatives: 95.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 20/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0374 - accuracy: 0.9856 - precision: 0.9856 - recall: 0.9856 - binary_accuracy: 0.9856 - false_positives: 438.0000 - false_negatives: 436.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0413 - val_accuracy: 0.9851 - val_precision: 0.9851 - val_recall: 0.9854 - val_binary_accuracy: 0.9852 - val_false_positives: 97.0000 - val_false_negatives: 95.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 21/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0372 - accuracy: 0.9852 - precision: 0.9852 - recall: 0.9851 - binary_accuracy: 0.9852 - false_positives: 448.0000 - false_negatives: 452.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0416 - val_accuracy: 0.9871 - val_precision: 0.9871 - val_recall: 0.9872 - val_binary_accuracy: 0.9872 - val_false_positives: 84.0000 - val_false_negatives: 83.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 22/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0364 - accuracy: 0.9862 - precision: 0.9863 - recall: 0.9863 - binary_accuracy: 0.9863 - false_positives: 417.0000 - false_negatives: 414.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0374 - val_accuracy: 0.9874 - val_precision: 0.9875 - val_recall: 0.9874 - val_binary_accuracy: 0.9875 - val_false_positives: 81.0000 - val_false_negatives: 82.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 23/25\n",
            "474/474 [==============================] - 4s 7ms/step - loss: 0.0348 - accuracy: 0.9869 - precision: 0.9868 - recall: 0.9869 - binary_accuracy: 0.9869 - false_positives: 400.0000 - false_negatives: 397.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0509 - val_accuracy: 0.9826 - val_precision: 0.9826 - val_recall: 0.9822 - val_binary_accuracy: 0.9824 - val_false_positives: 113.0000 - val_false_negatives: 116.0000 - val_sensitivity_at_specificity: 0.9989\n",
            "Epoch 24/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0333 - accuracy: 0.9870 - precision: 0.9870 - recall: 0.9870 - binary_accuracy: 0.9870 - false_positives: 394.0000 - false_negatives: 394.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0435 - val_accuracy: 0.9863 - val_precision: 0.9863 - val_recall: 0.9865 - val_binary_accuracy: 0.9864 - val_false_positives: 89.0000 - val_false_negatives: 88.0000 - val_sensitivity_at_specificity: 0.9989\n",
            "Epoch 25/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0355 - accuracy: 0.9866 - precision: 0.9865 - recall: 0.9866 - binary_accuracy: 0.9866 - false_positives: 409.0000 - false_negatives: 406.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0426 - val_accuracy: 0.9855 - val_precision: 0.9855 - val_recall: 0.9855 - val_binary_accuracy: 0.9855 - val_false_positives: 94.0000 - val_false_negatives: 94.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Test loss: 0.037728797644376755\n",
            "Test accuracy: 0.986307680606842\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 131, 2, 32)        992       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 65, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 36, 2, 64)         61504     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 18, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1152)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1152)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 2306      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 65122 (254.38 KB)\n",
            "Trainable params: 65122 (254.38 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "474/474 [==============================] - 6s 9ms/step - loss: 0.2366 - accuracy: 0.8926 - precision: 0.8913 - recall: 0.8910 - binary_accuracy: 0.8912 - false_positives: 3294.0000 - false_negatives: 3305.0000 - sensitivity_at_specificity: 0.9976 - val_loss: 0.1502 - val_accuracy: 0.9394 - val_precision: 0.9392 - val_recall: 0.9388 - val_binary_accuracy: 0.9390 - val_false_positives: 395.0000 - val_false_negatives: 398.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 2/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1349 - accuracy: 0.9463 - precision: 0.9455 - recall: 0.9457 - binary_accuracy: 0.9456 - false_positives: 1652.0000 - false_negatives: 1647.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.1001 - val_accuracy: 0.9648 - val_precision: 0.9653 - val_recall: 0.9645 - val_binary_accuracy: 0.9649 - val_false_positives: 225.0000 - val_false_negatives: 231.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 3/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1032 - accuracy: 0.9597 - precision: 0.9599 - recall: 0.9593 - binary_accuracy: 0.9596 - false_positives: 1215.0000 - false_negatives: 1234.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0834 - val_accuracy: 0.9700 - val_precision: 0.9698 - val_recall: 0.9697 - val_binary_accuracy: 0.9698 - val_false_positives: 196.0000 - val_false_negatives: 197.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 4/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0875 - accuracy: 0.9671 - precision: 0.9667 - recall: 0.9671 - binary_accuracy: 0.9669 - false_positives: 1009.0000 - false_negatives: 997.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0677 - val_accuracy: 0.9772 - val_precision: 0.9777 - val_recall: 0.9777 - val_binary_accuracy: 0.9777 - val_false_positives: 145.0000 - val_false_negatives: 145.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 5/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0770 - accuracy: 0.9710 - precision: 0.9705 - recall: 0.9715 - binary_accuracy: 0.9710 - false_positives: 896.0000 - false_negatives: 864.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.0694 - val_accuracy: 0.9729 - val_precision: 0.9738 - val_recall: 0.9726 - val_binary_accuracy: 0.9732 - val_false_positives: 170.0000 - val_false_negatives: 178.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 6/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0713 - accuracy: 0.9732 - precision: 0.9735 - recall: 0.9730 - binary_accuracy: 0.9733 - false_positives: 803.0000 - false_negatives: 819.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0554 - val_accuracy: 0.9808 - val_precision: 0.9805 - val_recall: 0.9811 - val_binary_accuracy: 0.9808 - val_false_positives: 127.0000 - val_false_negatives: 123.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 7/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0654 - accuracy: 0.9751 - precision: 0.9750 - recall: 0.9752 - binary_accuracy: 0.9751 - false_positives: 758.0000 - false_negatives: 751.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0554 - val_accuracy: 0.9812 - val_precision: 0.9812 - val_recall: 0.9808 - val_binary_accuracy: 0.9810 - val_false_positives: 122.0000 - val_false_negatives: 125.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 8/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0615 - accuracy: 0.9767 - precision: 0.9768 - recall: 0.9770 - binary_accuracy: 0.9769 - false_positives: 705.0000 - false_negatives: 699.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0539 - val_accuracy: 0.9823 - val_precision: 0.9822 - val_recall: 0.9826 - val_binary_accuracy: 0.9824 - val_false_positives: 116.0000 - val_false_negatives: 113.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 9/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0594 - accuracy: 0.9774 - precision: 0.9772 - recall: 0.9775 - binary_accuracy: 0.9774 - false_positives: 692.0000 - false_negatives: 681.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0499 - val_accuracy: 0.9825 - val_precision: 0.9825 - val_recall: 0.9825 - val_binary_accuracy: 0.9825 - val_false_positives: 114.0000 - val_false_negatives: 114.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 10/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0537 - accuracy: 0.9791 - precision: 0.9790 - recall: 0.9792 - binary_accuracy: 0.9791 - false_positives: 638.0000 - false_negatives: 630.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0542 - val_accuracy: 0.9811 - val_precision: 0.9811 - val_recall: 0.9812 - val_binary_accuracy: 0.9812 - val_false_positives: 123.0000 - val_false_negatives: 122.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 11/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0529 - accuracy: 0.9804 - precision: 0.9804 - recall: 0.9804 - binary_accuracy: 0.9804 - false_positives: 595.0000 - false_negatives: 593.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.0474 - val_accuracy: 0.9837 - val_precision: 0.9837 - val_recall: 0.9835 - val_binary_accuracy: 0.9836 - val_false_positives: 106.0000 - val_false_negatives: 107.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 12/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0522 - accuracy: 0.9802 - precision: 0.9802 - recall: 0.9799 - binary_accuracy: 0.9801 - false_positives: 601.0000 - false_negatives: 609.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0669 - val_accuracy: 0.9732 - val_precision: 0.9735 - val_recall: 0.9732 - val_binary_accuracy: 0.9734 - val_false_positives: 172.0000 - val_false_negatives: 174.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 13/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0504 - accuracy: 0.9813 - precision: 0.9813 - recall: 0.9815 - binary_accuracy: 0.9814 - false_positives: 568.0000 - false_negatives: 562.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0468 - val_accuracy: 0.9840 - val_precision: 0.9842 - val_recall: 0.9842 - val_binary_accuracy: 0.9842 - val_false_positives: 103.0000 - val_false_negatives: 103.0000 - val_sensitivity_at_specificity: 0.9989\n",
            "Epoch 14/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0478 - accuracy: 0.9818 - precision: 0.9817 - recall: 0.9818 - binary_accuracy: 0.9818 - false_positives: 554.0000 - false_negatives: 552.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0482 - val_accuracy: 0.9848 - val_precision: 0.9846 - val_recall: 0.9846 - val_binary_accuracy: 0.9846 - val_false_positives: 100.0000 - val_false_negatives: 100.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 15/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0450 - accuracy: 0.9833 - precision: 0.9834 - recall: 0.9833 - binary_accuracy: 0.9834 - false_positives: 502.0000 - false_negatives: 507.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0494 - val_accuracy: 0.9838 - val_precision: 0.9837 - val_recall: 0.9845 - val_binary_accuracy: 0.9841 - val_false_positives: 106.0000 - val_false_negatives: 101.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 16/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0436 - accuracy: 0.9839 - precision: 0.9840 - recall: 0.9839 - binary_accuracy: 0.9840 - false_positives: 485.0000 - false_negatives: 488.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0482 - val_accuracy: 0.9823 - val_precision: 0.9820 - val_recall: 0.9823 - val_binary_accuracy: 0.9822 - val_false_positives: 117.0000 - val_false_negatives: 115.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 17/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0414 - accuracy: 0.9846 - precision: 0.9848 - recall: 0.9846 - binary_accuracy: 0.9847 - false_positives: 462.0000 - false_negatives: 468.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0422 - val_accuracy: 0.9852 - val_precision: 0.9851 - val_recall: 0.9851 - val_binary_accuracy: 0.9851 - val_false_positives: 97.0000 - val_false_negatives: 97.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 18/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0433 - accuracy: 0.9837 - precision: 0.9837 - recall: 0.9835 - binary_accuracy: 0.9836 - false_positives: 495.0000 - false_negatives: 499.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0383 - val_accuracy: 0.9868 - val_precision: 0.9868 - val_recall: 0.9868 - val_binary_accuracy: 0.9868 - val_false_positives: 86.0000 - val_false_negatives: 86.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 19/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0385 - accuracy: 0.9853 - precision: 0.9854 - recall: 0.9852 - binary_accuracy: 0.9853 - false_positives: 443.0000 - false_negatives: 450.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0444 - val_accuracy: 0.9838 - val_precision: 0.9837 - val_recall: 0.9837 - val_binary_accuracy: 0.9837 - val_false_positives: 106.0000 - val_false_negatives: 106.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 20/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0377 - accuracy: 0.9857 - precision: 0.9858 - recall: 0.9856 - binary_accuracy: 0.9857 - false_positives: 432.0000 - false_negatives: 436.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0410 - val_accuracy: 0.9860 - val_precision: 0.9860 - val_recall: 0.9858 - val_binary_accuracy: 0.9859 - val_false_positives: 91.0000 - val_false_negatives: 92.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 21/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0388 - accuracy: 0.9854 - precision: 0.9853 - recall: 0.9852 - binary_accuracy: 0.9853 - false_positives: 446.0000 - false_negatives: 448.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0435 - val_accuracy: 0.9854 - val_precision: 0.9855 - val_recall: 0.9851 - val_binary_accuracy: 0.9853 - val_false_positives: 94.0000 - val_false_negatives: 97.0000 - val_sensitivity_at_specificity: 0.9986\n",
            "Epoch 22/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0350 - accuracy: 0.9866 - precision: 0.9866 - recall: 0.9865 - binary_accuracy: 0.9866 - false_positives: 406.0000 - false_negatives: 408.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0432 - val_accuracy: 0.9848 - val_precision: 0.9848 - val_recall: 0.9845 - val_binary_accuracy: 0.9846 - val_false_positives: 99.0000 - val_false_negatives: 101.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 23/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0353 - accuracy: 0.9869 - precision: 0.9869 - recall: 0.9868 - binary_accuracy: 0.9869 - false_positives: 396.0000 - false_negatives: 401.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0451 - val_accuracy: 0.9837 - val_precision: 0.9837 - val_recall: 0.9838 - val_binary_accuracy: 0.9838 - val_false_positives: 106.0000 - val_false_negatives: 105.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 24/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0341 - accuracy: 0.9877 - precision: 0.9878 - recall: 0.9877 - binary_accuracy: 0.9878 - false_positives: 371.0000 - false_negatives: 372.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0527 - val_accuracy: 0.9826 - val_precision: 0.9829 - val_recall: 0.9826 - val_binary_accuracy: 0.9828 - val_false_positives: 111.0000 - val_false_negatives: 113.0000 - val_sensitivity_at_specificity: 0.9986\n",
            "Epoch 25/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0316 - accuracy: 0.9884 - precision: 0.9883 - recall: 0.9883 - binary_accuracy: 0.9883 - false_positives: 354.0000 - false_negatives: 355.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0514 - val_accuracy: 0.9834 - val_precision: 0.9832 - val_recall: 0.9837 - val_binary_accuracy: 0.9835 - val_false_positives: 109.0000 - val_false_negatives: 106.0000 - val_sensitivity_at_specificity: 0.9985\n",
            "Test loss: 0.04506146162748337\n",
            "Test accuracy: 0.9843077063560486\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 130, 2, 32)        1024      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 65, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 35, 2, 64)         63552     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 17, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1088)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1088)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 2178      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 67074 (262.01 KB)\n",
            "Trainable params: 67074 (262.01 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "474/474 [==============================] - 6s 9ms/step - loss: 0.2365 - accuracy: 0.8926 - precision: 0.8920 - recall: 0.8914 - binary_accuracy: 0.8917 - false_positives: 3274.0000 - false_negatives: 3294.0000 - sensitivity_at_specificity: 0.9978 - val_loss: 0.1500 - val_accuracy: 0.9429 - val_precision: 0.9456 - val_recall: 0.9391 - val_binary_accuracy: 0.9425 - val_false_positives: 351.0000 - val_false_negatives: 396.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 2/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1337 - accuracy: 0.9476 - precision: 0.9466 - recall: 0.9463 - binary_accuracy: 0.9465 - false_positives: 1619.0000 - false_negatives: 1628.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0970 - val_accuracy: 0.9654 - val_precision: 0.9659 - val_recall: 0.9643 - val_binary_accuracy: 0.9651 - val_false_positives: 221.0000 - val_false_negatives: 232.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 3/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.1010 - accuracy: 0.9619 - precision: 0.9616 - recall: 0.9621 - binary_accuracy: 0.9618 - false_positives: 1166.0000 - false_negatives: 1150.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0831 - val_accuracy: 0.9677 - val_precision: 0.9673 - val_recall: 0.9683 - val_binary_accuracy: 0.9678 - val_false_positives: 213.0000 - val_false_negatives: 206.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 4/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0855 - accuracy: 0.9674 - precision: 0.9671 - recall: 0.9673 - binary_accuracy: 0.9672 - false_positives: 999.0000 - false_negatives: 993.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0600 - val_accuracy: 0.9800 - val_precision: 0.9794 - val_recall: 0.9798 - val_binary_accuracy: 0.9796 - val_false_positives: 134.0000 - val_false_negatives: 131.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 5/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0776 - accuracy: 0.9707 - precision: 0.9703 - recall: 0.9709 - binary_accuracy: 0.9706 - false_positives: 901.0000 - false_negatives: 884.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0620 - val_accuracy: 0.9780 - val_precision: 0.9784 - val_recall: 0.9774 - val_binary_accuracy: 0.9779 - val_false_positives: 140.0000 - val_false_negatives: 147.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 6/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0678 - accuracy: 0.9750 - precision: 0.9749 - recall: 0.9746 - binary_accuracy: 0.9748 - false_positives: 760.0000 - false_negatives: 769.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0526 - val_accuracy: 0.9818 - val_precision: 0.9815 - val_recall: 0.9822 - val_binary_accuracy: 0.9818 - val_false_positives: 120.0000 - val_false_negatives: 116.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 7/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0639 - accuracy: 0.9754 - precision: 0.9753 - recall: 0.9753 - binary_accuracy: 0.9753 - false_positives: 748.0000 - false_negatives: 750.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0549 - val_accuracy: 0.9809 - val_precision: 0.9811 - val_recall: 0.9806 - val_binary_accuracy: 0.9808 - val_false_positives: 123.0000 - val_false_negatives: 126.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 8/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0614 - accuracy: 0.9772 - precision: 0.9770 - recall: 0.9773 - binary_accuracy: 0.9771 - false_positives: 699.0000 - false_negatives: 689.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0485 - val_accuracy: 0.9825 - val_precision: 0.9822 - val_recall: 0.9825 - val_binary_accuracy: 0.9823 - val_false_positives: 116.0000 - val_false_negatives: 114.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 9/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0567 - accuracy: 0.9797 - precision: 0.9794 - recall: 0.9797 - binary_accuracy: 0.9795 - false_positives: 626.0000 - false_negatives: 616.0000 - sensitivity_at_specificity: 0.9994 - val_loss: 0.0489 - val_accuracy: 0.9820 - val_precision: 0.9823 - val_recall: 0.9818 - val_binary_accuracy: 0.9821 - val_false_positives: 115.0000 - val_false_negatives: 118.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 10/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0541 - accuracy: 0.9796 - precision: 0.9796 - recall: 0.9796 - binary_accuracy: 0.9796 - false_positives: 620.0000 - false_negatives: 620.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0532 - val_accuracy: 0.9814 - val_precision: 0.9811 - val_recall: 0.9812 - val_binary_accuracy: 0.9812 - val_false_positives: 123.0000 - val_false_negatives: 122.0000 - val_sensitivity_at_specificity: 0.9997\n",
            "Epoch 11/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0503 - accuracy: 0.9814 - precision: 0.9814 - recall: 0.9813 - binary_accuracy: 0.9814 - false_positives: 563.0000 - false_negatives: 567.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0500 - val_accuracy: 0.9822 - val_precision: 0.9823 - val_recall: 0.9826 - val_binary_accuracy: 0.9825 - val_false_positives: 115.0000 - val_false_negatives: 113.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 12/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0483 - accuracy: 0.9819 - precision: 0.9817 - recall: 0.9821 - binary_accuracy: 0.9819 - false_positives: 554.0000 - false_negatives: 544.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0498 - val_accuracy: 0.9837 - val_precision: 0.9834 - val_recall: 0.9840 - val_binary_accuracy: 0.9837 - val_false_positives: 108.0000 - val_false_negatives: 104.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 13/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0477 - accuracy: 0.9821 - precision: 0.9822 - recall: 0.9820 - binary_accuracy: 0.9821 - false_positives: 540.0000 - false_negatives: 546.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0552 - val_accuracy: 0.9806 - val_precision: 0.9806 - val_recall: 0.9808 - val_binary_accuracy: 0.9807 - val_false_positives: 126.0000 - val_false_negatives: 125.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 14/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0439 - accuracy: 0.9835 - precision: 0.9835 - recall: 0.9834 - binary_accuracy: 0.9834 - false_positives: 501.0000 - false_negatives: 504.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0446 - val_accuracy: 0.9849 - val_precision: 0.9848 - val_recall: 0.9845 - val_binary_accuracy: 0.9846 - val_false_positives: 99.0000 - val_false_negatives: 101.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 15/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0438 - accuracy: 0.9840 - precision: 0.9840 - recall: 0.9837 - binary_accuracy: 0.9839 - false_positives: 484.0000 - false_negatives: 494.0000 - sensitivity_at_specificity: 0.9995 - val_loss: 0.0507 - val_accuracy: 0.9820 - val_precision: 0.9818 - val_recall: 0.9820 - val_binary_accuracy: 0.9819 - val_false_positives: 118.0000 - val_false_negatives: 117.0000 - val_sensitivity_at_specificity: 0.9992\n",
            "Epoch 16/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0408 - accuracy: 0.9845 - precision: 0.9842 - recall: 0.9846 - binary_accuracy: 0.9844 - false_positives: 478.0000 - false_negatives: 467.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0481 - val_accuracy: 0.9832 - val_precision: 0.9832 - val_recall: 0.9834 - val_binary_accuracy: 0.9833 - val_false_positives: 109.0000 - val_false_negatives: 108.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 17/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0388 - accuracy: 0.9854 - precision: 0.9854 - recall: 0.9854 - binary_accuracy: 0.9854 - false_positives: 442.0000 - false_negatives: 443.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0446 - val_accuracy: 0.9852 - val_precision: 0.9852 - val_recall: 0.9852 - val_binary_accuracy: 0.9852 - val_false_positives: 96.0000 - val_false_negatives: 96.0000 - val_sensitivity_at_specificity: 0.9989\n",
            "Epoch 18/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0385 - accuracy: 0.9848 - precision: 0.9847 - recall: 0.9848 - binary_accuracy: 0.9848 - false_positives: 465.0000 - false_negatives: 460.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0444 - val_accuracy: 0.9849 - val_precision: 0.9849 - val_recall: 0.9848 - val_binary_accuracy: 0.9848 - val_false_positives: 98.0000 - val_false_negatives: 99.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 19/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0367 - accuracy: 0.9868 - precision: 0.9867 - recall: 0.9866 - binary_accuracy: 0.9866 - false_positives: 404.0000 - false_negatives: 407.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0414 - val_accuracy: 0.9865 - val_precision: 0.9865 - val_recall: 0.9865 - val_binary_accuracy: 0.9865 - val_false_positives: 88.0000 - val_false_negatives: 88.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 20/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0366 - accuracy: 0.9867 - precision: 0.9867 - recall: 0.9866 - binary_accuracy: 0.9867 - false_positives: 403.0000 - false_negatives: 405.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0416 - val_accuracy: 0.9845 - val_precision: 0.9845 - val_recall: 0.9845 - val_binary_accuracy: 0.9845 - val_false_positives: 101.0000 - val_false_negatives: 101.0000 - val_sensitivity_at_specificity: 0.9998\n",
            "Epoch 21/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0348 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9874 - binary_accuracy: 0.9874 - false_positives: 385.0000 - false_negatives: 382.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0410 - val_accuracy: 0.9855 - val_precision: 0.9855 - val_recall: 0.9854 - val_binary_accuracy: 0.9855 - val_false_positives: 94.0000 - val_false_negatives: 95.0000 - val_sensitivity_at_specificity: 0.9995\n",
            "Epoch 22/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0347 - accuracy: 0.9872 - precision: 0.9873 - recall: 0.9873 - binary_accuracy: 0.9873 - false_positives: 386.0000 - false_negatives: 386.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0438 - val_accuracy: 0.9860 - val_precision: 0.9860 - val_recall: 0.9860 - val_binary_accuracy: 0.9860 - val_false_positives: 91.0000 - val_false_negatives: 91.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Epoch 23/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0308 - accuracy: 0.9886 - precision: 0.9885 - recall: 0.9886 - binary_accuracy: 0.9885 - false_positives: 349.0000 - false_negatives: 347.0000 - sensitivity_at_specificity: 0.9996 - val_loss: 0.0484 - val_accuracy: 0.9843 - val_precision: 0.9846 - val_recall: 0.9845 - val_binary_accuracy: 0.9845 - val_false_positives: 100.0000 - val_false_negatives: 101.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 24/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0316 - accuracy: 0.9879 - precision: 0.9880 - recall: 0.9879 - binary_accuracy: 0.9880 - false_positives: 364.0000 - false_negatives: 366.0000 - sensitivity_at_specificity: 0.9998 - val_loss: 0.0395 - val_accuracy: 0.9874 - val_precision: 0.9874 - val_recall: 0.9874 - val_binary_accuracy: 0.9874 - val_false_positives: 82.0000 - val_false_negatives: 82.0000 - val_sensitivity_at_specificity: 0.9994\n",
            "Epoch 25/25\n",
            "474/474 [==============================] - 3s 7ms/step - loss: 0.0318 - accuracy: 0.9879 - precision: 0.9879 - recall: 0.9879 - binary_accuracy: 0.9879 - false_positives: 367.0000 - false_negatives: 366.0000 - sensitivity_at_specificity: 0.9997 - val_loss: 0.0467 - val_accuracy: 0.9849 - val_precision: 0.9849 - val_recall: 0.9849 - val_binary_accuracy: 0.9849 - val_false_positives: 98.0000 - val_false_negatives: 98.0000 - val_sensitivity_at_specificity: 0.9991\n",
            "Test loss: 0.04482996091246605\n",
            "Test accuracy: 0.9855384826660156\n"
          ]
        }
      ],
      "source": [
        "for i in range(1,32,1):\n",
        "  keras.backend.clear_session()\n",
        "  input_shape = (dimN,2,1)\n",
        "  modelConv = keras.Sequential(\n",
        "      [\n",
        "          keras.Input(shape=input_shape),\n",
        "          layers.LayerNormalization(axis=[1]),\n",
        "          layers.Conv2D(32, kernel_size=(i, 1), activation=\"relu\"),\n",
        "          layers.MaxPooling2D(pool_size=(2, 1)),\n",
        "          layers.Conv2D(64, kernel_size=(i, 1), activation=\"relu\"),\n",
        "          layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "          layers.Flatten(),\n",
        "          layers.Dropout(0.5),\n",
        "          layers.Dense(num_classes, activation=\"sigmoid\"),\n",
        "      ]\n",
        "  )\n",
        "  modelConv.summary()\n",
        "  batch_size = 64\n",
        "  epochs = 25\n",
        "\n",
        "  modelConv.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy',tf.keras.metrics.Precision(),tf.keras.metrics.Recall(),tf.keras.metrics.BinaryAccuracy(),tf.keras.metrics.FalsePositives(),tf.keras.metrics.FalseNegatives(),tf.keras.metrics.SensitivityAtSpecificity(0.5)])\n",
        "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                                    patience=10,\n",
        "                                                    mode='min')\n",
        "  log_dir = \"../ModelsDNN/logs_article/serot/new-fit/ModConvBinNormN\"+str(i)\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "  history = modelConv.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val), callbacks=[early_stopping,tensorboard_callback])#validation_split=0.1)\n",
        "  score = modelConv.evaluate(X_test, y_test, verbose=0)\n",
        "  print(\"Test loss:\", score[0])\n",
        "  print(\"Test accuracy:\", score[1])\n",
        "  modelConv.save(\"../ModelsDNN/ModConvBinNormN\"+str(i)+\".keras\")\n",
        "  hist_df = pd.DataFrame(history.history)\n",
        "  pathH = \"../ModelsDNN/ModConvBinNormN\"+str(i)+\"_history.csv\"\n",
        "  #print(pathH)\n",
        "  hist_df.to_csv(pathH)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Scores Analyzing"
      ],
      "metadata": {
        "id": "9ZWfpBiJkNoW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SA63-3CZJotT",
        "outputId": "f90a535e-ab05-4f84-9460-730640f1943d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ModConvBinNormN1.keras\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 160, 2, 32)        64        \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 80, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 80, 2, 64)         2112      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 40, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2560)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2560)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 5122      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7618 (29.76 KB)\n",
            "Trainable params: 7618 (29.76 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Test loss: 0.22217142581939697\n",
            "Test accuracy: 0.9064615368843079\n",
            "ModConvBinNormN2.keras\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 159, 2, 32)        96        \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 79, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 78, 2, 64)         4160      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 39, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2496)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2496)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 4994      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9570 (37.38 KB)\n",
            "Trainable params: 9570 (37.38 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Test loss: 0.15893147885799408\n",
            "Test accuracy: 0.9361538290977478\n",
            "ModConvBinNormN3.keras\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 158, 2, 32)        128       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 79, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 77, 2, 64)         6208      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 38, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2432)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2432)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 4866      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11522 (45.01 KB)\n",
            "Trainable params: 11522 (45.01 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Test loss: 0.11355171352624893\n",
            "Test accuracy: 0.9559999704360962\n",
            "ModConvBinNormN4.keras\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 157, 2, 32)        160       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 78, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 75, 2, 64)         8256      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 37, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2368)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2368)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 4738      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13474 (52.63 KB)\n",
            "Trainable params: 13474 (52.63 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Test loss: 0.0896405577659607\n",
            "Test accuracy: 0.9658461809158325\n",
            "ModConvBinNormN5.keras\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 156, 2, 32)        192       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 78, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 74, 2, 64)         10304     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 37, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2368)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2368)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 4738      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15554 (60.76 KB)\n",
            "Trainable params: 15554 (60.76 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Test loss: 0.08441269397735596\n",
            "Test accuracy: 0.9709230661392212\n",
            "ModConvBinNormN6.keras\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 155, 2, 32)        224       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 77, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 72, 2, 64)         12352     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 36, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2304)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2304)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 4610      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17506 (68.38 KB)\n",
            "Trainable params: 17506 (68.38 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Test loss: 0.07532085478305817\n",
            "Test accuracy: 0.9713846445083618\n",
            "ModConvBinNormN7.keras\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 154, 2, 32)        256       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 77, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 71, 2, 64)         14400     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 35, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2240)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2240)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 4482      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 19458 (76.01 KB)\n",
            "Trainable params: 19458 (76.01 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Test loss: 0.062026094645261765\n",
            "Test accuracy: 0.975538432598114\n",
            "ModConvBinNormN8.keras\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 153, 2, 32)        288       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 76, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 69, 2, 64)         16448     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 34, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2176)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2176)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 4354      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21410 (83.63 KB)\n",
            "Trainable params: 21410 (83.63 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Test loss: 0.06220972165465355\n",
            "Test accuracy: 0.9778461456298828\n",
            "ModConvBinNormN9.keras\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 152, 2, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 76, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 68, 2, 64)         18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 34, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2176)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2176)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 4354      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23490 (91.76 KB)\n",
            "Trainable params: 23490 (91.76 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Test loss: 0.0526341050863266\n",
            "Test accuracy: 0.9803076982498169\n",
            "ModConvBinNormN10.keras\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 151, 2, 32)        352       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 75, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 66, 2, 64)         20544     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 33, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2112)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2112)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 4226      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25442 (99.38 KB)\n",
            "Trainable params: 25442 (99.38 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Test loss: 0.04880281910300255\n",
            "Test accuracy: 0.9826154112815857\n",
            "ModConvBinNormN11.keras\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 150, 2, 32)        384       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 75, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 65, 2, 64)         22592     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 32, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 4098      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 27394 (107.01 KB)\n",
            "Trainable params: 27394 (107.01 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Test loss: 0.04807567968964577\n",
            "Test accuracy: 0.9818461537361145\n",
            "ModConvBinNormN12.keras\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 149, 2, 32)        416       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 74, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 63, 2, 64)         24640     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 31, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1984)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1984)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 3970      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 29346 (114.63 KB)\n",
            "Trainable params: 29346 (114.63 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Test loss: 0.048886507749557495\n",
            "Test accuracy: 0.9806153774261475\n",
            "ModConvBinNormN13.keras\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 148, 2, 32)        448       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 74, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 62, 2, 64)         26688     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 31, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1984)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1984)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 3970      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31426 (122.76 KB)\n",
            "Trainable params: 31426 (122.76 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Test loss: 0.04891234263777733\n",
            "Test accuracy: 0.9829230904579163\n",
            "ModConvBinNormN14.keras\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 147, 2, 32)        480       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 73, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 60, 2, 64)         28736     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 30, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1920)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1920)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 3842      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 33378 (130.38 KB)\n",
            "Trainable params: 33378 (130.38 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Test loss: 0.04869687929749489\n",
            "Test accuracy: 0.982769250869751\n",
            "ModConvBinNormN15.keras\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 146, 2, 32)        512       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 73, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 59, 2, 64)         30784     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 29, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1856)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1856)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 3714      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 35330 (138.01 KB)\n",
            "Trainable params: 35330 (138.01 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Test loss: 0.049796611070632935\n",
            "Test accuracy: 0.9821538329124451\n",
            "ModConvBinNormN16.keras\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 145, 2, 32)        544       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 72, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 57, 2, 64)         32832     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 28, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1792)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1792)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 3586      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 37282 (145.63 KB)\n",
            "Trainable params: 37282 (145.63 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Test loss: 0.04079541191458702\n",
            "Test accuracy: 0.9866153597831726\n",
            "ModConvBinNormN17.keras\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 144, 2, 32)        576       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 72, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 56, 2, 64)         34880     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 28, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1792)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1792)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 3586      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 39362 (153.76 KB)\n",
            "Trainable params: 39362 (153.76 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Test loss: 0.04223007336258888\n",
            "Test accuracy: 0.9844615459442139\n",
            "ModConvBinNormN18.keras\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 143, 2, 32)        608       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 71, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 54, 2, 64)         36928     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 27, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1728)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1728)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 3458      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 41314 (161.38 KB)\n",
            "Trainable params: 41314 (161.38 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Test loss: 0.0441850870847702\n",
            "Test accuracy: 0.9844615459442139\n",
            "ModConvBinNormN19.keras\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 142, 2, 32)        640       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 71, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 53, 2, 64)         38976     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 26, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1664)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1664)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 3330      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 43266 (169.01 KB)\n",
            "Trainable params: 43266 (169.01 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Test loss: 0.03705510497093201\n",
            "Test accuracy: 0.9872307777404785\n",
            "ModConvBinNormN20.keras\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 141, 2, 32)        672       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 70, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 51, 2, 64)         41024     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 25, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1600)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1600)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 3202      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 45218 (176.63 KB)\n",
            "Trainable params: 45218 (176.63 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Test loss: 0.039379555732011795\n",
            "Test accuracy: 0.9846153855323792\n",
            "ModConvBinNormN21.keras\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 140, 2, 32)        704       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 70, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 50, 2, 64)         43072     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 25, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1600)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1600)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 3202      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 47298 (184.76 KB)\n",
            "Trainable params: 47298 (184.76 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Test loss: 0.05043596774339676\n",
            "Test accuracy: 0.9835384488105774\n",
            "ModConvBinNormN22.keras\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 139, 2, 32)        736       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 69, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 48, 2, 64)         45120     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 24, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1536)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1536)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 3074      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 49250 (192.38 KB)\n",
            "Trainable params: 49250 (192.38 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Test loss: 0.05230444297194481\n",
            "Test accuracy: 0.9832307696342468\n",
            "ModConvBinNormN23.keras\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 138, 2, 32)        768       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 69, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 47, 2, 64)         47168     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 23, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1472)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1472)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 2946      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51202 (200.01 KB)\n",
            "Trainable params: 51202 (200.01 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Test loss: 0.04140113666653633\n",
            "Test accuracy: 0.9873846173286438\n",
            "ModConvBinNormN24.keras\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 137, 2, 32)        800       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 68, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 45, 2, 64)         49216     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 22, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1408)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1408)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 2818      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 53154 (207.63 KB)\n",
            "Trainable params: 53154 (207.63 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Test loss: 0.037166815251111984\n",
            "Test accuracy: 0.9873846173286438\n",
            "ModConvBinNormN25.keras\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 136, 2, 32)        832       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 68, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 44, 2, 64)         51264     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 22, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1408)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1408)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 2818      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 55234 (215.76 KB)\n",
            "Trainable params: 55234 (215.76 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Test loss: 0.049891941249370575\n",
            "Test accuracy: 0.9821538329124451\n",
            "ModConvBinNormN26.keras\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 135, 2, 32)        864       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 67, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 42, 2, 64)         53312     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 21, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1344)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1344)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 2690      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 57186 (223.38 KB)\n",
            "Trainable params: 57186 (223.38 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Test loss: 0.04623577743768692\n",
            "Test accuracy: 0.9835384488105774\n",
            "ModConvBinNormN27.keras\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 134, 2, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 67, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 41, 2, 64)         55360     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 20, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1280)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 2562      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 59138 (231.01 KB)\n",
            "Trainable params: 59138 (231.01 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Test loss: 0.03823322802782059\n",
            "Test accuracy: 0.9876922965049744\n",
            "ModConvBinNormN28.keras\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 133, 2, 32)        928       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 66, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 39, 2, 64)         57408     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 19, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1216)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1216)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 2434      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 61090 (238.63 KB)\n",
            "Trainable params: 61090 (238.63 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Test loss: 0.0359978973865509\n",
            "Test accuracy: 0.9866153597831726\n",
            "ModConvBinNormN29.keras\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 132, 2, 32)        960       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 66, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 38, 2, 64)         59456     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 19, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1216)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1216)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 2434      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 63170 (246.76 KB)\n",
            "Trainable params: 63170 (246.76 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Test loss: 0.037728797644376755\n",
            "Test accuracy: 0.986307680606842\n",
            "ModConvBinNormN30.keras\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 131, 2, 32)        992       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 65, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 36, 2, 64)         61504     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 18, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1152)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1152)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 2306      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 65122 (254.38 KB)\n",
            "Trainable params: 65122 (254.38 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Test loss: 0.04506146162748337\n",
            "Test accuracy: 0.9843077063560486\n",
            "ModConvBinNormN31.keras\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_normalization (Layer  (None, 160, 2, 1)         320       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 130, 2, 32)        1024      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 65, 2, 32)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 35, 2, 64)         63552     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 17, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1088)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1088)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 2178      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 67074 (262.01 KB)\n",
            "Trainable params: 67074 (262.01 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Test loss: 0.04482996091246605\n",
            "Test accuracy: 0.9855384826660156\n"
          ]
        }
      ],
      "source": [
        "dfTotNormScores = pd.DataFrame(columns=['Model','Test loss','Test accuracy','Test Precision','Test Recall','Test Binary Accuracy','Test False Positives','Test False Negatives',' Test Sensitivity At Specificity 0.5'])\n",
        "for i in range(1,32,1):\n",
        "  keras.backend.clear_session()\n",
        "  loaded_model = tf.keras.models.load_model(\"../ModelsDNN/ModConvBinNormN\"+str(i)+\".keras\")\n",
        "  score = loaded_model.evaluate(X_test, y_test, verbose=0)\n",
        "  model_name = \"ModConvBinNormN\"+str(i)+\".keras\"\n",
        "  print(\"ModConvBinNormN\"+str(i)+\".keras\")\n",
        "  loaded_model.summary()\n",
        "  print(\"Test loss:\", score[0])\n",
        "  print(\"Test accuracy:\", score[1])\n",
        "  dfTotNormScores.loc[i] = [model_name, score[0], score[1], score[2], score[3], score[4], score[5], score[6],score[7]]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfTotNormScores.to_csv('../ModelsDNN/ModConvBinNormN_Tot_Scores.csv')"
      ],
      "metadata": {
        "id": "cYBWg20mi7Mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "U4WexTAlJxIj",
        "outputId": "903c5c34-fb7b-4a0d-cb8e-56847810b10d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      Model  Test loss  Test accuracy  Test Precision  \\\n",
              "1    ModConvBinNormN1.keras   0.222171       0.906462        0.906615   \n",
              "2    ModConvBinNormN2.keras   0.158931       0.936154        0.936144   \n",
              "3    ModConvBinNormN3.keras   0.113552       0.956000        0.955706   \n",
              "4    ModConvBinNormN4.keras   0.089641       0.965846        0.966149   \n",
              "5    ModConvBinNormN5.keras   0.084413       0.970923        0.970923   \n",
              "6    ModConvBinNormN6.keras   0.075321       0.971385        0.971235   \n",
              "7    ModConvBinNormN7.keras   0.062026       0.975538        0.975542   \n",
              "8    ModConvBinNormN8.keras   0.062210       0.977846        0.977699   \n",
              "9    ModConvBinNormN9.keras   0.052634       0.980308        0.980305   \n",
              "10  ModConvBinNormN10.keras   0.048803       0.982615        0.982467   \n",
              "11  ModConvBinNormN11.keras   0.048076       0.981846        0.981846   \n",
              "12  ModConvBinNormN12.keras   0.048887       0.980615        0.980465   \n",
              "13  ModConvBinNormN13.keras   0.048912       0.982923        0.982772   \n",
              "14  ModConvBinNormN14.keras   0.048697       0.982769        0.982923   \n",
              "15  ModConvBinNormN15.keras   0.049797       0.982154        0.982000   \n",
              "16  ModConvBinNormN16.keras   0.040795       0.986615        0.986312   \n",
              "17  ModConvBinNormN17.keras   0.042230       0.984462        0.984308   \n",
              "18  ModConvBinNormN18.keras   0.044185       0.984462        0.984462   \n",
              "19  ModConvBinNormN19.keras   0.037055       0.987231        0.987231   \n",
              "20  ModConvBinNormN20.keras   0.039380       0.984615        0.984615   \n",
              "21  ModConvBinNormN21.keras   0.050436       0.983538        0.983236   \n",
              "22  ModConvBinNormN22.keras   0.052304       0.983231        0.983379   \n",
              "23  ModConvBinNormN23.keras   0.041401       0.987385        0.987385   \n",
              "24  ModConvBinNormN24.keras   0.037167       0.987385        0.987383   \n",
              "25  ModConvBinNormN25.keras   0.049892       0.982154        0.982154   \n",
              "26  ModConvBinNormN26.keras   0.046236       0.983538        0.983538   \n",
              "27  ModConvBinNormN27.keras   0.038233       0.987692        0.987844   \n",
              "28  ModConvBinNormN28.keras   0.035998       0.986615        0.986767   \n",
              "29  ModConvBinNormN29.keras   0.037729       0.986308        0.986459   \n",
              "30  ModConvBinNormN30.keras   0.045061       0.984308        0.984308   \n",
              "31  ModConvBinNormN31.keras   0.044830       0.985538        0.985538   \n",
              "\n",
              "    Test Recall  Test Binary Accuracy  Test False Positives  \\\n",
              "1      0.906615              0.906615                 607.0   \n",
              "2      0.936000              0.936077                 415.0   \n",
              "3      0.956000              0.955846                 288.0   \n",
              "4      0.966000              0.966077                 220.0   \n",
              "5      0.970923              0.970923                 189.0   \n",
              "6      0.971385              0.971308                 187.0   \n",
              "7      0.975692              0.975615                 159.0   \n",
              "8      0.978000              0.977846                 145.0   \n",
              "9      0.980154              0.980231                 128.0   \n",
              "10     0.982769              0.982615                 114.0   \n",
              "11     0.981846              0.981846                 118.0   \n",
              "12     0.980615              0.980538                 127.0   \n",
              "13     0.982923              0.982846                 112.0   \n",
              "14     0.982923              0.982923                 111.0   \n",
              "15     0.982000              0.982000                 117.0   \n",
              "16     0.986615              0.986462                  89.0   \n",
              "17     0.984308              0.984308                 102.0   \n",
              "18     0.984462              0.984462                 101.0   \n",
              "19     0.987231              0.987231                  83.0   \n",
              "20     0.984615              0.984615                 100.0   \n",
              "21     0.983538              0.983385                 109.0   \n",
              "22     0.983077              0.983231                 108.0   \n",
              "23     0.987385              0.987385                  82.0   \n",
              "24     0.987231              0.987308                  82.0   \n",
              "25     0.982154              0.982154                 116.0   \n",
              "26     0.983538              0.983538                 107.0   \n",
              "27     0.987692              0.987769                  79.0   \n",
              "28     0.986615              0.986692                  86.0   \n",
              "29     0.986308              0.986385                  88.0   \n",
              "30     0.984308              0.984308                 102.0   \n",
              "31     0.985538              0.985538                  94.0   \n",
              "\n",
              "    Test False Negatives   Test Sensitivity At Specificity 0.5  \n",
              "1                  607.0                              0.996154  \n",
              "2                  416.0                              0.998923  \n",
              "3                  286.0                              0.999846  \n",
              "4                  221.0                              0.999385  \n",
              "5                  189.0                              0.999385  \n",
              "6                  186.0                              0.999385  \n",
              "7                  158.0                              0.999846  \n",
              "8                  143.0                              0.999231  \n",
              "9                  129.0                              0.999846  \n",
              "10                 112.0                              0.999692  \n",
              "11                 118.0                              0.999692  \n",
              "12                 126.0                              0.999692  \n",
              "13                 111.0                              0.999538  \n",
              "14                 111.0                              0.999231  \n",
              "15                 117.0                              0.999385  \n",
              "16                  87.0                              0.999385  \n",
              "17                 102.0                              0.999538  \n",
              "18                 101.0                              0.999385  \n",
              "19                  83.0                              0.999538  \n",
              "20                 100.0                              0.999385  \n",
              "21                 107.0                              0.998769  \n",
              "22                 110.0                              0.999077  \n",
              "23                  82.0                              0.999231  \n",
              "24                  83.0                              0.999538  \n",
              "25                 116.0                              0.998769  \n",
              "26                 107.0                              0.998769  \n",
              "27                  80.0                              0.999385  \n",
              "28                  87.0                              0.999538  \n",
              "29                  89.0                              0.999231  \n",
              "30                 102.0                              0.998923  \n",
              "31                  94.0                              0.999077  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-de4e47d4-cf29-46a6-9e5a-111e60eb8263\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Test loss</th>\n",
              "      <th>Test accuracy</th>\n",
              "      <th>Test Precision</th>\n",
              "      <th>Test Recall</th>\n",
              "      <th>Test Binary Accuracy</th>\n",
              "      <th>Test False Positives</th>\n",
              "      <th>Test False Negatives</th>\n",
              "      <th>Test Sensitivity At Specificity 0.5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ModConvBinNormN1.keras</td>\n",
              "      <td>0.222171</td>\n",
              "      <td>0.906462</td>\n",
              "      <td>0.906615</td>\n",
              "      <td>0.906615</td>\n",
              "      <td>0.906615</td>\n",
              "      <td>607.0</td>\n",
              "      <td>607.0</td>\n",
              "      <td>0.996154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ModConvBinNormN2.keras</td>\n",
              "      <td>0.158931</td>\n",
              "      <td>0.936154</td>\n",
              "      <td>0.936144</td>\n",
              "      <td>0.936000</td>\n",
              "      <td>0.936077</td>\n",
              "      <td>415.0</td>\n",
              "      <td>416.0</td>\n",
              "      <td>0.998923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ModConvBinNormN3.keras</td>\n",
              "      <td>0.113552</td>\n",
              "      <td>0.956000</td>\n",
              "      <td>0.955706</td>\n",
              "      <td>0.956000</td>\n",
              "      <td>0.955846</td>\n",
              "      <td>288.0</td>\n",
              "      <td>286.0</td>\n",
              "      <td>0.999846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ModConvBinNormN4.keras</td>\n",
              "      <td>0.089641</td>\n",
              "      <td>0.965846</td>\n",
              "      <td>0.966149</td>\n",
              "      <td>0.966000</td>\n",
              "      <td>0.966077</td>\n",
              "      <td>220.0</td>\n",
              "      <td>221.0</td>\n",
              "      <td>0.999385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ModConvBinNormN5.keras</td>\n",
              "      <td>0.084413</td>\n",
              "      <td>0.970923</td>\n",
              "      <td>0.970923</td>\n",
              "      <td>0.970923</td>\n",
              "      <td>0.970923</td>\n",
              "      <td>189.0</td>\n",
              "      <td>189.0</td>\n",
              "      <td>0.999385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ModConvBinNormN6.keras</td>\n",
              "      <td>0.075321</td>\n",
              "      <td>0.971385</td>\n",
              "      <td>0.971235</td>\n",
              "      <td>0.971385</td>\n",
              "      <td>0.971308</td>\n",
              "      <td>187.0</td>\n",
              "      <td>186.0</td>\n",
              "      <td>0.999385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ModConvBinNormN7.keras</td>\n",
              "      <td>0.062026</td>\n",
              "      <td>0.975538</td>\n",
              "      <td>0.975542</td>\n",
              "      <td>0.975692</td>\n",
              "      <td>0.975615</td>\n",
              "      <td>159.0</td>\n",
              "      <td>158.0</td>\n",
              "      <td>0.999846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ModConvBinNormN8.keras</td>\n",
              "      <td>0.062210</td>\n",
              "      <td>0.977846</td>\n",
              "      <td>0.977699</td>\n",
              "      <td>0.978000</td>\n",
              "      <td>0.977846</td>\n",
              "      <td>145.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>0.999231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ModConvBinNormN9.keras</td>\n",
              "      <td>0.052634</td>\n",
              "      <td>0.980308</td>\n",
              "      <td>0.980305</td>\n",
              "      <td>0.980154</td>\n",
              "      <td>0.980231</td>\n",
              "      <td>128.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>0.999846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>ModConvBinNormN10.keras</td>\n",
              "      <td>0.048803</td>\n",
              "      <td>0.982615</td>\n",
              "      <td>0.982467</td>\n",
              "      <td>0.982769</td>\n",
              "      <td>0.982615</td>\n",
              "      <td>114.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>0.999692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>ModConvBinNormN11.keras</td>\n",
              "      <td>0.048076</td>\n",
              "      <td>0.981846</td>\n",
              "      <td>0.981846</td>\n",
              "      <td>0.981846</td>\n",
              "      <td>0.981846</td>\n",
              "      <td>118.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>0.999692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>ModConvBinNormN12.keras</td>\n",
              "      <td>0.048887</td>\n",
              "      <td>0.980615</td>\n",
              "      <td>0.980465</td>\n",
              "      <td>0.980615</td>\n",
              "      <td>0.980538</td>\n",
              "      <td>127.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>0.999692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>ModConvBinNormN13.keras</td>\n",
              "      <td>0.048912</td>\n",
              "      <td>0.982923</td>\n",
              "      <td>0.982772</td>\n",
              "      <td>0.982923</td>\n",
              "      <td>0.982846</td>\n",
              "      <td>112.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>0.999538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>ModConvBinNormN14.keras</td>\n",
              "      <td>0.048697</td>\n",
              "      <td>0.982769</td>\n",
              "      <td>0.982923</td>\n",
              "      <td>0.982923</td>\n",
              "      <td>0.982923</td>\n",
              "      <td>111.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>0.999231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>ModConvBinNormN15.keras</td>\n",
              "      <td>0.049797</td>\n",
              "      <td>0.982154</td>\n",
              "      <td>0.982000</td>\n",
              "      <td>0.982000</td>\n",
              "      <td>0.982000</td>\n",
              "      <td>117.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>0.999385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>ModConvBinNormN16.keras</td>\n",
              "      <td>0.040795</td>\n",
              "      <td>0.986615</td>\n",
              "      <td>0.986312</td>\n",
              "      <td>0.986615</td>\n",
              "      <td>0.986462</td>\n",
              "      <td>89.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>0.999385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>ModConvBinNormN17.keras</td>\n",
              "      <td>0.042230</td>\n",
              "      <td>0.984462</td>\n",
              "      <td>0.984308</td>\n",
              "      <td>0.984308</td>\n",
              "      <td>0.984308</td>\n",
              "      <td>102.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>0.999538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>ModConvBinNormN18.keras</td>\n",
              "      <td>0.044185</td>\n",
              "      <td>0.984462</td>\n",
              "      <td>0.984462</td>\n",
              "      <td>0.984462</td>\n",
              "      <td>0.984462</td>\n",
              "      <td>101.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>0.999385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>ModConvBinNormN19.keras</td>\n",
              "      <td>0.037055</td>\n",
              "      <td>0.987231</td>\n",
              "      <td>0.987231</td>\n",
              "      <td>0.987231</td>\n",
              "      <td>0.987231</td>\n",
              "      <td>83.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>0.999538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>ModConvBinNormN20.keras</td>\n",
              "      <td>0.039380</td>\n",
              "      <td>0.984615</td>\n",
              "      <td>0.984615</td>\n",
              "      <td>0.984615</td>\n",
              "      <td>0.984615</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.999385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>ModConvBinNormN21.keras</td>\n",
              "      <td>0.050436</td>\n",
              "      <td>0.983538</td>\n",
              "      <td>0.983236</td>\n",
              "      <td>0.983538</td>\n",
              "      <td>0.983385</td>\n",
              "      <td>109.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>0.998769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>ModConvBinNormN22.keras</td>\n",
              "      <td>0.052304</td>\n",
              "      <td>0.983231</td>\n",
              "      <td>0.983379</td>\n",
              "      <td>0.983077</td>\n",
              "      <td>0.983231</td>\n",
              "      <td>108.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>0.999077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>ModConvBinNormN23.keras</td>\n",
              "      <td>0.041401</td>\n",
              "      <td>0.987385</td>\n",
              "      <td>0.987385</td>\n",
              "      <td>0.987385</td>\n",
              "      <td>0.987385</td>\n",
              "      <td>82.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>0.999231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>ModConvBinNormN24.keras</td>\n",
              "      <td>0.037167</td>\n",
              "      <td>0.987385</td>\n",
              "      <td>0.987383</td>\n",
              "      <td>0.987231</td>\n",
              "      <td>0.987308</td>\n",
              "      <td>82.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>0.999538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>ModConvBinNormN25.keras</td>\n",
              "      <td>0.049892</td>\n",
              "      <td>0.982154</td>\n",
              "      <td>0.982154</td>\n",
              "      <td>0.982154</td>\n",
              "      <td>0.982154</td>\n",
              "      <td>116.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>0.998769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>ModConvBinNormN26.keras</td>\n",
              "      <td>0.046236</td>\n",
              "      <td>0.983538</td>\n",
              "      <td>0.983538</td>\n",
              "      <td>0.983538</td>\n",
              "      <td>0.983538</td>\n",
              "      <td>107.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>0.998769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>ModConvBinNormN27.keras</td>\n",
              "      <td>0.038233</td>\n",
              "      <td>0.987692</td>\n",
              "      <td>0.987844</td>\n",
              "      <td>0.987692</td>\n",
              "      <td>0.987769</td>\n",
              "      <td>79.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.999385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>ModConvBinNormN28.keras</td>\n",
              "      <td>0.035998</td>\n",
              "      <td>0.986615</td>\n",
              "      <td>0.986767</td>\n",
              "      <td>0.986615</td>\n",
              "      <td>0.986692</td>\n",
              "      <td>86.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>0.999538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>ModConvBinNormN29.keras</td>\n",
              "      <td>0.037729</td>\n",
              "      <td>0.986308</td>\n",
              "      <td>0.986459</td>\n",
              "      <td>0.986308</td>\n",
              "      <td>0.986385</td>\n",
              "      <td>88.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>0.999231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>ModConvBinNormN30.keras</td>\n",
              "      <td>0.045061</td>\n",
              "      <td>0.984308</td>\n",
              "      <td>0.984308</td>\n",
              "      <td>0.984308</td>\n",
              "      <td>0.984308</td>\n",
              "      <td>102.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>0.998923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>ModConvBinNormN31.keras</td>\n",
              "      <td>0.044830</td>\n",
              "      <td>0.985538</td>\n",
              "      <td>0.985538</td>\n",
              "      <td>0.985538</td>\n",
              "      <td>0.985538</td>\n",
              "      <td>94.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>0.999077</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de4e47d4-cf29-46a6-9e5a-111e60eb8263')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-de4e47d4-cf29-46a6-9e5a-111e60eb8263 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-de4e47d4-cf29-46a6-9e5a-111e60eb8263');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-91985d1d-2a65-45d3-8cbe-eda7ae2b1098\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-91985d1d-2a65-45d3-8cbe-eda7ae2b1098')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-91985d1d-2a65-45d3-8cbe-eda7ae2b1098 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "dfTotNormScores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "_o5eyJ_NsCwU",
        "outputId": "303b16dc-a33e-49d9-a3ed-fd73ddedc69b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "dfTotNormScores['Test accuracy'].plot(kind='line', figsize=(8, 4), title='Test accuracy')\n",
        "plt.gca().spines[['top', 'right']].set_visible(False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "V100",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}